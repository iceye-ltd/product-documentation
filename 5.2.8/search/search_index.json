{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["trimmer","stopWordFilter"]},"docs":[{"location":"","title":"WELCOME","text":""},{"location":"#how-to-read-this-document","title":"How To Read This Document","text":"<p>The list of contents on the left should guide you through the information you need from this site in a sensible order. </p> <ul> <li>First there is a description of the current ICEYE Fleet of satellites with some useful information on where each satellite is right now.</li> <li>This is followed by sections on Types of SAR Collection and SAR Data Products. This is where you can find out about the different types of SAR images you can buy and contains a useful summary of what performance parameters you can expect when you receive your imagery.</li> <li>Once you know what ICEYE data products best support your requirements, you will want to know how to order some imagery. This is covered in the next section on Ordering SAR imagery. This section also describes the level of support you can expect to receive.</li> <li>The next section is for those users that want to explore the techical content of their ICEYE SAR imagery. It contains detailed information for each image product and describes how each imaged is stored and formatted. It also contains documentation for the metadata elements stored in ICEYE images. It provides some guides and explanations on some foundation principles related to the practical exploitation of SAR imagery.</li> <li>Following this is a section for those curious to understand how SAR works. SAR truly is an amazing type of imaging sensor with many unique properties that are all too easy to overlook so we pulled this section together to explain the basic principles.</li> </ul> <p>If you want to learn more about ICEYE the company, its initiatives and projects then we would encourage you to visit the ICEYE website. It has many examples and stories about the company, what it has done and where it wants to go. Finally, if you are not quite sure where to find what you are looking for you can just type a short query in the search bar at the top of each page.</p>"},{"location":"#how-to-get-in-touch","title":"How To Get in Touch","text":"<ul> <li> - http://iceye.com</li> <li> - @ICEYEcom</li> <li> \u2013 @iceyefi</li> <li> \u2013 @iceye</li> <li> \u2013 https://www.linkedin.com/company/iceye/</li> </ul>"},{"location":"about/","title":"WELCOME TO ICEYE","text":""},{"location":"about/#your-choice-for-persistent-monitoring","title":"Your Choice for Persistent Monitoring","text":"<p>ICEYE empowers commercial and government partners with unmatched persistent monitoring capabilities for any location on Earth. We do this with our continually growing SAR satellite constellation, currently in orbit and delivering SAR data. This product guide reviews our constellation, products, imaging modes and ordering process.</p> <p>This is a living document because our innovative small SARs are flexible and they welcome our routine upgrades to their resolution, coverage and quality. We\u2019ll release new versions of this guide as we improve our sensors, expand our constellation, and streamline our order and delivery systems.</p> <p></p> <p>SAR sensors see through clouds and darkness. They measure pulse echoes with a precision much smaller than a single wavelength. Their resolution is independent of distance. They are capable of pristine geolocation, and they are change detection machines.</p> <p>We Look Forward to Serving You</p>"},{"location":"about/#the-small-sar-revolution-in-earth-imaging","title":"The Small SAR Revolution in Earth Imaging","text":"<p>During the Middle Ages, if you wanted to understand the way the world worked you would consult your local religious leader. A Priest or Prophet would interpret the Word of God from beautifully written tomes that were transcribed by hand over many years. These books were ornate and so precious that they could not be widely distributed, and most people did not know how to read. In these years, the thoughts of nations were controlled by various religious and political leaders.</p> <p>Then everything changed. The Renaissance and Reformation spurred new ways of thinking, and their ideas were recorded in printed books that were produced at low cost and in great volumes. People learned to read for themselves and think for themselves. Information spread across the globe.</p> <p>Sometimes disruption can be good. </p> <p>Hundreds of years later, in 2012, a small team of students working in the Nanosatellite Group of Aalto University considered the sequestered world of earth observation. The team was bothered by the limitations of government satellite programs in the same way that Renaissance and Reformation advocates challenged the knowledge control of the Middle Ages.</p> <p>Satellite imagery has been mostly provided by massive, government-owned or government-sponsored, exquisite systems. Like the tomes of old, these are beautifully implemented and precious. But normal people rarely have access to their images, and even when they are available, they do not have the timeliness to support the quick decisions needed in this rapidly changing world. </p> <p>The Nanosatellite students thought that timely, always available fine-resolution imagery should become a part of everyday life in the 21st century in the same way that GPS became integrated to nearly all businesses in the last decade of the 20th century. The humanitarian applications of easily-accessible imagery would include earthquakes, floods, volcanoes, glacial flow, and numerous environmental indicators. But if earth-observation imagery were to become as available, reliable and timely as the pace of our modern lives requires, things needed to change.</p> <p>Fueled by curiosity, passion, and long, dark Helsinki nights, the students decided that Synthetic Aperture Radar (SAR) would be the most useful way to obtain guaranteed, all-weather, day-night, observations of this cloud-covered planet. They reconsidered the conventional thinking regarding the mass and size needed to build SAR satellites, and then developed experimental sensors to prove and revise their thinking.</p> <p>In 2015 ICEYE Oy was born. And thanks to several backers who shared our vision, on January 12th, 2018 the world\u2019s first micro-SAR satellite was launched. In contrast to the existing SAR systems that each weigh several tons, our  ICEYE-X1 weighed only 75kg. It provided beautiful 3-meter resolution imagery, and it allowed our company to evaluate many natural disasters.</p> <p>The ICEYE fleet is now growing rapidly. We began 2021 with 7 satellites, and we\u2019ll expand this to a constellation of 18 by mid-2022. Change is natural to our flexible systems. We upgrade our satellites the way programmers update code. Our resolution and coverage improves with each new version. And our low-cost, low-mass satellites are so highly maneuverable that we can reposition them to optimize revisit rates and support global change detection.</p> <p>We will bring our users access to highly accurate, highly reliable monitoring, whenever and wherever they need it, at a pace that has never before existed.</p> <p>Welcome to the Earth Observation Renaissance !</p> <p>Read The ICEYE Story</p>"},{"location":"changes/","title":"Change Log","text":"Date Version Comment 12th Jul 2024 5.2.8 Updated fonts and colors to new ICEYE brand. Fixed search. 26th Jun 2024 5.2.7 Removed references to polyfill.io domain. 11th March 2024 5.2.4 Addition of Dwell Fine imaging characteristics and data product parameters. Upcoming CPX format renamed GeoTIFF SLC. Upcoming AML format renamed Cloud-optimized GeoTIFF GRD. 20th Jan 2024 5.2.3 Revision of performant and time-dominant incidence angle ranges for multiple imaging modes 17th Dec 2023 5.2.2 Addition of preview documentation for upcoming new formats CPX and AML 3rd Nov 2023 5.2.1 Addition of documentation for Colorized Sub-aperture Image (CSI) and SAR Video (VID) produtcs 13th Jun 2023 5.2.0 Addition of Spot Fine Imaging Characteristics and Data Product Parameters. Fleet summary modified to reflect capabilities of new Generation 3 satellites. 1st Feb 2023 5.1.2 Addition of Spot Extended Dwell Imaging Characteristics 1st Dec 2022 5.1.1 Removed reference to NaN values in SLC Data Product  Added change log (this page)  Corrected typo in stack time image under Product Ordering  Added geospatial validation report to June 2022.  Moved Foundations into a new section rather than under format specification.  Typo ellipsoid to geoid under RPC information  Removed stale page on image data formats 19 Aug 2022 5.1.0 Updated metadata to be version 2.4 7 Apr 2022 5.0.0 First release of online product documentation 1 Nov 2021 4.2.1 First online version following ICEYE Product Guide V4.2"},{"location":"glossary/","title":"Terminology, Acronyms and Symbols","text":""},{"location":"glossary/#sar-glossary","title":"SAR Glossary","text":"TERM DEFINITION Azimuth Direction aligned with the relative spaceborne platform velocity vector. Detection Processing step in which the phase information is removed and only the signal amplitude is preserved. Normally the detection uses a magnitude squared method and has units of voltage square per pixel. Focusing Data processing finalized to focus the SAR image in range and azimuth through bidimensional signal compression. Geocoded The data contains geographic information or coordinates corresponding to the location of the data. Georeference The internal coordinate system of the image can be related to a ground system of geographic coordinates Ground range Projection of the slant range into the ground. Incidence angle Local incidence angle on ground calculated using the ellipsoidal Earth model. Looks Image obtained using only part of the spectrum to focus the image (subaperture). It can be done in range and in azimuth, and normally is used to reduce the speckle noise from SAR images through incoherent sum (multi-look process). Range Direction orthogonal to the satellite velocity. Slant range vector Line-Of-Sight distance between the antenna and the target on ground. Slant range plane Plane containing the relative sensor velocity vector and the slant range vector for a given target. <p>|Orthorectification |A subtopic of georeferencing\u2014 The process of converting images into a form suitable for maps by removing sensor motion and terrain-related geometric distortions from raw imagery. |</p>"},{"location":"glossary/#list-of-acronyms","title":"List of Acronyms","text":"TERM DEFINITION ASCII American Standard Code for Information Interchange BSD Berkeley Software Distribution CF Calibration Factor Cn Coefficient \u2018n\u2019 in a polynomial DC Doppler Centroid DN Digital Number ECEF Earth-Centered, Earth-Fixed GR Ground Range GRD Ground Range Detected GRSR Ground Range to Slant Range conversion HDF Hierarchical Data Format KML Keyhole Markup Language PNG Portal Network Graphics PRF Pulse Repetition Frequency RMSE Root Mean Square Error RPC Rapid Positioning Capability (or Rational Polynomial Coefficient) SR Slant Range SAR Synthetic Aperture Radar SLC Single Look Complex UTC Coordinated Universal Time VV Polarization (Vertical transmitted and Vertical received) WGS84 World Geodetic System (1984) XML eXtensible Markup Language"},{"location":"archive/archive/","title":"ICEYE ARCHIVES","text":"<p>Things change fast at ICEYE and we are constantly updating our skills and capabilities as well as our satellites. On this page you will find a collection of our external documents and some links to places that we have found useful when learning about SAR.</p>"},{"location":"archive/archive/#previous-product-documentation","title":"Previous Product Documentation","text":"<p>As we evolve our products, we also have to evolve our metadata and documentation. To allow users to search through previous ICEYE documents we provide them as links in the following table.</p> DOCUMENT VERSION DATE SAR Product Guide 4.2 3 December 2021 Level 1 Product Format Specification 2.1 11 June 2020 Data Calibration and Validation 1.0 22 June 2020 Table 1: ICEYE Archive Documents"},{"location":"archive/archive/#iceye-publications","title":"ICEYE Publications","text":"<p>Having such a large SAR constellation provides unique opportunities for scientific reasearch and experimentation. ICEYE encourages its staff to participate in reaseach activities and innovation is a core principal for the company. In the following table are some recent scientific publications that the team has been working on.</p> REFERENCE CITE Radius A., Leprovost P., Ignatenko V., Muff D., Lamentowski L., Nottingham M., Dogan O., Seilonen T., March 2022, Phase Variant Analysis Algorithm for Azimuth Ambiguity Detection. In 2022 IEEE RADAR Conference Dogan O., Ignatenko V., Muff D., Lamentowski L., Nottingham M., Radius A., Leprovost P., Seilonen T., March 2022, Experimental Demonstration of a Novel End-to-End SAR Range Ambiguity Suppression Method.In 2022 IEEE RADAR Conference Muff, D., Ignatenko V., Dogan O., Lamentowski L., Leprovost P., Nottingham M., Radius A., Seilonen T., Tolpekin, V., The ICEYE Constellation - Some New Achievements. In 2022 IEEE RADAR Conference Ignatenko, V., Nottingham, M., Radius, A., Lamentowski, L. and Muff, D., 2021, July. ICEYE Microsatellite SAR Constellation Status Update: Long Dwell Spotlight and Wide Swath Imaging Modes. In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS (pp. 1493-1496). IEEE. Ignatenko, V., Laurila, P., Radius, A., Lamentowski, L., Antropov, O. and Muff, D., 2020, September. ICEYE Microsatellite SAR Constellation Status Update: Evaluation of first commercial imaging modes. In IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium (pp. 3581-3584). IEEE. Table 2: ICEYE Publications"},{"location":"archive/archive/#useful-links-and-references","title":"Useful Links and References","text":"REFERENCE Comment Thomas P. Ager. The Essentials of SAR: Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities.: 2021. ISBN-13 \u200f : \u200e 979-8512864487 Easy to read introduction to SAR for everyone Astri Polska, ESA SNAP workbook PDF with Radar data processing tools described Thuy Le Toan, Introduction to SAR Remote Sensing, lecture D1La1 of ESA Advanced Training Course on Land Remote Sensing Useful PDF for understanding of geometric properties and artifacts of SAR \"Step by Step: Recommended Practice Flood Mapping\", Office for Outer Space Affairs. UN-SPIDER Knowledge Portal Useful step-by-step instructions from the United Nations Echoes in space. EO College. A useful short course on SAR that we recommend to all our new customers. Table 3: Other useful links"},{"location":"foundations/geospatialAccuracy/","title":"Geospatial Accuracy","text":""},{"location":"foundations/geospatialAccuracy/#background","title":"Background","text":"<p>The complex image output of the SAR image-formation process is a set of focused pixels with phase and amplitude values. Each pixel pair of the image is referenced to the sensor by its range and azimuth coordinates. That is, each pair has a specific range to a sensor reference location and an azimuth location in the along-track direction. This range-azimuth geometry establishes an arc in space, which is the basis of the geolocation modeling of SAR images. The arc for each pixel is initially fit to the slant plant surface, and for amplitude images it is subsequently projected to a ground surface, such as the ground plane or ellipsoid or topographic surface. The geolocation accuracy of an image depends on how well that range-azimuth arc is measured. The relevant parameters for the arc are: the range and azimuth values, the sensor reference location, and the sensor velocity vector. We will consider each of them in turn.</p>"},{"location":"foundations/geospatialAccuracy/#range","title":"Range","text":"<p>A SAR system is able to measure the range to a point on the ground very precisely. The theoretical precision of range is a fraction of a wavelength. However, as the RADAR pulse propagates through the atmosphere, it undergoes diffraction which curves the path of the pulse. This adds an unintended increase to the range of an object. The amount of increase depends on the look angle, the location of the satellite and scene, and even the time of day. The ICEYE SAR processor applies path length corrections (typically on the order of a couple of metres) using well established models. </p>"},{"location":"foundations/geospatialAccuracy/#azimuth","title":"Azimuth","text":"<p>The sensor also compares pulses to measure how the range to a point changes as the satellite moves along its trajectory. This provides precise information of the azimuth, or along-track, location of a pixel. Since this record is derived from precise pulse-to-pulse phase changes, it is the most accurate aspect of SAR data. </p>"},{"location":"foundations/geospatialAccuracy/#on-board-timing-errors","title":"On-Board Timing Errors","text":"<p>A fundamental source of error for all RADAR systems relates to timing. In radar systems, precise electronic clocks are used to record the passage of time. All clocks have some sort of drift in their accuracy which, if not corrected, affects the measured range and focussing of the imagery. ICEYE satellites apply timing corrections to their internal clocks by periodically synchronising with GNSS (Global Navigation Satellite System) satellites.</p>"},{"location":"foundations/geospatialAccuracy/#orbit-knowledge","title":"Orbit Knowledge","text":"<p>A potentially large source of errors comes from not knowing precisely where the sensor is when each pulse is transmitted and received. This is determined by the satellite's orbit knowledge. ICEYE satellites constantly record their GNSS location. This information is transmitted to the ground during ground station telemetry downloads that occur usually once per orbit (sometimes more frequently). Additionally, the GNSS data is stored with the wideband radar data for rapid downlink and processing.</p> <p>Once on the ground, the orbit information is passed to ICEYE's orbit determination servers. These refine the orbit by taking into account the satellite's attitude and motion, the solar radiation pressure and the local gravitational field strength. The refinements are then used to improve the image geospatial accuracy and to provide accurate time/position/velocity estimates for future collections.</p> <p>In the future we plan on further refining the orbit fidelity using post-collected GNSS corrections combined with retroreflectors attached to the satellite.</p> <p>The Following table summarises the different levels of orbit fidelity. This information is stored in each image's metadata.</p> ORBIT FIDELITY DESCRIPTION LATENCY Predicted Uses the latest orbit solution to predict where the satellite will be at some point in the future. It is used for collection planning and feasibility studies.  It is not typically used for image formation processing because it has the largest errors. updated 6 hours before collection Rapid Uses GNSS stored samples collected during or near to the imaging operation. The spherical error (SE90) of the samples is 3 m. This allows imagery to be downlinked during or soon after collection to provide tactical SAR imagery to users with a modest geospatial error. This level is not yet available on all satellites. Immediate Precise This is the default orbit fidelity used for ICEYE satellites. The satellite position and velocity state vectors are refined after the imaging operation using downlinked telemetry and attitude data. The spherical error of the refined data is 1.5 m 10-45 minutes after imaging operation Scientific This uses GNSS corrections applied to the samples taken during imaging to significantly reduce the position velocity error. This is not yet available across the ICEYE Fleet. 2 to 4 days after collection Table 1 : Different Levels of Orbit Fidelity in ICEYE SAR Images"},{"location":"foundations/geospatialAccuracy/#orbit-knowledge-metadata","title":"Orbit Knowledge Metadata","text":"<p>The location of the satellite during any imaging operation is made available by including the satellite and velocity information in the metadata for each image product. The data can be found under the <code>orbit_state_vector</code> metadata element. The accuracy of each element is determined by the orbit fidelity used to create the product which can be found in the <code>orbit_processing_level</code> metadata element which corresponds so one of the levels in table 1.</p>"},{"location":"foundations/geospatialAccuracy/#determining-ground-locations","title":"Determining Ground Locations","text":"<p>A sensor-orientation SAR amplitude image is a distillation of its richer complex image parent. It is the viewable version of SAR pixels and thus contains only microwave brightness values and no phase data. As with the complex image, its pixels have a range-azimuth structure. The difference is that it is usually projected to a ground surface, not the slant plane. It must be emphasized that the SAR image on its own cannot provide accurate ground locations. The chosen ground projection surface is typically an ellipsoid with a height set to the average height of the imaged area. This means that latitude and longitude image corner coordinates are for reference only. They are intended to layout the image footprint, and since they were projected to a single-elevation surface they cannot be used for accurate geolocation. SAR geolocation requires the projection of the natural range-azimuth arc of each pixel to an actual terrain height. This means that the image exploitation system must have a ground terrain height model on hand and it must use the coded SAR geometry model equations. This situation is exactly the same for optical images. The imaging conversion of 3D space to any 2D image, optical or SAR, means that proper geolocation requires pixel projections to elevation models on exploitation workstations.</p>"},{"location":"foundations/geospatialAccuracy/#elevation-models","title":"Elevation Models","text":"<p>In the case of a calibrated SAR with accurate range-azimuth coordinates and precise orbit data, the most significant source of geospatial error comes from the way the data is measured and exploited on a workstation. The following animation explains why the measured location of a point on an accurate SAR image is dominated by errors in external terrain height information. </p> Figure 2: The geospatial accuracy of a SAR image is a function of the accuracy of the terrain model used."},{"location":"foundations/geospatialAccuracy/#the-geolocation-potential-of-sar","title":"The Geolocation Potential of SAR","text":"<p>It is interesting to consider the pristine potential of SAR geolocation. Both SAR and optical satellite sensors can provide accurate orbit information, but optical sensors also need to physically measure the pointing orientation of the sensor to the ground. These data are derived from on-board gyroscopes and star sensors, and errors in the estimates of the sensor pointing direction project along the huge distance to the ground surface. A SAR satellite must also estimate pointing direction in order to illuminate the proper location on the ground. But once the image is formed, the angle to the ground location is determined by the azimuth coordinate, which is itself derived from ultra-precise pulse-to-pulse phase changes. The aspect of optical geolocation which contributes the most uncertainty, pointing direction, is not a significant factor for SAR geolocation. A well-calibrated SAR with accurate orbits, in conjunction with precise elevation data, can provide a geolocation accuracy of less than one meter for well-defined points. This is the precision to which ICEYE aspires.</p>"},{"location":"foundations/geospatialAccuracy/#geospatial-metadata","title":"Geospatial Metadata","text":"<p>It is interesting to note that the ground projection issue relates to any oblique looking imaging system (such as optical sensors) that are able to take images off-nadir. Fortunately a lot of geospatial viewers and exploitation tools have evolved to help the user deal with such issues. Some viewers have terrain models built in and can provide precise location information using parameters embedded in the metadata of each image. Two common approaches are Doppler Centroid Polynomials and Rapid Polynomial Coefficients.</p>"},{"location":"foundations/geospatialAccuracy/#fast-and-simple-geolocation-rapid-positioning-capability","title":"Fast and Simple Geolocation: Rapid Positioning Capability","text":"<p>The range-azimuth arc and its associated geometry model equations form the rigorous, physics-based foundation of SAR geolocation. However, the actual implementation of this model is quite detailed and can include ponderous and slow iterative solutions. An engineering replacement to optical and SAR physics-based geometry models is commonly used to speed and simplify the calculation of ground locations. This replacement model takes the form of a ratio of polynomials that link a ground location (in latitude, longitude and height) to its associated image location. The replacement engineering model has been called Rational Polynomial Coefficients (RPC), but at ICEYE we prefer to call it Rapid Positioning Capability. The latter term instantly indicates its purpose and value, rather than referencing its mathematical structure. Because it is merely a polynomial replacement, the RPC data structure provided for ICEYE SAR images is exactly the same as the RPC model for all optical images. RPC is not only fast and simple; it is also sensor- and phenomenology-independent.</p> <p>It should be noted that RPC data are derived from an image\u2019s geometric metadata and the physics-based geometry model for that sensor. They are usually calculated during image formation and included in the output image file. RPC coefficients are provided for ICEYE\u2019s amplitude images in the GRD format. The model is described in [ <sup>1</sup> ] which extends the work for the National Imagery Transmission Format (NITF)<sup>2</sup> to GeoTIFFs. The translation of latitude, longitude and height to image pixel coordinates is described below.</p> <p>The approximation used in ICEYE products is a set of rational polynomials that describe the normalized row and column values (\\(rn\\) , \\(cn\\)) as a function of normalized geodetic latitude, longitude, and height. The link between the two is the (\\(P\\), \\(L\\), \\(H\\)) set of normalized polynomial coefficients (<code>LINE_NUM_COEF_n</code>, <code>LINE_DEN_COEF_n</code>, <code>SAMP_NUM_COEF_n</code>, <code>SAMP_DEN_COEF_n</code>) as applied in the RPC polynomial format. Normalized values, rather than actual values are used in order to minimize the introduction of errors during the calculations. The transformation between row and column values (\\(r\\),\\(c\\)) and normalized row and column values (\\(r_n\\), \\(c_n\\)), and between the geodetic latitude, longitude, and height ( \u03c6, \u03bb, h ), and normalized geodetic latitude, longitude, and height (P, L, H) is defined by a set of normalizing translations (offsets) and scales that ensure all values are contained within the range -1 to +1. The normalization of these parameters is given in Table 2.</p> <p>If you load ICEYE's images into RPC-compliant GIS Viewers (eg QGIS<sup>3</sup>), with access to a ground elevation model, the Viewer will automatically perform conversion from image row, column to lat, long, height (WGS84 geoid).</p> NORMALISED DEFINITION \\(P\\) (Latitude - <code>LAT_OFF</code>) / <code>LAT_SCALE</code> \\(L\\) (Longitude - <code>LONG_OFF</code>) / <code>LONG_SCALE</code> \\(H\\) (Height - <code>HEIGHT_OFF</code>) / <code>HEIGHT_SCALE</code> \\(r_n\\) (Row - <code>LINE_OFF</code>) / <code>LINE_SCALE</code> \\(c_n\\) (Column - <code>SAMP_OFF</code>) / <code>SAMP_SCALE</code> Table 2 : Normalization of RPC parameters <p>The GeoTIFF encoding of the RPC data in ICEYE data products is provided as a structure of 14 parameters described in Table 3.</p> <p>The equation to calculate the row and column number from the RPC values is given by:</p> \\[ r_n= \\frac{ \\sum_{i=1}^{20} LINE\\_NUM\\_COEF_i \u22c5 \\rho_i(P,L,H) }           { \\sum_{i=1}^{20} LINE\\_DEN\\_COEF_i \u22c5 \\rho_i(P,L,H) }      \\] \\[ c_n = \\frac{\\sum_{i=1}^{20} SAMP\\_NUM\\_COEF_i \u22c5 \\rho_i(P,L,H) }            {\\sum_{i=1}^{20} LINE\\_DEN\\_COEF_i \u22c5 \\rho_i(P,L,H) } \\] <p>Where the rational polynomial numerators and denominators are each a 20-point cubic polynomial function of the form:</p> RPC CUBIC POLYNOMIAL \\(\\sum_{i=1}^{20} C_i \u22c5 \\rho_i(P,L,H) =\\) \\(C_1\\) \\(+C_6 LH\\) \\(+C_{11} PLH\\) \\(+C_{16} P^3\\) \\(+C_2L\\) \\(+C_7 PH\\) \\(+C_{12} L^3\\) \\(+C_{17} PH^2\\) \\(+C_3P\\) \\(+C_8 L^2\\) \\(+C_{13} LP^2\\) \\(+C_{18} L^2 H\\) \\(+C_4H\\) \\(+C_9 P^2\\) \\(+C_{14} LH^2\\) \\(+C_{19} P^2 H\\) \\(+C_5LP\\) \\(+C_{10} H^2\\) \\(+C_{15} L^2P\\) \\(+C_{20} H^3\\) <p>Where coefficients \\(C_1\u2026C_{20}\\) represent the vector coefficients provided in the product metadata : <code>LINE_NUM_COEF_n</code>, <code>LINE_DEN_COEF_n</code>, <code>SAMP_NUM_COEF_n</code>, <code>SAMP_DEN_COEF_n</code>. The image coordinates are in units of pixels. The ground coordinates are latitude and longitude in units of decimal degrees and the height above geoid is in units of meters. The ground coordinates are referenced to WGS84. </p> NAME DESCRIPTION VALUE RANGE UNITS LINE_OFF Line Offset &gt;= 0 pixels SAMP_OFF Sample Offset &gt;= 0 pixels LAT_OFF Geodetic Latitude Offset -90 to +90 degrees LONG_OFF Geodetic Longitude Offset -180 to +180 degrees HEIGHT_OFF Geodetic Height Offset unlimited meters LINE_SCALE Line Scale &gt; 0 pixels SAMP_SCALE Sample Scale &gt; 0 pixels LAT_SCALE Geodetic Latitude Scale 0 &lt; LAT_SCALE &lt;= 90 degrees LONG_SCALE Geodetic Longitude Scale 0 &lt; LONG_SCALE &lt;= 180 degrees HEIGHT_SCALE Geodetic Height Scale HEIGHT_SCALE &gt; 0 meters LINE_NUM_COEFF (1-20) Line Numerator Coefficients. Twenty coefficients for the polynomial in the Numerator of the \\(r_n\\) equation. unlimited LINE_DEN_COEFF (1-20) Line Denominator Coefficients. Twenty coefficients for the polynomial in the Denominator of the \\(r_n\\) equation. unlimited SAMP_NUM_COEFF (1-20) Sample Numerator Coefficients. Twenty coefficients for the polynomial in the Numerator of the \\(c_n\\) equation. unlimited SAMP_DEN_COEFF (1-20) Sample Denominator Coefficients. Twenty coefficients for the polynomial in the Denominator of the \\(c_n\\) equation. unlimited Table 3 : RPC metadata parameters in ICEYE Products"},{"location":"foundations/geospatialAccuracy/#geometric-calibration-process","title":"Geometric Calibration Process","text":"<p>In order to monitor the geometric integrity of ICEYE images,  the satellites routinely collect images over ground-surveyed calibration sites around the world. Each site consists of a set of calibration point targets such as trihedral corner reflectors. The position, orientation and size of these features are carefully measured and maintained, and they are often provided by organizations such as NASA JPL as a free service to the geospatial community. ICEYE engineers compare the target ground coordinates derived from the image coordinates and known elevation to the precisely surveyed ground-truth coordinates. These calibration comparisons provide a statistical measure of the horizontal accuracy of ICEYE images by comparing calibration point target locations in terrain corrected imagery to ground truth measurements of each calibration point target. The root, mean square error (RMSE) is then calculated from all the measured location errors. Currently the ICEYE fleet is achieving a worst-case RMSE of 6 m. In actual practice elevation models used during image exploitation have vertical uncertainties, and feature signatures are not as precise as those of corner reflectors. Together these increase the horizontal error of image-derived ground coordinates.</p> <p>Info</p> <p>You can read about our latest geospatial accuracy validation campaign under Foundations/Validation</p> Figure 3: a 2.4m trihedral at the NASA JPL Rosamond Calibration Array[^4]."},{"location":"foundations/geospatialAccuracy/#references","title":"References","text":"<ol> <li> <p>OSGeo. RPCs in GeoTIFF. URL: http://geotiff.maptools.org/rpc_prop.html.\u00a0\u21a9</p> </li> <li> <p>National Imagery and Mapping Agency. The Compendium of Controlled Extensions (CE) for the National Imagery Transmission Format (NITF) Version 2.1. November 2000. URL: http://geotiff.maptools.org/STDI-0002_v2.1.pdf.\u00a0\u21a9</p> </li> <li> <p>QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/.\u00a0\u21a9</p> </li> <li> <p>R.J. Muellerschoen. The rosamond corner reflector array for sar calibration; past, present, future. 7th Nov 2017. Accessed 30 December 2021. URL: https://trs.jpl.nasa.gov/handle/2014/48764.\u00a0\u21a9</p> </li> </ol>"},{"location":"foundations/radiometric/","title":"Radiometric Considerations","text":""},{"location":"foundations/radiometric/#calibration-and-projection-conversion","title":"Calibration and Projection Conversion","text":"<p>The grey-scale values of SAR pixels do not directly correspond to a scientific measurement of the radar cross section of the associated ground area. In most cases this does not matter as users just want to view the spatial distribution of scattering objects and perhaps their relative radar reflectivity. However, SAR is a scientific instrument and some applications benefit from additional information about the ground's reflecting properties. These applications require the pixel\u2019s mean radar cross section, which is a true measure of the radar reflectivity. To access this information, a calibration factor needs to be applied to the pixel data. This next section provides information on how this is done. First, however, we need to have a short discussion about mean radar cross section.</p> <p>Caution</p> <p>Scan mode products are not currently calibrated. Whilst imagery is visually and spatially exploitable, there may be slight errors when converting image sample values to a mean RADAR cross section number.</p>"},{"location":"foundations/radiometric/#different-types-of-mean-radar-cross-section","title":"Different Types of Mean Radar Cross Section","text":"<p>An object's ability to scatter energy back towards the radar is called its radar cross section (RCS). It is not a fixed property and its value can change under different situations:</p> <ul> <li>The orientation of the object with respect to the RADAR</li> <li>The shape of the object</li> <li>The wavelength of the RADAR compared to the size of the object</li> <li>The ability of the object to reflect an electromagnetic field <ul> <li>This is called the  dielectric constant. Metal and water have high dielectric constants and reflect strongly, bare ground cover has much lower dielectric constant.</li> </ul> </li> <li>Polarization of the radar energy</li> </ul> <p>The RCS describes the relative reflecting cross-section of an object and its units are \\(m^2\\). RCS values are compared to the reference RCS of a hypothetical, perfectly-reflecting sphere with an area of 1 \\(m^2\\) (radius of 0.565 m) . RCS does not indicate the physical size of an object. For example, a metal plate with an area of 1 \\(m^2\\) oriented orthogonal to the incoming energy would have an RCS of 14,000 \\(m^2\\), while that of a small boat could be much less than 1 \\(m^2\\).  The symbol for RCS is by convention \\(\\sigma\\).</p> <p>In the real world, though, there are usually multiple scattering objects within a resolution cell (and we almost never encounter a 1 m metal sphere). Since a pixel in a SAR image contains many hundreds of scattering objects, it has a mean RADAR cross section. To distinguish this from a single-object RCS we use the symbol \\(\\sigma_0\\). </p> <p></p> Figure 1: The relationship between \u03b20, \u03b30 and \u03c30 <p>When illuminating the ground with a SAR sensor, the orientation of the surface compared to the resolution cell in the slant plane has a large impact on the mean RCS. The slant plane area of a pixel is constant, but when projected onto the ground, the pixel\u2019s area is elongated in range, and the mean RCS changes with incidence angle. This leads to a 'brightening effect' at lower incidence angles in the slant plane image as each pixel's ground area increases. This means that the observed mean RCS values in the SLC image represent the RADAR brightness rather than the terrain mean RCS \\(\\sigma_0\\). The RADAR brightness is denoted by \\(\\beta_0\\).</p> <p>Another noticeable and sometimes undesirable effect is that of local terrain topography. Terrain slopes that are oriented towards the satellite have a larger radar backscatter towards the RADAR than leeward slopes, which are inclined away from the radar and tend to reflect radar energy away. If the actual reflective properties of the terrain are needed, then this relief effect can be flattened to create a \\(\\gamma_0\\) image.</p> <p>The relationship between these three properties can be seen in Figure 1.</p>"},{"location":"foundations/radiometric/#calibration-correction","title":"Calibration Correction","text":"<p>The radiometric and beam calibration of ICEYE's sensors is performed using wide-area and consistent reflections from Amazon and Congo forests, while point target sites are used for impulse response and geolocation calibration. The conversion to radar brightness (\\(\\beta_0\\)) values is provided through the application of a calibration factor (CF) annotated as <code>calibration_factor</code> in the product metadata:</p> \\[ \\beta_0 = CF|DN_{SLC}|^2 \\] \\[ \\beta_0 = CF\\frac{|DN_{GRD}|^2}{\\sin(\\theta)} \\] <p>For amplitude scenes, a conversion to \\(\\sigma_0\\) has already been applied using the incidence angle calculated from the ellipsoid model. This simplifies the calculation of the radar backscatter to :</p> \\[ \\sigma_0 = CF |DN_{GRD}|^2  \\] \\[ \\sigma_{0dB} = 10\\log_{10}(\\sigma_0)  \\] \\[ |DN_{GRD}|^2 = |DN_{SLC}|^2 \\sin(\\theta) \\] <p>If the processing of \\(\\beta_0\\) is required from the amplitude image for further orthorectification to \\(\\sigma_0\\) or \\(\\gamma_0\\) values using a local DEM, then the conversion to radar brightness can be performed using the incidence angle information annotated in the metadata (see Ground Range To Incidence Angle Conversion). </p> <p>(\\(\\gamma_0\\)) values can be obtained using the \\(\\beta_0\\) values and a local digital elevation model. To assist in viewing analysis and projection, all amplitude products are projected onto the WGS84 Reference Ellipsoid.</p>"},{"location":"foundations/radiometric/#doppler-centroid-determination","title":"Doppler Centroid Determination","text":"<p>ICEYE SAR images are zero-Doppler based. This means that image pixels are focussed to the zero-Doppler (or broadside) position. The  radar beam covers a range of Doppler frequencies. Objects entering the beam have a high Doppler frequency and objects leaving the beam have a low Doppler frequency. This means that the centre point, called the Doppler Centroid (DC), can be used to find where the radar beam is pointing at any moment. The Doppler Centroid and the orbit state vector information are used to determine the precise azimuth location that the radar beam is pointing to.</p> <p>A set of DC coefficients are provided in the image metadata. For each azimuth location, the DC dependence in range is described using a polynomial function. The polynomial is valid from the near to the far range of the scene. The DC coefficients can be obtained by fitting the DC dependence in range from time as:</p> \\[ DC(t)=C_0\\left(t-t_{ref}\\right)^0+C_1 \\left(t-t_{ref}\\right)^1+C_2 \\left(t-t_{ref}\\right)^2+C_3 \\left(t-t_{ref}\\right)^3\\] <p>where the reference point in time \\(t_{ref}\\) corresponds to the mid-range time, and time varies between \\(t_{min}\\) and \\(t_{max}\\) corresponding to near range (first pixel time) and far range, respectively.  The mid-range time is calculated as:  </p> \\[ t_{ref}= (t_{min} +t_{max})/2=t_{min}+n_{rs}/(2f_{sr} )\\] <p>where \\(n_{rs}\\) is the number of range samples, and \\(f_{sr}\\) is the range sampling rate.</p>"},{"location":"foundations/slantToGround/","title":"Slant to Ground Conversion","text":""},{"location":"foundations/slantToGround/#ground-range-to-slant-range-conversion","title":"Ground Range To Slant Range Conversion","text":"<p>For ground projected products, the ground range to slant range (GRSR) conversion can be performed using the GRSR polynomial coefficients (<code>GRSR_Coefficients</code>) stored in the metadata. Once applied, the slant range location of a specific pixel in the ground range can be calculated from:</p> \\[ R_{slant}(j)=\\sum_{k=0}^{p+1} C_k ((j-1)\\delta_r)^k,\\qquad j=[1...n] \\] <p>Where:</p> <ul> <li>\\(R_{slant}(j)\\) is the slant range for the \\(j\\)-th ground range pixel</li> <li>\\(p\\) is the order of the ground range to slant range polynomial (<code>grsr_poly_order</code> in the metadata)</li> <li>\\(C_k\\) is the \\(k\\)-th polynomial coefficient</li> <li>\\(\\delta_r\\) is the ground range spacing (<code>range_spacing</code> in the metadata)</li> </ul>"},{"location":"foundations/slantToGround/#ground-range-to-incidence-angle-conversion","title":"Ground Range To Incidence Angle Conversion","text":"<p>The nominal incidence angle is the angle between a given slant range and the WGS84 ellipsoid. This should not be confused with the local incidence angle, which  is references to the local terrain. It can be calculated from the ground range using the <code>Incidence_Angle_Coefficients</code> in the metadata and:</p> \\[ \\theta(j)=\\sum_{k=0}^{p+1} C_k ((j-1)\\delta_r)^k,\\qquad j=[1...n] \\] <p>Where:</p> <ul> <li>\\(\\theta(j)\\) is the incidence angle for the \\(j\\)-th ground range pixel</li> <li>\\(p\\) is the order of the ground range to incidence angle polynomial (<code>incidence_angle_poly_order</code> in the metadata)</li> <li>\\(C_k\\) is the \\(k\\)-th polynomial coefficient</li> <li>\\(\\delta_r\\) is the ground range spacing (<code>range_spacing</code> in the metadata)</li> </ul>"},{"location":"foundations/OverviewOfSAR/beautifulEquations/","title":"The Beautiful Equations","text":"<p>The brute force method of real-aperture radar cannot produce high-resolution images. In synthetic-aperture radar we take advantage of the natural coherence of radar illumination to produce structured and consistent pulses. These enable the measurement of slight pulse-to-pulse phase shifts and the use of frequency-modulated chirps. The innovations of aperture synthesis, modulated waveforms and pulse compression produce images capable of a remarkable pixel resolution and which does not degrade as distance to the ground increases. </p> <p>Even though they are handled differently, the azimuth and range processes have a fundamental similarity:</p> <p> </p> <p>Azimuth resolution is based on phase variations across the collection interval. These are compared to known phase variations across that area to produce a long \u201csynthetic\u201d aperture and a resolution cell narrow in azimuth.</p> <p>Range resolution is based on frequency variations across the returned pulse. These are compared to known frequency variations in the reference pulse to produce a short \u201csynthetic\u201d pulse and a resolution cell narrow in range.</p> <p>These processes result in two of the most simple and powerful equations in all of remote sensing. They are the equations that describe the spatial resolution of a SAR sensor. They are The Beautiful Equations : </p> \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[ \\delta_{sr} = \\frac{c}{2B} \\] <p>with \\(\\delta_{az}\\) and \\(\\delta_{sr}\\) being the azimuth resolution and the slant range resolution respectively.</p>"},{"location":"foundations/OverviewOfSAR/noise/","title":"Separating Signals from Noise","text":""},{"location":"foundations/OverviewOfSAR/noise/#the-whisper","title":"The Whisper","text":"<p>As a radar pulse travels from the antenna to the ground surface its total power remains constant, but as it moves away from the antenna, it spreads out into space and its power density weakens. As shown in Figure 17, it is as if the \u201cskin\u201d of the pulse becomes thinner with distance. This weakening is dramatic; it decreases with the square of the distance from the antenna.</p> <p></p> Figure 17: Expanding Surface Area of a Pulse <p>Given that the ground might be 750 km from the antenna, the pulse is quite weak by the time it finally reflects from surface objects. This presents even more of a problem because only a portion of the weakened pulse is reflected toward the receive antenna, and then it has to travel all the way back, weakening again with the square of the distance. By the time the microwaves return to the antenna, they are microscopically faint. The antenna and radar receiver manage to detect, amplify, and record these echoes so that they can be processed into SAR resolution cells that span more than 100,000 brightness values. SAR is amazing.</p>"},{"location":"foundations/OverviewOfSAR/noise/#the-challenge-of-noise","title":"The Challenge of Noise","text":"<p>Those backscattered microwaves are so weak when they arrive at the antenna that they are perturbed by any noise sources that get mixed in with them. Noise is an artifact of random microwave emissions caused mostly by onboard sensor hardware. One of the tenets of remote sensing is that all objects emit electromagnetic energy based on their temperature. The thermal noise of heated receiver hardware spans wide swaths of the spectrum, including the microwave bands, and this competes with those whispering pulse echoes.</p> <p>As they struggle to capture those fading backscatter whispers, radar receivers also record random, interfering microwaves that they themselves produce. One of the disappointing aspects of the noise level is that it increases as range bandwidth increases. The large signal bandwidth that the receiver has to be capable of recording also lets more noise enter the receiver.</p> <p>One of the ways that noise is quantified for SAR sensors is called the Noise Equivalent Sigma Zero (NESZ). This parameter describes the noise floor of an image. All received signals have to be stronger than the NESZ value to rise above the noise level, so it is best for NESZ to be as low as possible. Images with high NESZ values look grainy.</p> <p>Unfortunately, NESZ is mystifying to SAR users who are not familiar with the dB language of engineering. Many users are confused by NESZ values like -20 dB, which actually indicates a fractional level of 1%. That is, an NESZ of -20 dB means the noise level is 1% as strong as a reference reflection from an idealized metal sphere. An NESZ of -17 dB would means the noise level is 2% as strong as the reference.</p> <p>System designers have to consider many competing imaging parameters to balance image quality, resolution and noise. For spacecraft, the best choices are increased average power, larger antennas, the use of high-quality receivers with low noise factors, steeper illumination angles, and lower orbits.</p>"},{"location":"foundations/OverviewOfSAR/overviewOfSAR/","title":"An Overview of SAR Imaging","text":"<p>Note</p> <p>This overview is excerpted with permission from The Essentials of SAR, by Thomas P. Ager<sup>1</sup>This comprehensive text was written for SAR users, not electrical engineers. It reviews the many interesting aspects of SAR and its uses that we cannot cover in this short overview.</p>"},{"location":"foundations/OverviewOfSAR/overviewOfSAR/#the-value-of-sar-imaging","title":"The Value of SAR Imaging","text":"<p>Synthetic aperture radar is well known as the imaging technique that can see through clouds and darkness. But SAR provides a number of other capabilities that are simply not available from optical sources. These include:</p> <ul> <li>High Resolution Independent of Distance: One of the outstanding characteristics of SAR is that it is capable of detailed resolution regardless of how far away the sensor is from the ground. SAR sensors can provide very high resolution, even from space.</li> <li>Variable Resolution and Coverage: SAR illumination is controlled electronically, and it can be manipulated to vary resolution and coverage. Images can be collected over small areas at fine resolution, over medium-sized areas at medium resolution or over large areas at coarse resolution.</li> <li>Precision Geolocation: SAR measurements are inherently precise. Properly calibrated images can have geolocation accuracy less than the scale of a single pixel for well-defined features.</li> <li>Coherent Illumination and Many Products: The controlled nature of SAR imaging enables the formation of images and many other products. These include sub-aperture image stacks that highlight glinting features and motion, dense elevation models, precise measurements of surface motion, and amplitude and coherent change images or series.</li> </ul>"},{"location":"foundations/OverviewOfSAR/overviewOfSAR/#radar-bands","title":"Radar Bands","text":"<p>There are several radar bands ranging from wavelengths at the millimeter level to a full meter (Table 1). X-Band has the best combination of cloud-penetration and resolution for spaceborne sensors.  In addition to atmospheric gases, there are larger atmospheric particles that scatter visible light but which are transparent to microwaves. In addition to penetrating clouds, X-band radar waves travel through smog, volcanic ash, and sandstorms. </p> BAND WAVELENGTH [CM] FREQUENCY [GHZ] ORIGIN UHF 30 to 100 1 to 0.3 Ultra High Frequency P 60 to 120 0.5 to 0.25 P for \"previous\", as the British used the band for the earliest radars, but later switched to higher frequencies. L 15 to 30 2 to 1 for 'Long Wave' S 7.5 to 15 4 to 2 for 'Short Wave'. Not to be confused with the radio band C 3.75 to 7.5 8 to 4 Originally for 'compromise' between S and X band X 2.5 to 3.75 12 to 8 Used in WWII for fire control, X for cross as in crosshair Ku 1.67 to 2.5 18 to 12 for \"Kurz-under\" K 1.11 to 1.67 27 to 18 German \"kurz\" means short, another reference to short wavelength Ka 0.75 to 1.11 40 to 27 Ka for \"kurz-above\" V 0.40 to 0.75 75 to 40 V for 'very' high frequency - not to be confused with VHF W 0.27 to 0.40 110 to 75 W follows V in the alphabet mm 0.10 to 0.27 300 to 110 millimeter wave Table 1 : Radar Bands"},{"location":"foundations/OverviewOfSAR/overviewOfSAR/#references","title":"References","text":"<ol> <li> <p>Thomas P. Ager. The Essentials of SAR: A Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities. 2021. ISBN-13 \u200f : \u200e 979-8512864487.\u00a0\u21a9</p> </li> </ol>"},{"location":"foundations/OverviewOfSAR/rangeResolution/","title":"Range Resolution","text":""},{"location":"foundations/OverviewOfSAR/rangeResolution/#fixing-range-resolution-by-synthesizing-a-short-pulse","title":"Fixing Range Resolution by Synthesizing a Short Pulse","text":"<p>In our discussions about aperture synthesis, we did not say anything about range resolution. This is because the \u201csynthetic aperture\u201d technique itself deals only with azimuth. It does not do anything to address the problem we saw with brute-force range resolution. Recall that this is one-half of the pulse length, which is the speed of light (\\(c\\)) times the pulse duration, \\(T\\): </p> \\[\\delta_{ra} = \\frac{c\\ T}{2}\\] <p>where \\(\\delta_{ra}\\) is the slant range resolution.</p> <p>Thus far, we have described our radar pulses as if they have a fixed frequency, like X-band pulses of 10 GHz frequency and a 3 cm wavelength. But most radars actually transmit chirped pulses in which the frequency changes (Figure 11). Notice how the wavelength of the green pulse is manipulated and varies from long to short</p> <p></p> Figure 11: Chirped Pulse <p>When we state the frequency or wavelength of a SAR sensor, those values typically apply at the mid-way time of the pulse. This is known as the radar center frequency or wavelength. The actual transmitted wavelengths are varied quite a bit on either side to form chirped pulses (Figure 12).</p> <p></p> Figure 12: Centre Frequency <p>There are many different pulse modulation techniques, but the chirp with a smoothly varying frequency is most common. A chirped pulse is easy to produce and since the total transmitted energy is a product of amplitude and duration, a long pulse can contain a substantial amount of energy without needing a large peak power.</p> <p>A chirped pulse enables high range resolution because its form is exactly specified and its echo is a reversed and weakened copy. The reflection has the same shape as the emitted signal, it\u2019s just flipped and has a much smaller amplitude. The two are compared in what is called a matched filter process. The known structure of the emitted pulse is compared to the echo at various locations. A calculation is performed, and if they are misaligned the result of this calculation is zero. At the exact location where they match there is a strong signal that indicates the match. A synthetic pulse that is narrow in range replaces the spread-out pulse (Figure 13).</p> <p></p> Figure 13: Range Compression <p>The width of the compressed pulse is based entirely on the bandwidth of the emitted pulse. The slant range resolution equation is transformed:</p> \\[ \\delta_{slant\\ range\\ chirp\\ compressed} = \\frac{c}{2B} \\] <p>This is a really beautiful equation. It is so simple and powerful. Resolution in range is entirely based on how much bandwidth we impart to chirped pulses, and like its azimuth counterpart it has nothing whatsoever to do with distance to the ground.</p>"},{"location":"foundations/OverviewOfSAR/rangeResolution/#slant-range-resolution-examples","title":"Slant Range Resolution Examples","text":"<p>So how much can we vary pulse frequency? Well, bandwidths can be made really large. Consider an X-band system capable of 300,000,000 cycles per second (300 MHz) of bandwidth. We can calculate resolution in the slant range:</p> \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300MHz} \\] \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300\\times10^8Hz} \\] \\[ \\delta_{sr} = 0.5 metres \\] <p>Plans for the next generation of ICEYE satellites include pulse bandwidths of 600 MHz and 1200 MHz. These will yield a slant range resolution cell of 0.25 meters and better from a satellite that is perhaps 750,000 meters away from the imaged area.</p>"},{"location":"foundations/OverviewOfSAR/rangeResolution/#ground-range-resolution","title":"Ground Range Resolution","text":"<p>The slant range is the distance between the antenna and the target, and that is the direction where range resolution is measured. To produce images along the ground surface, the pixels have to be projected to the \u201cground range\u201d from their original slant range orientation (Figure 14). This has the effect of elongating the pixels in range.</p> <p></p> Figure 14: Ground Range Resolution <p>The illustration shows the relationship between slant range resolution, shown in blue, and the length of the equivalent resolution distance along the ground, shown in green. When the illumination is steep, as in this example, the projection to the ground surface results in a much longer ground range cell. You can imagine what would happen as the steepness continued to approach nadir. This is exactly opposite to the situation with optical imaging resolution, which is best at nadir.</p> <p>Slant range and ground range resolution comparisons for two incidence angles are shown in Table 2. Notice the dramatic increase for the steeper illumination.</p> INCIDENCE ANGLE 30\u00b0 INCIDENCE ANGLE 60\u00b0 Slant Range 0.50m 0.50m Ground Range 1.00m 0.55m Table 2: Resolution comparison between slant range and ground range <p>While slant range resolution seems \u201cbetter\u201d than ground range resolution, keep in mind that it refers to the sensor\u2019s ability to discriminate features along the oblique path of the energy. Most of the features we care about lie along the ground surface, and ground range resolution is a useful way to describe image resolution.</p>"},{"location":"foundations/OverviewOfSAR/remarkableStory/","title":"The Remarkable Story of Synthetic Aperture Radar","text":""},{"location":"foundations/OverviewOfSAR/remarkableStory/#improving-azimuth-resolution-by-synthesizing-a-long-antenna","title":"Improving Azimuth Resolution by Synthesizing a Long Antenna","text":"<p>It takes a long antenna to create narrow radar beams, but the aperture itself does not have to be a giant physical antenna. Instead, a \u201csynthetic\u201d aperture can be created from a small antenna and a linear extent of recording locations. Figure 7 shows a radar antenna sequentially emitting a series of pulses, like a microwave strobe light, and recording the echoes from a string of receive positions.</p> Figure 7: Linear Extent of Recording Locations <p>In the SAR technique all of the measurements are stored and later processed together. It is as if they were collected from one long antenna equal in length to the extent of the sensor locations that received the echoes. Synthetic Aperture Radar is a post-processing scheme applied to data collected by a standard radar antenna and receiver. </p>"},{"location":"foundations/OverviewOfSAR/remarkableStory/#stripmap-and-spotlight-apertures","title":"Stripmap and Spotlight Apertures","text":"<p>There are a few methods to illuminate the ground in SAR imaging. These collection modes trade off resolution and coverage in different ways. To establish how we can simulate long apertures we\u2019ll contrast the two most common forms of SAR imaging: stripmap and spotlight. In stripmap mode the pulses are sent out at a constant angle, usually broadside to the flight direction. In this case, the length of this simulated aperture (\\(L\\)) is the same as the width of the beam on the ground (Figure 8). Wider beams produced by smaller antennas mean longer apertures and better azimuth resolution. This directly contrasts with the real-aperture radar of SLAR where the beam was kept as narrow as possible to obtain good resolution.</p> <p></p> Figure 8: Stripmap Synthetic Aperture <p>The spotlight form of SAR varies the boresight angle in the azimuth direction to illuminate a fixed ground location (Figure 9). This technique greatly increases the synthetic-aperture length and offers excellent azimuth resolution, at the cost of limited ground coverage. At ICEYE we are capable of illuminating a fixed spot for as long as 30 seconds. Given the velocity of low-earth orbits (7.5 km/sec), this yields a synthetic aperture more than 225 kilometers long !</p> <p></p> Figure 9: Spotlight Synthetic Aperture"},{"location":"foundations/OverviewOfSAR/remarkableStory/#phase-history-data-and-sar-azimuth-resolution","title":"Phase History Data and SAR Azimuth Resolution","text":"<p>We can create long \u201csynthetic\u201d apertures because radar illumination is coherent. That is, the sensor controls the structure of the transmitted pulses and they all have the same form. It emits pulses and measures the details of each echo: time, strength and \u201cphase\u201d. Phase refers to the position of the wave in its cycle, denoting whether it is at its peak, trough or somewhere in between.</p> <p>The SAR antenna moves only slightly from pulse to pulse. It turns out that the change in location must be less than one-half the antenna length. But this small change in location causes the successive measurements of the range to some object to change as well. The slight change in position imparts a slight change in range. Since the phase is dependent on the range, the small change in adjacent sensor locations also imparts a slight change in phase. These phase changes form a pattern across the aperture, which changes depending on the azimuth location of a ground feature. The record of all the changing phases for all the scatterers in the scene is called phase history data. For a particular object, this is the \u201chistory\u201d of how phase changed from one receive location to the next.</p> <p>Given carefully measured sensor locations, the phase histories for each location across the scene are predictable. The azimuth position of each scatterer can be calculated by comparing the predicted phase pattern of some location to the measured phase history pattern for that point. This is the essence of azimuth resolution. Phase history data and their reference patterns are compared to discriminate the azimuth position of scatterers in the scene.</p> <p>Now that we have that huge aperture and the equation for azimuth resolution becomes: </p> \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] <p>where \\(\\delta_{az}\\) is the SAR azimuth resolution.</p> <p>This equation is gorgeous. It says that azimuth resolution is based on the wavelength of our radar waves and the change in the integration angle (\\(\\Delta \\theta\\)) while the point was being imaged (Figure 10). Resolution improves when the wavelength is small and the integration angle change is large.</p> <p></p> Figure 10: Spotlight Synthetic Aperture Angle <p>Now let\u2019s use SAR with an integration angle change of 0.07 radians (4.5\u00b0). This is reasonable because the current operational performance of ICEYE's spotlight mode can easily exceed this angle. </p> \\[\\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[\\delta_{az} = \\frac{3 cm}{2 \\times 0.07} \\] \\[\\delta_{az} = 0.21m \\] <p>For stripmap mode the azimuth resolution equation reduces to a simpler form, where \\(D_A\\) is the length of the antenna in the azimuth direction:</p> \\[\\delta_{az} = \\frac{D_A}{2} \\] <p>This is just a special stripmap case of the more general equation, but it seems to imply that we could make the antenna really small to achieve good stripmap resolution. While this is literally true, the small size of the antenna would lessen the total power that could be transmitted and also degrade the ability to record the weak backscattered echoes. Noise would increase significantly. It would also require the PRF to get unreasonably large because a pulse is required at least every one-half antenna length.</p> <p>Stripmap cannot support high-resolution SAR. For that we need to steer the beam during illumination to increase the synthetic aperture, as with a spotlight collection. This mode is capable of fine resolution and it can use a larger, and therefore more powerful and sensitive antenna.</p>"},{"location":"foundations/OverviewOfSAR/remarkableStory/#something-is-missing","title":"Something Is Missing","text":"<p>These elegant equations are an astonishing statement about resolution, but it is even more amazing when we consider what is missing. Notice that the SAR azimuth resolution equations do not include a term for distance. Use it on an aircraft or move it all the way out into space, and azimuth resolution does not change.</p> <p>Of course, distance does impact signal strength. When the sensor is further away, the signal strength weakens dramatically and this poses serious challenges to the SAR imaging process. We will not discuss this issue in this overview, but we can say here that radar antennas are very sensitive. Spaceborne SARs successfully record very weak backscatters.</p>"},{"location":"foundations/OverviewOfSAR/sarProcessing/","title":"SAR Processing Overview","text":""},{"location":"foundations/OverviewOfSAR/sarProcessing/#the-sar-processing-flow-and-its-products","title":"The SAR Processing Flow and Its Products","text":"<p>SAR image generation begins with the emission of thousands of coherent pulses and the decomposition of each echo into raw measurements of time, amplitude and phase. The first part of the processing flow is called Phase History Processing because it accounts for the changes over time of the phase values of each scatterer. Phase history data are focused into the azimuth and range components of each resolution cell to produce an image product called a \u201ccomplex image\u201d (Figure 15).</p> <p></p> Figure 15: The SAR Processing Flow and Its Products"},{"location":"foundations/OverviewOfSAR/sarProcessing/#the-complex-image","title":"The Complex Image","text":"<p>Info</p> <p>By the way, you will hear SAR engineers refer to the two parameters of a complex image as \u201cIn-Phase\u201d and \u201cQuadrature\u201d. These are just another way to describe the complex values.</p> <p>The left image in Figure 16 is a ICEYE amplitude image of agricultural fields. In this image each pixel has a brightness value assigned to it. This is what many people consider to be the base SAR product, but this is really only half of the full image. The SAR processor calculates the average phase value for each pixel as well. The matching \u201cphase image\u201d of that same scene is on the right in the figure. The combination of these two images is called a complex image, in which every pixel has amplitude and phase values. We use the term \u201ccomplex\u201d because the pixels are described by a mathematical construct called a complex number, where every number has two components.</p> <p></p> Figure 16: Amplitude and Phase Structure of a Complex Image <p>Of course, phase data are not useful for direct human interpretation. And while they may look like random noise, phase pixels are a unique and valuable aspect of SAR imaging. Phase data can be used to manipulate the synthetic aperture in different ways to extract useful information that is not available from amplitude images. Moreover, changes in the phase measurements of the same object on different images can be used to detect small surface structure characteristics. In the next section we\u2019ll discuss how we can use phase data to refine images and create other products.</p>"},{"location":"foundations/OverviewOfSAR/sarProcessing/#sar-products-derived-from-complex-data","title":"SAR Products Derived from Complex Data","text":""},{"location":"foundations/OverviewOfSAR/sarProcessing/#amplitude-images","title":"Amplitude Images","text":"<p>Info</p> <p>You should also be aware that an engineering calculation called \u201cdetection\u201d converts in-phase and quadrature values to amplitude values. Engineers often refer to SAR amplitude images as \u201cdetected\u201d images.</p> <p>An amplitude image is certainly the most common SAR product, but you need to appreciate that this image is produced for human viewing and analysis. It is not the core image product. Amplitude images do not contain any phase information. Furthermore, the version of the amplitude image used for human viewing is not a direct copy of the amplitude values in a complex image. This is because radar sensors record an enormous span of brightness levels for each complex pixel. The maximum intensity of amplitude in a complex image is usually more than 100,000 times (50 dB) the minimum intensity, and for the best-quality images with bright targets, it is much greater. ICEYE images are produced with 16 bits of dynamic range per pixel (65536 gray levels) but even this is not sufficient to record the full dynamic range of SAR.</p> <p>As valuable as they are, amplitude images have no phase data and they lose much of the dynamic range of complex pixels.  You can imagine the growing potential for computers and algorithms to process those complex pixels in ways the human visual system cannot.</p>"},{"location":"foundations/OverviewOfSAR/sarProcessing/#multi-look-amplitude-images","title":"Multi-look Amplitude Images","text":"<p>One way in which we can use complex data is to produce different versions of the seemingly simple amplitude image. One common form of an amplitude image, for example, is called a multi-look image. Consider that azimuth and range resolution are handled independently. One is based on the length of the synthetic aperture and the other is based on the signal bandwidth, and sometimes these are quite different in magnitude. It is common for azimuth resolution to be collected at a higher fidelity than range resolution. If a full-resolution image were produced from such data it would look compressed in range. To view the image in a more natural aspect we need to \u201csquare the pixels\u201d so that the range and azimuth scales are the same. </p> <p>Info</p> <p>Speckle is a grainy, noise-like feature of SAR images. It is caused by the coherent nature of SAR illumination. The reflections from small scatterers within a resolution cell combine constructively and destructively to brighten or darken the returns.</p> <p>This is done by manipulating the synthetic aperture into smaller sub-apertures and then combining them. The sub-apertures are called \u201clooks\u201d and they each produce an image with lower azimuth resolution. This may sound disappointing, but when these individual sub-aperture images are combined, they form a multi-look image in which the noisy effect of speckle is reduced.  Complex images are stored at full-resolution and are called single-look complex (SLC) images. Amplitude images are typically multi-looked in azimuth using two to 12 sub-apertures. If range resolution exceeds azimuth resolution a similar multi-look process can be applied in the range dimension.</p>"},{"location":"foundations/OverviewOfSAR/sarProcessing/#sub-aperture-stack-or-video-image","title":"Sub-aperture Stack or Video Image","text":"<p>Suppose we take the aperture splitting further and create six or seven segments to produce multiple sub-aperture images. One advantage of this sub-aperture stack is that it can indicate glints that are bright in only a portion of the full aperture. This signature might be washed out on the full-resolution image by the bulk of the aperture in which there was no glinting, but it can be very noticeable in one of the low-resolution sub-apertures. Glints tend to be important signatures because they are usually caused by human-made features. We could even loop the stack like a short movie, or SAR video image, to look for such glints and moving objects. This product works best for long spotlight exposures of ten seconds or more.</p>"},{"location":"foundations/OverviewOfSAR/sarProcessing/#amplitude-and-coherent-change-images","title":"Amplitude and Coherent Change Images","text":"<p>Perhaps the most useful SAR products are the amplitude and coherent change images (ACI, CCI). Two or more images of the same site are collected at different times to detect scene changes. For ACD only the brightness values are compared, while CCD uses phase data.</p> <p>In order for change detection to work, the images have to be collected from nearly the same location in space with similar illumination geometries. For ACD the two images can be overlaid in the complementary colors (eg red and cyan). In this way, features with similar backscatters will be gray, but features with backscatters that changed during the imaging period will appear in one of the two colors. It is conventional for the first image to be displayed in red and the second in cyan. If something on the ground changes between the two collections you will see whichever color signature is dominant.</p> <p>A mnemonic is used to help interpret ACD products: \u201cRed is fled. Blue is new\u201d. That is, a red signature indicates a feature that was present on the first image but left the scene prior to the second image, and a blue signature indicates a feature that appears only on the second image. This mnemonic is an easy way to help remember the order of the images, but appreciate that the second image is actually cyan, not blue. The intentional sloppiness of the mnemonic is acceptable here because verbal precision would ruin the rhyme.</p> <p>In contrast to amplitude change detection, CCD compares the phase values of two nearly identical images taken at different times. CCD is far more sensitive to changes because it is based on phase differences rather than pixel brightness differences and, as we know, phase is measured to within a small fraction of a wavelength. The collection constraints to ensure image-to-image coherence are tighter for CCD than ACD.</p> <p>When the collection parameters are nearly identical, the phase values are also nearly identical, and any changes are due to backscatter differences at a scale of less than one wavelength. It is typical for CCD images to display pixels where phase is consistent in white and the pixels where the phase has changed are dark. These are areas where the two images have \u201cdecorrelated\u201d, or lost phase consistency, due to some subtle change in the scene.</p>"},{"location":"foundations/OverviewOfSAR/sarProcessing/#other-multi-image-sar-products","title":"Other Multi-image SAR Products","text":"<p>The amplitude and phase data of SAR images can be combined to produce other useful products that are too numerous to describe in detail in this overview. These include digital elevation models derived from pixel brightness values or phase data, millimeter-level surface motion measurements derived phase comparisons of sets of matching images, and automated detections of ships, oil spills and other features. Once constellations of small SARs are established it will be possible to monitor any site in the world with large stacks of exactly matching images whose consistent signatures are linked to known ground features. These images could be collected within hours of each other and they will be the basis of intelligent site monitoring services that will not only detect changes, but which will also say what has changed and how it has changed.</p>"},{"location":"foundations/OverviewOfSAR/simpleFormOfImaging/","title":"A Simple Form of Radar Imaging","text":"<p>As seen in Figure 1 the radar antenna emits a series of pulses toward the ground where they are scattered in many directions. The sensor records the \u201cbackscatter\u201d, which is the portion reflected toward the antenna. It measures the strength of the echo and the time it took for the pulse to travel to the ground and back.</p> <p></p> Figure 1: Pulse Transmission and Backscatter <p>Signal strength corresponds to pixel brightness and the timing provides range information. The range is one-half the total travel time. In the equation below, \\(\\Delta T\\) is the travel time and \\(c\\) is the speed of light:</p> \\[Range = \\frac{\\Delta T\\ c}{2}\\]"},{"location":"foundations/OverviewOfSAR/simpleFormOfImaging/#side-looking-illumination","title":"Side-Looking Illumination","text":"<p>Since the pixels of a radar imaging system are placed on the image based partly on their range, the antenna cannot illuminate the ground in a vertical orientation. If it did, features on the same imaging line at equivalent angles off nadir would have identical ranges, like the two purple diamonds in Figure 2, and they would occupy the same pixel location.</p> <p></p> Figure 2: Vertical Illumination <p>Radar imaging must be side-looking so that ground points from the near to far range have different range values (Figure 3). The illumination is typically broadside, or perpendicular, to the flight direction. </p> <p></p> Figure 3: Side-Looking Illumination"},{"location":"foundations/OverviewOfSAR/simpleFormOfImaging/#radar-angles","title":"Radar Angles","text":"<p>The angles associated with radar illumination are shown in Figure 4, which is based on a spherical earth surface. Most radar imaging is broadside to the flight direction, but some systems can collect off-broadside in a squinted orientation. The angle down from the local level at the sensor is called the depression angle. The angle between the line-of-sight ray and the local vertical is the incidence angle. The angle between the tangent to the surface and the line of sight is the grazing angle. Note that the incidence and grazing angles are complements in that they form a right angle when combined. This means that a 60\u00b0 incidence angle is the same as a 30\u00b0 grazing angle.</p> <p></p> Figure 4: Radar Imaging Angles"},{"location":"foundations/OverviewOfSAR/simpleFormOfImaging/#side-looking-airborne-radar","title":"Side Looking Airborne Radar","text":"<p>The first useful radar imaging technique was a form called Side-Looking Airborne Radar (SLAR) (Figure 5). The image is built up via the forward motion of the antenna, one line at a time. The pulses are emitted at a rate called the pulse repetition frequency (PRF), which can range from a few hundred pulses each second for airborne systems to thousands each second for spacecraft. In the SLAR technique, the individual pulses create each image line. The angular width of the pulse on the ground along the direction of flight, or azimuth direction, determines one component of resolution. The range measurements are collected in the \u201cslant range\u201d direction, and range variations to different objects form the second dimension of resolution.</p> <p></p> Figure 5: Side-Looking Airborne Radar <p>SLAR was used the early days of radar imaging but it had serious limitations. Range resolution was one-half the length of the pulse in the range direction. Since the pulses are emitted at light speed, even a very brief pulse of one-millionth of a second would be 300 meters long and produce range resolution of 150 meters (Figure 6).</p> <p>Azimuth resolution was based on the angular width of the pulse in the azimuth direction (\\(\\beta\\)). Long antennas create narrow beams, but the beam spreads out from the antenna to the distant ground surface. Antennas cannot be made long enough to produce good azimuth resolution, and SLAR produced images with resolutions in the hundreds of meters, even from aircraft. This is why the brilliant concept of synthesizing a long antenna from the actions of a small one was developed. We call this Synthetic Aperture Radar.</p> <p></p> Figure 6: SLAR Pulse Dimensions"},{"location":"foundations/OverviewOfSAR/theInnovation/","title":"The ICEYE Innovation","text":"<p>In this overview of SAR, we have discussed several remarkable capabilities beyond its famous ability to penetrate clouds. These include image resolution independent of distance, electronic beam control to vary resolution and coverage, pristine geolocation, and the natural ability to measure phase to within a small fraction of a wavelength. We\u2019ve seen that SAR pixels have both amplitude and phase, and from these we can produce many useful products. At ICEYE, we have developed an innovative way to incorporate all of these aspects of SAR in our small and adaptable systems. We are launching a full constellation of small SARs, and we\u2019ll upgrade them routinely to better image this ocean planet.</p>"},{"location":"foundations/validation/geospatialValidation/","title":"Verification and Validation of Geospatial Measurements","text":"<p>Verification and validation of geospatial measurements on SAR imagery is an integral part of ICEYE's quality control process. Below you will find our latest validation report. More reports will be added as they become available.</p>"},{"location":"foundations/validation/geospatialValidation/#method","title":"Method","text":"<p>'Geolocation' is the name of the process used to find the univocal correspondence between image pixels and their position on the Earth's surface. In this section we introduce a geolocation algorithm that we use to measure the geospatial accuracy of ICEYE imagery. </p> <p>The purpose of geolocation is to calculate the difference between an observed objects's location measured from SAR imagery and its actual, ground-truth, location. The true 'ground truth' location of an object can be specified in a geocentric rotating coordinate system such as ECEF (Earth-centred, Earth-fixed) as having the coordinate \\(R_o=[x_o,y_o,z_o]\\). The satellite's location in this same reference system changes with time and is given by \\(R_s(t)=[x_s(t),y_s(t),z_s(t)]\\) and has a velocity given by \\(V_s(t)=[v_{sx}(t),v_{sy}(t),v_{sz}(t)]\\). From these, the slant range from the satellite to the object as a function of time \\(s_r(t)\\) is given by (1):</p> \\[ s_r(t) = (x_s(t) - x_o)^2 + (y_s(t)-y_o)^2 + (z_s(t)-z_o)^2 \\qquad (1) \\] <p>As the satellite transits past the object, the phase of its radar response varies providing the object's signature with a characteristic spatial Doppler frequency shift given by (2):</p> \\[ f_D(t) = - \\frac{2}{\\lambda s_r(t)} (\\mathbf{R_s(t)} - \\mathbf{R_o}) \\cdot (\\mathbf{V_s(t)} - \\mathbf{V_o}) \\qquad (2) \\] <p>Geometrically, the objects position is found by calculating the intersection between a sphere of radius that corresponds to the range of the object (1), a cone defined by the Doppler frequency at a certain time (2) and the reference ellipsoid (see Fig. 1). There are two locations where all three parametric surface meet - one on the left side of the sensor and one on the right, which is why SAR systems only image on one side.</p> <p></p> Figure 1: The location of an object in a SAR image is defined by the intersection of a range-sphere, a Doppler-cone and a reflecting-surface. <p>To calculate the geolocation accuracy of a SAR image the following steps are performed :</p> <ol> <li>The first step is the selection of calibration objects, usually corner reflectors, each with a known geographical location. For this purpose both publicly available corner reflectors and ICEYE's own dedicated corner reflectors are used. The object position \\(R_o=[x_o, y_o, z_o]\\) is used in the following step to calculate the expected target position in range and azimuth \\((I_r,I_a)\\) in the image.</li> <li>The second step is to determine the location of the sensor as a function of time by using the orbital state vectors provided in the metadata of each image.  ICEYE orbital state vectors provide position and velocity every second which does not have the fidelity to accurately locate each azimuth location in the image and so the state vectors are interpolated.</li> <li>The expected range and azimuth position of the corner reflector \\((I_r,I_a)\\) is then calculated using Eq. (1) and Eq. (2). The azimuth position of the object corresponds to the time of closest approach between the object and the sensor which is the instant that the Doppler frequency shift of the object observed from the sensor is zero. (By convention ICEYE SAR images are processed to the zero Doppler location/time). The expected range position is calculated using the distance \\(\\mathbf{R_s(t)}-\\mathbf{R_o}\\) when the Doppler shift is zero. ie:</li> </ol> \\[  - \\frac{2}{\\lambda s_r(t)} (\\mathbf{R_s(t)} - \\mathbf{R_o}) \\cdot (\\mathbf{V_s(t)} - \\mathbf{V_o}) = 0 \\qquad (3)  \\] <ol> <li>The measured range and azimuth position \\((M_r,M_a)\\) of the calibration object is calculated by oversampling the SAR image and fitting the expected two-dimensional imaging response function to the object and measuring the location of the peak. This can be seen in Figure 2. The geolocation error in pixels is given by: </li> </ol> \\[ \\begin{aligned} \\Delta R_g = I_r - M_r \\\\ \\Delta A_z = I_a - M_a  \\end{aligned} \\qquad (4) \\] <p></p> Figure 2: The sensors location accuracy is determined by comparing the measured image location to the actual location of a calibratioin object."},{"location":"foundations/validation/geospatialValidation/#rosamond-validation-april-2022-spotlight-stripmap","title":"Rosamond Validation - April 2022: Spotlight &amp; Stripmap","text":""},{"location":"foundations/validation/geospatialValidation/#test-site","title":"Test Site","text":"<p>During April 2022, a geolocation validation was performed using the Rosamond Corner Reflector Array (RCRA) area in California, USA<sup>1</sup>. At this location there are 38 Corner Reflectors, each in one of four dimensions (0.7 m, 2.4 m, 2.8 m and 4.8 m). Fig. 3.</p> <p></p> Figure 3: Test site in the Rosamond Corner Reflector Array"},{"location":"foundations/validation/geospatialValidation/#datasets","title":"Datasets","text":"<p>The geolocation accuracy was assessed based on 167 spot images taken between 22 August 2019 and 15 March 2022, and 304 strip images taken between 10 March 2019 and 01 June 2022. Fig. 4. shows a histogram with the number of images and their distribution among the different satellites operating in the ICEYE fleet over that period. Although there are fewer images for the newer satellites (the ones with larger number in the name), this report will continue to be updated to include more images from all satellites.</p> <p></p> Figure 4: Number of images used in this analysis across the ICEYE fleet."},{"location":"foundations/validation/geospatialValidation/#results","title":"Results","text":"<p>An overview of the validation results is provided in Table 1. The overall geolocation accuracy in both the range direction and azimuth direction is better than 4m RMSE and is consistent between the two imaging modes. The results also show a ~3.0m systematic bias in the range direction, and about ~0.8m bias in the azimuth direction. The cause of these biases are currently under investigation and will be addressed in the following months. The detailed results can be found here for Spotlight images and here for Stripmap images (see also this this description of the columns in the results).</p> Imaging Mode #Images #CR Observations Range Error: \u03bc\u00b1\u03c3 (m) Range Error: RMSE (m) Azimuth Error: \u03bc\u00b1\u03c3 (m) Azimuth Error: RMSE (m) Spotlight 167 2354 -2.8\u00b11.7 3.2 -0.9\u00b13.2 3.3 Stripmap 304 3388 -3.2\u00b11.8 3.6 -0.7\u00b13.1 3.1 Table 1: ICEYE fleet geolocation accuracy assessment results March 2019 to June 2022. <p>The measured geolocation accuracy for each satellite for Spot images is shown in Fig. 5, and from Strip images is shown in Fig. 6.</p> <p></p> Figure 5: Geolocation error: Spot images August 2019 to March 2022. <p></p> Figure 6: Geolocation error: Strip images March 2019 to June 2022."},{"location":"foundations/validation/geospatialValidation/#conclusions","title":"Conclusions","text":"<p>The measurement of geospatial accuracy of SAR images is subject to multiple error sources, including uncertainties in terrain height, orbit knowledge, atmospheric propagation model, and sensor related uncertainties such as position along track, lever arms between GPS and antenna phase center, timing across track, and thermal variations. In some cases, orbit positional errors may introduce gross geospatial errors (larger than 50m in this analysis). Such errors are identified by ICEYE's QC procedures and are reprocessed before customer delivery. As such those images are currently not included in this analysis.</p> <p>ICEYE\u2019s satellite capabilities are constantly evolving, with older satellites being more prone to on-board timing errors. Newer satellites have improved on this and thus have better geospatial accuracy.</p> <p>The geolocation accuracy from stripmap images are very similar to that from spotlight images in both range and azimuth directions.</p> <p>The results also show a clear systematic bias in both range and azimuth directions that will be addressed in the following months to improve these values further.</p>"},{"location":"foundations/validation/geospatialValidation/#references","title":"References","text":"<ol> <li> <p>R.J. Muellerschoen. The rosamond corner reflector array for sar calibration; past, present, future. 7th Nov 2017. Accessed 30 December 2021. URL: https://trs.jpl.nasa.gov/handle/2014/48764.\u00a0\u21a9</p> </li> </ol>"},{"location":"productFormats/csi/","title":"Colorized Sub-aperture Image","text":"<p>Info</p> <p>Colorized Sub-aperture Images are only produced when the Dwell collection mode is utilized</p>"},{"location":"productFormats/csi/#colorized-sub-aperture-image-csi","title":"Colorized Sub-aperture Image (CSI)","text":"<p>Colorized Sub-aperture Images are made by coloring the backscatter received for different sub-apertures and combining it into a single product. The colors denote the direction that a point in the image predominantly scatters in. The collection time is split into individual sub-apertures. Each sub-aperture is individually colored from red at the start of the collection to blue at the end of the collection. A composite image is made by combining all the sub-apertures and it can be interpreted as follows:</p> <ul> <li>Isotropic scatterers: Objects on the ground that scatter an equal amount in all directions have an equal brightness in all directions that they are looked at. When the individually colored sub-apertures from these areas are added together, each individual color contribution is roughly the same making their appearance in the CSI image a grey-scale - like a normal SAR image. Examples of isotropic scatters are grass, trees and water.</li> <li>Anisotropic scatterers: Objects that have a dominant reflection in one particular direction will retain that color after all the sub-apertures are combined. Objects that have preferential scattering orientations usually have flat surfaces and/or sharp angles and indicate that they are human-made. Objects that are partially obstructed by vegetation or tree canopy will also be highlighted in a dominant color. As the human eye is very good at picking out colors from grey tones, our eyes are naturally drawn to the human-made features.</li> </ul> <p></p> Figure 1: Detail of a Colorized Sub-aperture Image (CSI) showing vehicles and human made infrastructure displayed in a dominant color.  <p>ICEYE is able to produce Colorized Sub-aperture Images (CSI) only for certain types of collection characteristics such as Dwell. In the case of Dwell, each CSI is made up of 13 sub-apertures, each containing the data acquired during less than 2 seconds. The total duration of a Dwell acquisition is 25 seconds. The exact time, duration, color and satellite location for each sub-aperture is available as  metadata in the GeoTIFF product file. </p> <p></p> Figure 2: Detail of a Dwell acquisition and how each color is assigned when forming a Colorized Sub-aperture Image (CSI)."},{"location":"productFormats/csi/#dwell-sub-apertures-and-colors","title":"Dwell sub-apertures and colors","text":"<p>The nominal duration and color for each sub-aperture in a Dwell collection is documented in the table below. Please see Notes and Explanations for more detailed information as well as corresponding values in the image metadata. </p> Sub-aperture Nominal Duration [sec] Color (RGB 0-1) Color 1 1.91 1.0000, 0.0000, 0.0000 <p>\u2588\u2588</p> 2 1.91 0.9994, 0.0333, 0.0000 <p>\u2588\u2588</p> 3 1.91 0.9864, 0.1644, 0.0000 <p>\u2588\u2588</p> 4 1.91 0.8944, 0.4472, 0.0000 <p>\u2588\u2588</p> 5 1.91 0.6000, 0.8000, 0.0000 <p>\u2588\u2588</p> 6 1.91 0.2334, 0.9724, 0.0000 <p>\u2588\u2588</p> 7 1.91 0.0000, 1.0000, 0.0000 <p>\u2588\u2588</p> 8 1.91 0.0000, 0.9724, 0.2334 <p>\u2588\u2588</p> 9 1.91 0.0000, 0.8000, 0.6000 <p>\u2588\u2588</p> 10 1.91 0.0000, 0.4472, 0.8944 <p>\u2588\u2588</p> 11 1.91 0.0000, 0.1644, 0.9864 <p>\u2588\u2588</p> 12 1.91 0.0000, 0.0333, 0.9994 <p>\u2588\u2588</p> 13 1.91 0.0000, 0.0000, 1.0000 <p>\u2588\u2588</p> <p></p> Figure 3: Example of a concentration of vehicles and equipment highlighted in a Colorized Sub-aperture Image (CSI)"},{"location":"productFormats/csi/#container-format-and-metadata","title":"Container format and metadata","text":"<p>The CSI format uses a regular GeoTIFF container so the image can be viewed by any regular (or geospatial) image viewer. Important metadata on each of each of the sub-apertures and how the CSI is formed is available in the GeoTIFF. GeoTIFF metadata can be accessed by multiple methods including:</p> <ul> <li>Using the gdal library and running the command <code>gdalinfo filename.tif</code> (for example: <code>gdalinfo ICEYE_X2_VID_SLED_1906432_20231020T110813.tif</code>)  </li> <li>Using the open source application QGIS and selecting Raster \u2192 Miscellaneous \u2192 Raster information \u2192 Run </li> </ul> <p></p> Figure 4: Example of Colorized Sub-aperture Image (CSI) of an airport highlighting human-made structures and equipment in dominant colors"},{"location":"productFormats/csi/#key-csi-geotiff-metadata","title":"Key CSI GeoTIFF Metadata","text":"Metadata Element\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Description Type Unit <code>FRAME_COLOURS</code> RGB 0-1 color code of each sub-aperture. List of float64 triplets RGB 0-1 <code>FRAME_DURATION</code> Duration of SAR data collection for each sub-aperture. List of float64 seconds <code>FRAME_MID_TIME</code> Timestamp at the center of each sub-aperture. Number of seconds since the beginning of the SAR collection. List of float64 seconds <code>FRAME_POS</code> Satellite position at the center of each sub-aperture List of float64 triplets ECEF coordinates <code>FRAME_VEL</code> Velocity vector of the satellite at the center of each sub-aperture List of float64 triplets meters per second"},{"location":"productFormats/csi/#notes-and-explanations","title":"Notes and Explanations","text":"<ol> <li>Sub-aperture duration: The duration of the sub-aperture varies slightly depending on specific collection characteristics. The actual duration value is available in the GeoTIFF metadata.</li> <li>Sub-aperture colors:  Nominal colors for each sub-aperture are listed in the metadata table  to facilitate interpretation. The normalized RGB color contribution of each sub-aperture is available in the GeoTIFF metadata element FRAME_COLOURS.</li> </ol>"},{"location":"productFormats/grd/","title":"Amplitude Image","text":""},{"location":"productFormats/grd/#ground-range-detected-","title":"'Ground Range Detected' - \ud83d\ude35\u200d\ud83d\udcab?","text":"<p>After complex images are processed into amplitude images and projected to the ground plane they retain the native range-azimuth sensor orientation. The commonly used terms for these range-azimuth amplitude images include some combination of 'detected', 'ground range' and 'multi-look'. At ICEYE these have been called Ground Range Detected (GRD) images. While our term is consistent with industry practice, over time we have come to realise that 'GRD' does not adequately describe the product. In fact, few users understand what 'detected' really means. It is actually an old electronic engineering term from the days when signal processing was performed on oscilloscopes. When applied to SAR images, detection is the process of converting in-phase and quadrature complex pixels (equivalent to amplitude and phase) into amplitude-only values. Due to SAR\u2019s electrical engineering heritage, technical jargon like this has become infused into the language of SAR, and this confuses users. In this case, we form a simple amplitude image, and refer to it with an obscure engineering term.</p> <p>Another limitation is that 'ground range' and 'detected' do not describe the essential fact that the image is in the  range-azimuth layout. In fact, an alternate form of amplitude images is to interpolate pixels to fit a map projection. While that format is completely different from the native range-azimuth structure, it is also detected and it is in the ground range. So, the SAR community\u2019s commonly used terms for range-azimuth amplitude images are based on dated jargon and they fail to state what the structure actually is.</p> <p>At ICEYE we like to use clear, descriptive English so we prefer to call a GRD image a range-azimuth amplitude image. It might also be called a sensor-orientation amplitude image. It is a struggle, though,  to shake off the SAR community\u2019s legacy language. Many of our customers are used to the term GRD and we are keeping the acronym in some of our product filenames for compatibility reasons. This is likely to change in the future.</p>"},{"location":"productFormats/grd/#amplitude-image-description","title":"Amplitude Image Description","text":"<p>Amplitude images represent focused SAR data that has been detected and (usually) multi-look processed and projected to the ground plane using an Earth ellipsoid model. The image coordinates are oriented along the flight direction and ground range (figure 1). The pixel spacing is equidistant in azimuth and in ground range. Ground range coordinates are the slant range coordinates projected onto the ellipsoid of the Earth. For this projection the WGS84 reference ellipsoid (table 1) is used and an averaged fixed value of terrain height is used. This makes the ellipsoid surface closer to the true ground surface. The mean ellipsoid height used is annotated in the <code>avg_scene_height</code> metadata element.</p> <p>Tip</p> <p>For an explanation of why, see Determining Ground Locations in the 'Geospatial Considerations' section under 'Foundations'</p> ELLIPSOID REFERENCE SEMI MAJOR AXIS SEMI MINOR AXIS INVERSE FLATTENING WGS84 6378137.0 m 6356752.314245 m 298.257 223 563 Table 1 : WGS84 Reference Ellipsoid used in ICEYE Amplitude images <p>Pixel values represent a scaled amplitude. The resulting product has approximately circular spatial resolution and square pixel spacing. Additionally, an incidence angle dependence in range, calculated using the ellipsoidal Earth model has been applied to enable the conversion of radar brightness to backscatter intensity. This is explained in more detail in the section on Radiometric Considerations.</p> <p>The core advantages of range-azimuth amplitude (GRD) images is that they are laid out in the natural SAR orientation, which is required for rigorous geolocation, and their pixels are free of the interpolation artifacts of map projection images.  This product is the form of a SAR amplitude image that retains its SAR heritage. It\u2019s pixels are presented in the natural range-azimuth form best suited for shadows-down interpretation, that is free of map-projection-induced artifacts, that supports manipulation into orthophotos and other forms, and which supports the SAR image geometry model used to calculate ground locations. </p> <p>To assist users that require geocoded imagery with minimal interpolation artefacts, ICEYE amplitude image products are tagged with ground control points (GCP) and rapid positioning capability polynomial coefficients (RPC\u2019s). These allow precise geospatial exploitation using freely available tools such as QGIS<sup>1</sup> or GDAL<sup>2</sup>.</p> Figure 1: The Binary Representation of Amplitude Images"},{"location":"productFormats/grd/#binary-representation","title":"Binary Representation","text":"<p>The 'digital numbers' in the image data layer \\(DN_{GRD}\\) of amplitude SAR products are stored in a GeoTIFF file format using unsigned 16 bit integer representation along with a combination of commonly used and specifically defined GeoTIFF tags. GeoTiff files are readable with standard image processing and GIS software tools.</p> <p>It is common for different imaging modes and different incidence angles to have a native range-azimuth sample spacing in the slant plane that is not square. Square sample spacing and a circular impulse response function in the ground plane is achieved either by varying the transmitted bandwidth or by applying multi-looking during the slant to ground transformation and detection process. </p> <p>Typically, the conversion from complex samples to amplitude only samples is performed as</p> \\[ |DN_{SLC}|^2 = (I^2 + Q^2) \\] <p>with \\(I^2\\) and \\(Q^2\\) representing the real and imaginary amplitude of the complex backscatter.</p> <p>For amplitude image scenes, a conversion to  \\(\\sigma_0\\) has been already applied using an incidence angle \\(\\theta\\) that is calculated from the ellipsoidal Earth model:</p> \\[ |DN_{GRD}|^2 =|DN_{SLC}|^2\\sin(\\theta) \\] <p>Ellipsoid parameters and metadata tags can easily be found using the command :</p> <p><pre><code>gdalinfo &lt;geotiff_filename.tif&gt;\n</code></pre> The amplitude image metadata elements can be found in the metadata section. </p>"},{"location":"productFormats/grd/#amplitude-image-in-context","title":"Amplitude Image in Context","text":"<p>Figure 2 provides a useful summary of Amplitude images in the context of the processing options available with the red line highlighting the decisions made during product production. </p> <p></p> Figure 2: The Processing Steps and Implementation Considerations for ICEYE amplitude images"},{"location":"productFormats/grd/#references","title":"References","text":"<ol> <li> <p>QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/.\u00a0\u21a9</p> </li> <li> <p>OSGeo. GDAL: Geospatial Data Abstraction Layer. May 2020. Accessed June 2020. URL: https://gdal.org/.\u00a0\u21a9</p> </li> </ol>"},{"location":"productFormats/introduction/","title":"Introduction To SAR Data","text":""},{"location":"productFormats/introduction/#from-satellite-to-sar","title":"From Satellite to SAR","text":"<p>After an imaging operation has taken place, the recorded radar echo data is downloaded to one of the terminals in the ICEYE ground station network where the images are formed. The focussing algorithm varies depending on the acquisition type. The data is then stored and represented as binary data in a container file format ready for exploitation.  When producing different forms of exploitable products, several decisions have to be made about the data representation. At ICEYE we realise that not every format is suitable for every customer or use case, so starting in 2022 we will be increasing the range of processing options available. This section includes a discussion of format options so that later we can refer to our current formats in context of the larger landscape.</p> <p></p> Figure 1: The Port of Rotterdam on three consecutive days."},{"location":"productFormats/introduction/#the-tree-of-processing-options","title":"The Tree of Processing Options","text":"<p>There are many steps that have to be considered when converting RADAR pulse data into an exploitable image. Here we will talk about each in turn.</p> <p></p> Figure 2: The SAR Image Tree of Processing Options"},{"location":"productFormats/introduction/#sample-arrangement","title":"Sample Arrangement","text":"<p>This is the way the image pixels are aligned as a raster in the container file. Most Geospatial Information System (GIS) viewers will convert the projection for you on your screen. Map-oriented images are larger than range-azimuth images as the rotation to make the image 'north-up' in the container file requires the addition of blank pixels to make the image rectangular. Map projection layouts are often projected to a single elevation surface; thus, they lack the geometric fidelity of range-azimuth images. They also can impart flipped terrain-perception effects in which mountains appear to be valleys and valleys appear elevated. Despite this, some users prefer the map-oriented product because its map representation with north up can be directly used with paper-based maps without any rotations.</p>"},{"location":"productFormats/introduction/#axis-alignment","title":"Axis Alignment","text":"<p>Another file representation option is the alignment of axes in the binary data. Range-azimuth data can be aligned shadows down or azimuth down. Modern GIS viewers can display the data in either representation and easily convert between the two. Scientists using algorithms to exploit the data need to understand the data representation thought. Historically, imagery intelligence analysts require fine resolution imagery to observe subtle features on small objects of interest. In these situations it is more important to have a consistent alignment of shadows, multipath and layover of an object than to  have North \u2018up\u2019. For large-scale mapping, azimuth down easily allows a collection to be extended by concatenating more data to the end of a file.</p>"},{"location":"productFormats/introduction/#projection-suface","title":"Projection Suface","text":"<p>The focussed SAR resolution cells are fit to a projection surface. Most commonly this is the slant plane,  the ground plane or an ellipsoid surface, but the projection surface can have any orientation and even be an inclined plane, a curve or the topographic surface.</p> <p>There are many reasons for a user preferring one projection surface over another. This is usually related to how the imagery will be exploited, but it should be recognised that the slant plane is the most efficient and artefact-free focus projection surface.</p>"},{"location":"productFormats/introduction/#number-of-looks","title":"Number of Looks","text":"<p>The multi-look process reduces resolution in order to reduce the speckle in the image. A single look has the finest resolution which may be different in range and azimuth. Symmetric IPR is the term used when the resolution (sometimes referred to as IPR or impulse response) is symmetrical in range and azimuth.</p>"},{"location":"productFormats/introduction/#complex-samples","title":"Complex Samples","text":"<p>Each sample starts life as a complex number. This is usually as an in-phase (I) and quadrature (Q) pair, but it can also be represented as amplitude and phase, which saves a user some time if they want to look at only the amplitude data. The process of calculating the amplitude from I and Q is called detection, which is the D in Ground Range Detected (GRD). </p> <p>The number of shades of grey that a pixel in a SAR image can have is determined by the binary representation of that pixel. As very few pixels are very bright or very dark it is often convenient to store the SAR image data as an unsigned integer - typically uint8 or uint16 format- designed to span the majority of the grey-scale values. This reduces the data size of the image and is useful for most tasks. Sometimes however, it is important to be able to discriminate between different kinds of very bright or dark pixel values (for example man-made objects in trees or ocean wave structure on a calm ocean). In these situations, a floating-point representation is more useful as it has a larger bit depth..</p>"},{"location":"productFormats/introduction/#container-format","title":"Container Format","text":"<p>The container and file format defines how the data and associated metadata is stored on disk. It also defines which image viewers know how to read the data. </p>"},{"location":"productFormats/metadata/","title":"Metadata","text":"<p>Metadata is the term used to describe all the ancillary information about an image that might be important to the user. </p> <p>This page captures all the metadata items that are present in ICEYE imagery. You can use the search bar at the top from any page and enter the metadata element you are interested in and it will find it on this page.</p>"},{"location":"productFormats/metadata/#iceye-product-metadata-version-24","title":"ICEYE Product Metadata (Version 2.4)","text":"Format Metadata Elements Description Type Unit Example HDF5 SLC-XML GEOTIF AMP-XML <code>acquisition_end_utc</code> UTC time for when the last pulse of the scene was sent ASCII UTC time 2019-03-10T18:20:00.307546 <code>acquisition_id</code> Identitification number for this acquisition ASCII int 469840 <code>acquisition_mode</code> Acquisition mode used ASCII text Stripmap, Spotlight <code>acquisition_prf</code> Pulse Repetition Frequency used for the acquisition float64 Hz 4823.00342969132 <code>acquisition_start_utc</code> UTC time for when the first pulse of the scene was sent ASCII UTC time 2019-03-10T18:19:50.316054 <code>angX</code> X-component of the antenna pointing orientation vector of float64 TBP <code>angY</code> Y-component of the antenna pointing orientation vector of float64 TBP <code>angZ</code> Z-component of the antenna pointing orientation vector of float64 TBP <code>ant_elev_corr_flag</code> Flag indicating if antenna elevation pattern compensation was applied int64 flag 1 <code>antenna_pattern_compensation</code> Amplification factor applied for antenna pattern compensation (for each range sample) vector of float numbers [1.8106, 1.8103...1.0956,1.0957] <code>AREA_OR_POINT</code> geotif flag indicating if this is an area collection or a point collection ASCII text Area' or 'Point' <code>avg_scene_height</code> Average elevation over ellipsoid (calculated using SRTM or other  low resolution global DEM) float32 meters 661 <code>azimuth_ground_spacing</code> Azimuth sample spacing in meters with the average ground projected velocity float64 meters 1.44733 <code>azimuth_spacing</code> Azimuth sample spacing in meters with the average ground projected velocity float64 meters 1.44733 <code>azimuth_look_bandwidth</code> Bandwidth of each look in range (only for GRD products) float64 Hz 1157.2 <code>azimuth_look_overlap</code> Overlap of adjacent looks in azimuth (only for GRD products) float64 Hz 289.3 <code>azimuth_looks</code> Looks in azimuth direction (for SLC products it is 1) int64 number 3 <code>azimuth_resolution</code> 3dB resolution of this data product float64 meters 2.49 <code>azimuth_time_interval</code> Time interval between azimuth samples in the SLC product. (=1/processing_prf) float64 seconds 0.0002073 <code>calibration_factor</code> Factor to be applied to calibrate detected products to absolute brightness intensity float64 number 1.2341123e-05 <code>carrier_frequency</code> Carrier frequency of the radar system, static parameter float64 Hz 9650000000 <code>chirp_bandwidth</code> Bandwidth used for radar pulse (defines achievable radar range resolution) float64 Hz 134000000 <code>chirp_duration</code> Duration of chirp float64 seconds 4.1473e-05 <code>coord_center</code> Centre coordinate [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [8440,22139,34.86704,-117.99988] <code>coord_first_far</code> First azimuth row far range coordinate.  [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [16878,1,35.17738,-118,11233] <code>coord_first_near</code> First azimuth row near range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [1,1,35.12016,-117.74549] <code>coord_last_far</code> Last azimuth row far range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [16878,44298,34.61222,-118.24414] <code>coord_last_near</code> Last azimuth row near range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [1,44298,34.55509,-117.88013] <code>data_orientation</code> Can be either \"native\" or \"shadows_down\". This describes the data inside the product storage arrays. 'native' means columns are for increasing range and increasing rows are slow time. ''shadows-down' means increasing rows are increasing range and columns represent slow-time direction ASCII text \"native\" <code>dc_estimate_coeffs</code> Doppler centroid coefficient as a 2D array, size MxN, where M is the number of DC estimates, and N is the (DC polynomial order+1) 2D array of float64, size MxN number [[5.417583e+03, 1.130813e+07, -8.125472e+09,7.947223e+12], ... [5.417583e+03, 1.130813e+07, -8.125472e+09,7.947223e+12]] <code>dc_estimate_poly_order</code> Order of polynomial describing one doppler centroid estimate int64 number 3 <code>dc_estimate_time_utc</code> Timestamp for each doppler centroid estimate ASCII list Time (UTC) ['2019-03-10T18:19:51.775477'],['2019-03-10T18:19:52.775477'],['2019-03-10T18:19:53.775477'],['2019-03-10T18:19:54.775477']] <code>Doppler_Centroid_Coefficients</code> XML Block of data containing  sets of coefficiencts in a . Each Coefficient. Has a list index number , a  and a .  These are then followed by +1 coefficients (), each marked with a number () and a value (). See  Doppler Centroid Coefficient Schema Coefficient Block Hz <code>Doppler_Rate</code> See Doppler Rate Coefficients Schema Coefficient Block <code>doppler_rate_coeffs</code> Coefficients of doppler rate polynomial as a function of range time. Stored as a vector with size corresponding to the order of the doppler rate polynomial vector of float64 number [5.124592968269841e+03; -1.153864338674892e+06; 2.582540352459471e+08; -5.572042961000484e+10] <code>doppler_rate_poly_order</code> Order of polynomial describing doppler rate range dependence int64 number 3 <code>first_pixel_time</code> Two-way slant range time origin, corresponding to the near range (1st range sample) float64 seconds 0.004398670017444 <code>fsl_compensation</code> Amplification factor applied for free space loss compensation (for each range sample) vector of float64 numbers [1.0457, 1.0457...1.0841,1.0841] <code>gcp_terrain_model</code> Options are WGS84 for Ellipsoid, EGM96 for GEOID, DEM for DEM based ASCII text <code>geo_ref_system</code> Geographic reference frame indicator for scene coordinates and orbit state vectors ASCII text WGS84 <code>grd_amplitude</code> Amplitude array (only for GRD products). Sigma-nought conversion factor of sin(inc_angle) applied. as \u2018sample_precision\u2019 number array <code>grsr_coefficients</code> ground range to slant range polynomial coefficients (only for GRD product) vector of float64 number [6.467483312430216e+05; 0.47388031307797884; 6.685331046296479e-07; -4.928145432555108e-13; 5.0525558404285224e-20] <code>GRSR_Coefficients</code> See GRSR_Coefficients schema Coefficient Block <code>grsr_ground_range_origin</code> ground range origin for GRSR conversion number 0 <code>grsr_poly_order</code> Order of polynomial describing ground range to slant range projection dependence (only for GRD product) int64 number 4 <code>grsr_zero_doppler_time</code> ground range origin zero Doppler time ASCII UTC time 2019-04-08T14:50:13.120113 <code>height_spline</code> Python numpy spline parameters for surface height used to focus image hickle meters <code>heading</code> Satellite heading at centre of imaging operation float64 degrees <code>incidence_angle_coefficients</code> coefficients of the polynomial for calculating the incidence angle dependence in range vector of float64 number [ 2.67986035e+01; 8.66207416e-05; -5.61940883e-11; -1.73946139e-17; 8.22003978e-23] <code>Incidence_Angle_Coefficients</code> See Incidence_Angle_Coefficients XML Block Schema Coefficient Block number <code>incidence_angle_ground_range_origin</code> incidence angle origin in ground range, for calculating incidence angle dependence in range float64 number 0 <code>incidence_angle_poly_order</code> order of the polynomial for calculating the incidence angle dependence in range int64 number 4 <code>incidence_angle_zero_doppler_time</code> incidence angle origin zero Doppler time ASCII UTC time 2019-04-08T14:50:13.120113 <code>incidence_center</code> incidence angle in ground at middle range float64 degrees 23.5 <code>incidence_far</code> incidence angle in ground at far range float64 degrees <code>incidence_near</code> incidence angle in ground at near  range float64 degrees <code>lat_spline</code> Python numpy spline parameters for image pixel latitudes hickle degrees <code>local_incidence_angle</code> Array of values describing the local incidence angle or each range sample in the scene []float64 degrees <code>look_side</code> Look side of the acquisition, only 2 options LEFT or RIGHT ASCII text LEFT <code>lon_spline</code> Python numpy spline parameters for image pixel longitudes hickle degrees <code>mean_earth_radius</code> mean WGS84 ellipsoid radius over scene float64 meters 6371346.049 <code>mean_orbit_altitude</code> mean sensor altitude above WGS84 ellipsoid float64 meters 595177.494 <code>number_of_azimuth_samples</code> Number of azimuth samples (number of rows in binary data) int64 number 44298 <code>number_of_dc_estimations</code> Number of doppler centroid estimates int64 number 9 <code>number_of_range_samples</code> Number of range samples (number of columns in binary data) int64 number 16878 <code>number_of_state_vectors</code> Total number of orbit state vectors provided for the scene int64 number 120 <code>orbit_absolute_number</code> Absolute number of orbits since launch int64 number 1447 <code>orbit_direction</code> Specifies whether the orbit is in ascending or descending node at the time of acquisition ASCII text ASCENDING or DESCENDING <code>orbit_processing_level</code> PREDICTED (based on orbit propagation model ) RAPID (uses onboard GPS data ) PRECISE (corrections applied after GPS data received in ground using high precision orbit propagator (eg ODTK) SCIENTIFIC (Uses precise ground-based measurements together with all above to post-fix orbit to best possible) ASCII Text <code>orbit_relative_number</code> Relative number of orbit within the repeat cycle int64 number 1447 <code>orbit_repeat_cycle</code> Ground track repeat cycle (to be included) int64 number 99999 <code>Orbit_State_Vectors</code> See Orbit_State_Vectors XML Schema Coefficient Block <code>pitch</code> Pitch angle of the satellite attitude float degrees 11.5 <code>polarization</code> Transmit and receive polarizations used ASCII text VV <code>posX</code> X-component of state vector position, for each state vector vector of float64 meters [-2401162517\u2026 -2456350660] <code>posY</code> Y-component of state vector position, for each state vector vector of float64 meters [-5201254993\u2026 -5253761907] <code>posZ</code> Z-component of state vector position, for each state vector vector of float64 meters [3963994744\u2026 3859728760] <code>processing_prf</code> Pulse Repetition Frequency used for the processing, defines azimuth sample spacing in time (can be higher than acquisition in cases where the Doppler frequency needs to be unfolded due to high variation of Doppler centroid with range) float64 Hz 9646.00685938265 <code>processing_time</code> Timestamp provided by the SAR processor saying when the image for processed ASCII UTC Time 2020-05-27T05:01:49.123456 <code>processor_version</code> Version number of the processor used to generate the product float64 number (internal version numbering) <code>product_level</code> Processing level ASCII text SLC, GRD <code>product_file</code> File name of this product ASCII text ICEYE_X2_SLC_SM_16519_20200102T155349.h5 <code>product_name</code> ICEYE_datasetID_eventID_(YYYYMMDD)T(HHMMSS) ASCII Text ICEYE_2457_123123_20191201T056721 <code>product_type</code> Product type (if we have product names for different imaging modes) ASCII text Stripmap, StripmapHigh, Spotlight, SpotlightHigh <code>range_look_bandwidth</code> Bandwidth of each look in range (only for GRD products) float64 Hz 53600000 <code>range_look_overlap</code> Overlap of adjacent looks in range (only for GRD products) float64 Hz 13400000 <code>range_looks</code> Looks in range direction (for SLC products it is 1) int64 number 3 <code>range_resolution_center</code> Scene centre range resolution float64 meters 2.15 <code>range_resolution_far</code> Range resolution at the far edge of the image float64 meters 1.93 <code>range_resolution_near</code> range resolution at the near edge of the image float64 meters 2.49 <code>range_sampling_rate</code> Sampling rate used for digital sampling, defines range sample spacing in time float64 Hz 157500000 <code>range_spacing</code> <code>range_spread_comp_flag</code> Flag indicating if free space loss compensation was applied int64 flag 1 <code>ref_track_point_ecef</code> reference point for image in earth centred earth fixed coordinate frame []float64 m array <code>ref_track_point_lla</code> reference poInt for image in terms of latitude, longitude and altitude []float64 deg,deg,m array <code>RPC</code> RPC according to http://geotiff.maptools.org/rpc_prop.html Coefficient Block <code>s_i</code> Real part of the SLC complex array (only for SLC products) as \u2018sample_precision\u2019 number array <code>s_q</code> Imaginary part of the SLC complex array (only for SLC products) as \u2018sample_precision\u2019 number array <code>sample_precision</code> Precision used for binary data samples ASCII text float32, int16 <code>satellite_look_angle</code> Satellite look angle float64 degrees 23.5 <code>satellite_name</code> Name of the satellite ASCII text ICEYE-X2, ICEYE-X4... <code>scan_beams</code> Provides information Scan beams used in Scan mode (SCAN MODE ONLY) Struct <code>slant_range_spacing</code> Spacing between two consecutive slant range samples in meters (SLC ONLY) float64 meters 0.95172208888 <code>slant_range_to_first_pixel</code> Two-way slant range distance corresponding to near range (1st sample) float64 metres <code>spec_version</code> Version of the Level 1 Product Format Specification document float64 number 2.3 <code>state_vector_time_utc</code> Timestamp for each orbit state vector list of ASCII UTC time [2019-03-10T18:19:48.000000, ...] <code>total_processed_bandwidth_azimuth</code> Doppler bandwidth used for azimuth compression (defines achievable azimuth resolution) float64 Hz 2893 <code>tropo_range_delay</code> Mean signal path length correction (one way) that has been applied to correct for tropospheric propagation float64 meters 2.4 <code>velX</code> X-component of state vector velocity, for each state vector vector of float64 meters/sec [-3285.698...-3245.220] <code>velY</code> Y-component of state vector velocity, for each state vector vector of float64 meters/sec [-3162.667...-3051.016] <code>velZ</code> Z-component of state vector velocity, for each state vector vector of float64 meters/sec [-6130.372...-6208.463] <code>window_function_azimuth</code> Windowing function used over azimuth frequencies ASCII text taylor_20_4 <code>window_function_range</code> Windowing function used over range frequencies ASCII text taylor_20_4 <code>yaw</code> Yaw angle of the satellite attitude float degrees <code>zerodoppler_end_utc</code> Time corresponding to when the satellite was at the zero Doppler position for the last scene pulse ASCII UTC time 2019-03-10T18:20:00.960210 <code>zerodoppler_start_utc</code> Time corresponding to when the satellite was at the zero Doppler position for the first scene pulse ASCII UTC time 2019-03-10T18:19:51.775477"},{"location":"productFormats/packaging/","title":"SAR Data Package","text":""},{"location":"productFormats/packaging/#file-naming","title":"File Naming","text":"<p>Product file naming convention describes the product processing level so that a user does not have to analyze product metadata to understand key properties. The product filename components are shown in Figure 1. The Product ID is a unique identifier of the acquired scene and is assigned during scene ordering and acquisition. </p> <p></p> Figure 1: Data product filename components <p>The constituent elements are explained in more detail in  Table 1</p> CONSTITUENT NAME VALUE NOTES ICEYE_ constellation ICEYE_ fixed XN_ sensor X2/X4/X5 specific sensor that has acquired the scene PPL_ product processing level SLC/GRD variant of processing level IM_ imaging mode SM/SMH/SL/SLH stripmap, stripmap-high, spotlight, spotlight-high PRID_ product id eg. 6403 data take ID YYYYMMDD UTC start date eg. 20190211 YYYYMMDD format Thhmmss UTC start time eg. T131415 Thhmmss format Table 1: Product filename components. Example : ICEYE_X6_GRD_SM_153426_20211026T060946"},{"location":"productFormats/packaging/#package-overview","title":"Package Overview","text":"<p>SAR images can be ordered either from archive (previously collected imagery) or as a planned future acquisition. Products are geo-coded and radiometrically corrected.</p> <p>ICEYE\u2019s focus is currently on the integrity of complex and amplitude images. This will expand over the next year as we introduce a phase history data product and other products derived from complex and amplitude images.</p> <p>A basic ICEYE product is represented by a set of SAR image binary data, corresponding image metadata and it is delivered as a singular product package. Products are characterized by the payload configuration (such as imaging mode and look direction) used by the respective satellite, as well as the level of processing that has been applied to the SAR scene. With respect to the data geometric projection and representation, products are differentiated into two primary types: geo-referenced Single Look Complex (SLC) and Amplitude Images (Also known as Ground Range Detected (GRD) scenes). SAR image binary data, delivered as digital numbers or quadrature components, can be converted to radar brightness \\(\\beta_0\\) and mean radar cross section \\(\\sigma_0\\) using the annotated calibration factor in the image metadata.</p> <ol> <li> <p>Committee on Earth Observation Satellites Working Group on Information Systems and Services. Interoperability Handbook Issue 1.1. 2008. URL: https://ceos.org/document_management/Working_Groups/WGISS/Documents/WGISS_CEOS-Interoperability-Handbook_Feb2008.pdf.\u00a0\u21a9</p> </li> </ol>"},{"location":"productFormats/slc/","title":"Single Look Complex Image","text":""},{"location":"productFormats/slc/#overview","title":"Overview","text":"<p>Single Look Complex (SLC) images have the highest fidelity of all SAR image products because they are only one step removed from the original RADAR collected data. They retain all the original sensor measurements and are free from interpolation artefacts or projection issues. A small concession is made with the default SLC product in that the dynamic range of the complex numbers is reduced to make image sizes more manageable. SLC products are the best source for SAR image analysis, but complex-image exploitation software is currently difficult to use without skill and experience. For this reason, SLC images are usually used for automated processing and advanced exploitation such as interferometric applications, or by users who prefer lower-level processing in order to implement their own processing chains. The SLC product can be orthorectified using both commercial and free specialized SAR software tools such as the European Space Agency (ESA) Sentinel Application Platform (SNAP)<sup>1</sup>.</p>"},{"location":"productFormats/slc/#geometry","title":"Geometry","text":"<p>Scenes are stored in the satellite image acquisition geometry (AKA the slant plane). The image coordinate system is centred on the zero-Doppler (time of closest approach)  SAR coordinates and are arranged in the slant-range-by-azimuth imaging plane. The pixels are spaced equidistant in azimuth (according to the inverse of the pulse repetition frequency) and in slant range (according to the range sampling frequency). Each image pixel is stored with in-phase I and quadrature Q components and therefore, contains both amplitude and phase information.  </p>"},{"location":"productFormats/slc/#looks","title":"Looks","text":"<p>As the name suggests, SLC images have only a single look. This means they retain full resolution in azimuth and range. In most cases the impulse response function (the shape of a single, isolated radar-bright object in the radar image) is asymmetrical with azimuth resolution being smaller (finer) than range resolution.</p>"},{"location":"productFormats/slc/#binary-representation","title":"Binary Representation","text":"<p>SLC images are stored as binary matrices in an HDF5 file container<sup>2</sup>. Real and imaginary components  are stored separately, using either signed 16 bit integers or IEEE-754 single precision 32-bit floating point format (the version used is annotated in the <code>sample_precision</code> metadata element).  </p> <p>The structure of the binary data is shown in Figure 1. Each row of the matrix is a single range line (often called a range profile by RADAR engineers) of the image with increasing range preceding from lower indices to higher indices (left to right in Figure 1). Early row indices in the matrix correspond to early pulses and later rows correspond to later pulses (top to bottom in Figure 1). It is important to recognise that image viewing software needs to take into account the matrix configuration as viewing the matrix as it is stored may result in the image being reflected in either dimension depending on right/left looking and ascending/descending.</p> Figure 1: The Binary Representation of SLC images"},{"location":"productFormats/slc/#shadows-down","title":"Shadows Down","text":"<p>Some software algorithms prefer to process SLC imagery with increasing range aligned to increasing row index - often called shadows down orientation. This approach is usually used for fine resolution SAR imaging systems where it is important for target recognition to have a consistent shadow and layover alignment. It is often better for analysts to view SAR amplitude imagery shadows down as opposed to North-up because the human visual system prefers that orientation to properly interpret topography and elevated features. ICEYE provides SLC imagery shadows down by request. However, any image storage scheme can be manipulated on an image workstation to present images shadows down.</p>"},{"location":"productFormats/slc/#hdf5-container","title":"HDF5 Container","text":"<p>The SLC HDF5 container contains metadata associated with the collection in its header structure. The metadata is described in the Metadata section of this site. HDF and metadata tags can easily be found using a Python interpreter and the commands : </p> <pre><code>import h5py\nf = h5py.File(\"&lt;filename.h5&gt;\")\nfor key in f.keys():\nprint(f[key])\n</code></pre>"},{"location":"productFormats/slc/#sensor-independent-complex-data-sicd","title":"Sensor Independent Complex Data (SICD)","text":"<p>This is a form of complex data that is carefully designed to remove any sensor-specific parameters. SICD image data is in the same format regardless of processing algorithm or collection strategy. In theory, any algorithm that uses SICD will work on SAR imagery from any SAR vendor. The SICD specification was developed by the US National Geospatial Intelligence Agency (NGA) and it is stored in the NITF (National Imagery Transmission Format[@nitf) container. For this reason, SICD files can only be used with GIS viewers and algorithms that know how to handle this type of dataset. Since NITF is not as well known as hdf5, the SICD product is currently only available from ICEYE by request.</p>"},{"location":"productFormats/slc/#slc-in-context","title":"SLC in Context","text":"<p>Figure 2 provides a useful summary of SLC images in the context of the processing options available with the red line highlighting the decisions made during product production. </p> <p></p> Figure 2: The Processing Steps and Implementation Considerations for ICEYE SLC images"},{"location":"productFormats/slc/#references","title":"References","text":"<ol> <li> <p>European Space Agency. The sentinel application platform - snap. Accessed 2020 Dec 17. URL: http://step.esa.int/main/toolboxes/snap/.\u00a0\u21a9</p> </li> <li> <p>The HDF Group. The hdf5 library &amp; file format. Accessed 2020 Dec 17. URL: https://www.hdfgroup.org/solutions/hdf5/.\u00a0\u21a9</p> </li> </ol>"},{"location":"productFormats/upcomingformats/","title":"Upcoming Formats","text":"<p>Info</p> <p>The data formats described in this page are available as a preview and can be provided to ICEYE customers upon request. More information in the FAQ. </p> <p>We are excited to provide a preview of upcoming new formats for our complex and amplitude data products as well as their corresponding metadata format. These new formats attempt to lower the barriers for getting the maximum value out of ICEYE SAR data: They are more user friendly, and compatible with more GIS and image viewing software and web applications. They also offer easier access to  all the information they contain without the need for specialized scientific tools or advanced SAR knowledge.</p>"},{"location":"productFormats/upcomingformats/#geotiff-slc-preview","title":"GeoTIFF SLC (Preview)","text":""},{"location":"productFormats/upcomingformats/#the-challenge-with-complex-data","title":"The challenge with complex data","text":"<p>SAR complex data has traditionally been packaged in scientific or military-intel formats like HDF5 SLC (HDF container) or (SICD) (NITF container) where each image pixel is stored with in-phase I and quadrature Q components and therefore, contains both amplitude and phase information. These formats require compliant tools and software that is currently difficult to use without specialized skill and experience. For this reason, the user of complex images has been limited to automated processing and advanced exploitation such as interferometric applications, or by users who prefer lower-level processing in order to implement their own processing chains. </p>"},{"location":"productFormats/upcomingformats/#complex-data-in-a-geotiff","title":"Complex data in a GeoTiff","text":"<p>GeoTIFF SLC images are packaged in the open, international GeoTiff format. This enables their easy ingestion and manipulation in most image readers, GIS tools and libraries. The amplitude and phase data is formatted in two GeoTiff bands, similar to how bands are used for multispectral images. Image readers and GIS tools are able to ingest this complex image just like they do any other GeoTiff file. The amplitude band can be immediately presented for viewing, while the phase band is available for further exploitation by more specialized tools. The key advantage is that the GeoTIFF SLC image is at full resolution, so users have access to the full resolution as well as to reduced-speckle, pixel-ageraged views (equivalent to different levels of multi-looking) that are produced instantly when zooming in and out. </p> <p>While the SAR data inside the GeoTIFF SLC format is stored in the slant plane (the satellite image acquisition geometry), the metadata inside the GeoTIFF contains RPC values that allows GIS tools to perform automatic ground projection, so they  are ready to be used as part of analysis and exploitation workflows. Please note that Orthorectification using a Digital Elevation Model is still recommended for accurate geospatial comparison and analysis.</p> <p>THe GeoTIFF SLC format uses the Cloud-Optimized GeoTIFF standard that allows fast data visualization and geospatial processing workflows. GIS applications can efficiently stream or download only the parts of the information they need to visualize or process web-based data. Tiles and overviews are included to enable fast image rendering. GeoTIFF SLC files accessed by web applications or stored online can be efficiently streamed and partially downloaded with the use of HTTP range queries. </p> <p></p> Figure 1: Detail of a Dwell GRD viewed in QGIS. Squared pixels are limited by range resolution  <p></p> Figure 2: Detail of a Dwell GeoTIFF SLC viewed in QGIS. Full azimuth resolution visible without the need for scientific viewing software."},{"location":"productFormats/upcomingformats/#recommended-qgis-settings","title":"Recommended QGIS settings","text":"<p>The following settings are recommended when using QGIS to visualize GeoTIFF SLC images. They ensure that the correct render type and optimal resampling method is used to display the amplitude band. </p> <p></p> Figure 3: Recommended QGIS settings for exploiting the GeoTIFF SLC format. <ol> <li>Select <code>Layer Properties -&gt; Symbology</code></li> <li>Under <code>Band Rendering</code><ul> <li>Render type: <code>Singleband gray</code></li> <li>Gray band: <code>Band 1 (Gray)</code></li> </ul> </li> <li>Under Contrast enhancement, start with <code>Cumulative count cut 2 - 98%</code>, and adjust if necessary</li> <li>Under Resampling<ul> <li>Early resampling: <code>On</code></li> <li>Zoomed in: <code>Lanczos</code></li> <li>Zoomed out: <code>Lanczos</code></li> </ul> </li> </ol> <p>Explanation: Although GeoTIFF SLC image has a single look, QGIS performs Lanczos averaging when rendering to make the projection correct. This is equivalent to multilooking, but the software is doing it in real time. The user gets the benefit of reduced speckle when zoomed out and the benefit of the finest resolution when zoomed in.</p> <p></p> Figure 4: Zoomed out image showing reduced speckle because of Lanczos averaging (multi-looking)  <p></p> Figure 5: Zoomed in image showing speckle but also higher azimuth resolution"},{"location":"productFormats/upcomingformats/#cloud-optimized-geotiff-grd-preview","title":"Cloud-Optimized GeoTIFF GRD (Preview)","text":"<p>Cloud-Optimized GeoTIFF GRD images contain the amplitude part of the backscattering signal. They are a more user friendly implementation of the current GRD format. The Cloud-Optimized GeoTIFF GRD format uses the Cloud-Optimized GeoTIFF standard and offers the following advantages:</p> <ul> <li>Supported by most image viewing software, GIS applications, data exploitation tools and libraries.</li> <li>Allows for faster data visualization and geospatial processing workflows.  Applications can efficiently stream/download only the parts of the information they need to visualize data. Tiles and overviews are included to enable fast image rendering. Cloud-Optimized GeoTIFF GRD files accessed by web applications or stored online can be efficiently streamed and partially downloaded with the use of HTTP range queries.</li> <li>The Cloud-Optimized GeoTIFF GRD format allows for increased data precision (u32/f32) to support the very high dynamic range of the latest ICEYE data product.</li> <li>Defaults to shadows-down data orientation to facilitate interpretation of topography and elevated features</li> </ul>"},{"location":"productFormats/upcomingformats/#metadata-30-preview","title":"Metadata 3.0 (Preview)","text":"<p>The metadata of the new GeoTIFF SLC and Cloud-Optimized GeoTIFF GRD image formats is stored in GeoJSON format which is more modern than the XML used to store metadata by the current SLC and GRD formats. GeoJSON is a geocoded metadata format supported by many GIS tools.  </p> <p>The included satellite orbit metadata can be used to visualize the exact position of the satellite when the SAR data was collected as well as the imaging geometry. </p> <p>A JSON schema that can be used for validation purposes is available at the following location:</p> <p>https://sar.iceye.com/schema/product-spec/0.0.2/image.json </p> <p></p> Figure 6: Imaging geometry and satellite orbit track can be visualized by opening the GRD/SLC GeoJSON metadata files Google Earth Pro"},{"location":"productFormats/upcomingformats/#frequently-asked-questions","title":"Frequently asked questions","text":""},{"location":"productFormats/upcomingformats/#are-geotiff-slc-and-cloud-optimized-geotiff-grd-available-to-iceye-customers","title":"Are GeoTIFF SLC and Cloud-Optimized GeoTIFF GRD available to ICEYE customers?","text":"<p>Yes, both formats are available as a preview and can be provided to customers upon request. ICEYE encourages customers to try these new product formats and provide us with feedback. We look forward to continuing to develop and improve all our data products.</p>"},{"location":"productFormats/upcomingformats/#will-geotiff-slc-or-cloud-optimized-geotiff-grd-eventually-replace-any-of-the-existing-formats-currently-offered-by-iceye","title":"Will GeoTIFF SLC or Cloud-Optimized GeoTIFF GRD eventually replace any of the existing formats currently offered by ICEYE?","text":"<p>Based on customer feedback, ICEYE may decide to adjust its product format offering in the future. There is currently no planned timeline for this. </p>"},{"location":"productFormats/vid/","title":"SAR Video","text":"<p>Info</p> <p>SAR Video products are only produced when the Dwell collection mode is utilized</p>"},{"location":"productFormats/vid/#sar-video-vid","title":"SAR Video (VID)","text":"<p>SAR Video is similar to the CSI product in which the acquired SAR data is divided into multiple sub-apertures. However, in the case of SAR Video, they are not used to create composite images. Instead, each discrete sub-aperture is used as a frame of a video.</p> <p>Video is very useful in applications where moving objects need to be analyzed. By simple inspection and analysis of a video, it is possible to infer the general direction and speed of moving objects such as vessels and vehicles. SAR Video is also effective for detecting objects hidden in the forest area as well as human-made objects as these tend to give bright reflections and show as glint when playing a video.</p> <p></p> Figure 1: Detail of a SAR Video (VID) Product showing multiple vessels in movement."},{"location":"productFormats/vid/#container-format-and-metadata","title":"Container format and metadata","text":"<p>The formats of the VID product are MPEG4 and GIF. Additionally, a GeoTIFF format is produced where each of the video frames is available as a separate band to facilitate frame by frame analysis in any image exploitation tools. The user can measure and track changes and moving objects between frames by stepping through the different bands of the image. ICEYE is able to produce SAR Video products (VID) only for certain types of collection characteristics such as Dwell. In the case of Dwell, each video is made of 25 frames (Note 1). Important metadata for each of each of the video frames is available in the GeoTIFF. GeoTIFF metadata can be accessed by multiple methods including:</p> <ul> <li>Using the gdal library and running the command <code>gdalinfo filename.tif</code> (for example: <code>gdalinfo ICEYE_X2_VID_SLED_1906432_20231020T110813.tif</code>)  </li> <li>Using the the open source application QGIS by selecting Raster \u2192 Miscellaneous \u2192 Raster information \u2192 Run </li> </ul> <p></p> Figure 2: Detail of a SAR Video (VID) Product showing waves and human-made objects highlighted by glint."},{"location":"productFormats/vid/#key-vid-geotiff-metadata","title":"Key VID GeoTIFF Metadata","text":"Metadata Element\u00a0\u00a0\u00a0\u00a0 Description Type Unit <code>FRAME_DURATION</code> Duration of SAR data collection for each video frame. List of float64 seconds <code>FRAME_MID_TIME</code> Timestamp at the center of each video frame. Number of seconds since the beginning of the SAR collection List of float64 seconds <code>FRAME_POS</code> Satellite position at the center of each video frame List of float64 triplets ECEF coordinates <code>FRAME_VEL</code> Velocity vector of the satellite at the center of each video frame List of float64 triplets meters per second"},{"location":"productFormats/vid/#notes-and-explanations","title":"Notes and Explanations","text":"<ol> <li>Frame duration: The exact duration and temporal separation of each video frame varies slightly depending on specific collection characteristics. The actual values are availalable in the GeoTIFF metadata.</li> </ol>"},{"location":"productguide/fleet/","title":"THE ICEYE FLEET","text":"<p>The ICEYE global imaging service uses an innovative satellite and sensor design based on advancements in small satellite technologies and an adaptable New Space approach. The ICEYE constellation is constantly evolving and it is optimized for persistent monitoring with fast and repeatable access to any location on Earth. Our flexible collection supports high resolution imaging over small areas as well as reduced resolution scans of wide areas. </p> <p>Our goal is to provide global access from a fleet of satellites, each in a coherent daily ground track repeat orbit (CD-GTR). This means that any location can be imaged multiple times from nearly the same orbital location using the same imaging geometry. The repeat cycle for these coherent collections is 24 hours or less. </p> <p>Over the last year we have been filling out our constellation with our third generation satellites that have improved collection capabilities. When combined with our latest ground processing technology, the ICEYE fleet provides an optimium solution between image quality, rapid access and area coverage.</p> Figure 1: ICEYE Generation 3 Satellite"},{"location":"productguide/fleet/#sar-sensor-parameters","title":"SAR Sensor Parameters","text":"<p>The ICEYE sensors are X-band radars, each with an active phased array antenna and electronic beam steering. The innate mechanical agility of these low-mass satellites and their electronic steering enable fast and precise pointing of radar pulses to the ground. The satellites can also image to the right or left side of the satellite track. Technical parameters of the current sensors are listed in Table 1.</p> SENSOR PARAMETER SPECIFICATION Carrier frequency 9.65 GHz (X-band) Antenna size 3.2 meters (along-track) x 0.4 meters PRF 2-7 kHz Look direction both LEFT and RIGHT Range Bandwidth 37.6-600 MHz Peak Radiated Power 3.2 kW Polarization VV Incidence angle range 5-45\u00b0 (mode dependent) Mass 110 kg Communication [radar payload data downlink] X-band 500 Mbits/s Table 1: ICEYE Generation 3 satellite system parameters"},{"location":"productguide/fleet/#orbits","title":"Orbits","text":"<p>At present, ICEYE satellites are all in sun-synchronous orbits with 15 orbits per day, but the orbits are not uniformly spaced. This means that the time to revisit a location on the equator varies over a period of days. The mean revisit rate at the equator is 20 hours and the mean time to access a location on the equator is 12 hours. At higher and lower latitudes, the rates are more frequent. Table 2 lists the orbital parameters of the current SAR instruments. Their ground track repeat cycles vary between 1 and 22 days. Each orbital plane is phased around the Earth with a different local time of the ascending node (LTAN) so that the overall constellation can observe a location at different times of the day. This has an advantage over dawn-dusk sun-synchronous orbits, in which the local time of collection is always close to sunrise or sunset.</p> Orbit Parameters Nominal Altitude 560 to 580 km Orbit Parameters Value Inclination 97.7\u00b0 (sun-synchronous) Orbits / Day 15 Ground track repeat 1 - 22 days Constellation mean revisit at equator 20 hours Constellation mean time to access at equator 12 hours Orbit maintenance Ion Propulsion Table 2: Constellation Parameters <p>Each satellite has the ability to slowly adjust its orbits throughout its operating life. The adjustment is usually performed in the orbital plane by raising or lowering the satellite's altitude. This changes the orbital period, which in turn changes the ground track repeat period. As the fleet grows it will gradually be adjusted into one-day repeating coherent ground tracks. This provides novel opportunities to combine identical data collections of the same area whilst maintaining rapid access times.</p> <p></p> Figure 2: Daily Coherent Ground Track Repeat (GTR) imagery reveals unprecedented levels of intelligence such as the flow rate of The Muldrow Glacier USA between 16th and 30th April 2021. <p>The satellite orbital agility is provided via a set of ion thrusters positioned around the satellite. These provide a near limitless supply of manoeuvring thrust, and also ensure that the constellation can be rapidly configured to increase the coverage rate of certain geographic regions in response to world events.</p> <p>The location of each ICEYE satellite is publicly available. The current configuration of the constellation can be found using one of the excellent online orbital elements tools such as celestrak<sup>2</sup> or n2yo<sup>1</sup>, which provide a live view of the current ICEYE constellation.  </p>"},{"location":"productguide/fleet/#references","title":"References","text":"<ol> <li> <p>N2YO. Accessed 2020 Dec 17. URL: https://www.n2yo.com/.\u00a0\u21a9</p> </li> <li> <p>T.S. Kelso. Celstrak. 1985. Accessed 2020 Dec 17. URL: http://www.celestrak.com.\u00a0\u21a9</p> </li> </ol>"},{"location":"productguide/ordering/","title":"Ordering ICEYE Products","text":"<p>ICEYE offers timely and reliable global SAR imaging. This section describes the tasking process for new ICEYE collections and how to order archived imagery from ICEYE\u2019s catalog. The type of SAR collections available to order are described in \"Types of SAR Collection\".</p>"},{"location":"productguide/ordering/#iceye-tasking","title":"ICEYE Tasking","text":"<p>To make things easier for our customers we have a simple tasking process for new images based on standard imaging configurations and simple time windows (Standard Orders). This provides you with the quickest and simplest way to order SAR imagery. More sophisticated requests can be placed using a Custom Order. </p>"},{"location":"productguide/ordering/#standard-orders","title":"Standard Orders","text":"<p>ICEYE Tasking Standard Orders are based on the concept of acquisition time windows. When placing an order, you can specify a list of timing requirements that define one or more time windows in which the desired images should be acquired.  This allows ICEYE to confirm that the images will be acquired during the specified time windows, without the need for you to review a preliminary feasibility study with exact acquisition times.</p> <p></p> Figure 1: Example of a single image order with an acquisition time window of 2 days. This order specifies that the image should be collected anytime between 4-October-2021 00:00 and 6-October-2021 00:00 <p></p> Figure 2: Example of an order for a stack of images with a repeat cycle of 20 days and an acquisition time window for each image of 14 days. <p>For existing customer, standard orders are submitted via email. To order, please fill out the Standard Order Form with your contact information, and be sure to specify all the required tasking options described in the paragraphs below. Once completed, please send your Standard Order Form and the optional AOI file to the COSP email address you were provided with during your account set up.</p> <p>New customers should complete this form on the ICEYE website. There may be a slight delay while your account is set up but after that you will be able to order data using the instructions on this page.</p> <p>Info</p> <p>The order form will be provided by COSP. If you need a new one please contact the COSP team using the information that you were provided with when your account was set up or contact the sales team </p> <p></p> Figure 3: Standard ICEYE Tasking order flow <p>The named recipients for that order will be notified via email once the order is received by the ICEYE Customer Operations and Satellite Planning (COSP) team.</p> <p>Once received, your order will be ingested into the ICEYE's planning system which will determine if the order can be confirmed within the area of interest  (AOI), and time windows that you have requested for the AOI.</p> <ul> <li>If the order can be fulfilled, you will be notified via email that your order has been accepted and the images will be scheduled for acquisition. Alternatives are provided if available.</li> <li>If the order cannot be fulfilled within the time constraints that you specified, you will be notified via email that your order cannot be completed.</li> </ul> <p>Please note that standard orders require no final confirmation from you. If your order is accepted, the images will be acquired and delivered to you.</p> <p>After an order is confirmed, ICEYE will make sure that your images are acquired, downlinked, processed, quality controlled and delivered to you. The exact acquisition times are determined by the acquisition time window that you chose when placing your order. </p>"},{"location":"productguide/ordering/#how-to-fill-in-a-standard-order-form","title":"How to fill in a standard order form","text":"<p>When placing a Standard Order you will need to specify and/or select from the following options available in the Imagery Order Form :</p> <ol> <li> <p>AOI: The Area of Interest in the form of a latitude/longitude pair in the WGS 84 coordinate system.  Alternatively, you can include a KML/KMZ, or geojson file as an attachment to your order.</p> </li> <li> <p>Acquisition type: Select whether you want a</p> <ul> <li>Single acquisition of the specified AOI</li> <li>Stack of images of the same AOI over a time period</li> </ul> </li> <li> <p>Timing information:  </p> <ul> <li>Start and End time for the order: This is the time range in which the order is valid. </li> <li>Acquisition time windows: Choose a time window according to the  precision that you require for each of the images that should be acquired.<ul> <li>Basic: Each image is acquired within a 14-day time window from your specified order start time and repeat cycle. This time window is ideal for non-time-critical monitoring applications that do not require precise acquisition times.</li> <li>Pro: Each image is acquired within a 2-day time window from your specified order start time and repeat cycle. This is our base level service, commonly used in applications that do not depend on exact acquisition times or geometries.</li> <li>Exact: Each image is acquired within a 2-hour time window from your specified order start time and repeat cycle.  This is our premium service, tailored for time-critical collections that do not require a precise imaging geometry. Note that for Exact time windows, you can optionally include an attachment with your desired exact acquisition times. This attachment can be the result of a feasibility study that you had previously requested or it can be generated directly by you using our published satellite ephemerides. Please see the section Optional Feasibility Studies below. </li> </ul> </li> <li>Repeat cycle: This is the time between the start of consecutive acquisition time windows. This information is only required for orders of image stacks (repeat acquisitions).</li> </ul> </li> <li> <p>Imaging Mode: Refer to Section \"Types of SAR Collection\" for more information on these imaging modes</p> <ul> <li>Strip</li> <li>Spot</li> <li>Spot Extended Area</li> <li>Scan </li> </ul> </li> </ol>"},{"location":"productguide/ordering/#feasibility-study-as-part-of-a-standard-order","title":"Feasibility Study as Part of a Standard Order","text":"<p>ICEYE customers can request a feasibility study at any time when considering placing a standard order request. Simply email the COSP team at the address your were given when your account was set up. You will need to provide an AOI, an imaging mode (or resolution), a time period and any possible additional instructions that you may require. The ICEYE Customer Operations and Satellite Planning Team will respond with a list of acquisition opportunities. Please note that Feasibility Studies are for informational purposes and do not reserve constellation capacity for the opportunities reported. The required constellation capacity to fulfill an order under the agreed time window is only reserved after ICEYE confirms an order. Please also note that feasibility studies are not required to place a standard order. You can eliminate the need for a feasibility study by accurately describing the time windows and other acquisition constraints that match your actual needs as part of your standard order.</p> <p></p> Figure 4: Feasibility studies can be requested before placing a standard order. <p>Sometimes you might like to perform your own feasibility studies and we encourage this. We have made sure our satellite ephemeris information is publicly available at celestrak<sup>1</sup> and n2yo.com<sup>2</sup>, and have provided step by step instructions on how to use the Swath Acquisition Viewer Software, SaVoir on the ICEYE website. Let us know how well this works for you.</p>"},{"location":"productguide/ordering/#custom-orders","title":"Custom Orders","text":"<p>Custom Tasking orders offer a higher level of flexibility when specifying tasking requirements you desire. In general, any options that are not available as part of standard order can be requested as part of a custom order.  Custom orders are initiated by submitting a Custom Order Form to the email address you received when your account was set up. Our tasking experts will study the feasibility of your request and will quote an acquisition plan for you to approve. New customers should contact the ICEYE sales team.</p> <p>The following are examples of options that are currently available as part of a custom order:</p> <ul> <li>Mosaics : Coverage of large areas by acquiring multiple images</li> <li>Custom AOI coverage requirements : Each acquired image must cover at least a minimum percentage of the area of interest.</li> <li>Local time deviation limits : Images belonging to a stack or mosaic collection should be acquired within a certain local time range. </li> <li>Long image size requirements : Images that exceed the standard frame size of the requested imaging mode to cover the desired AOI. For example, long Strip acquisitions.</li> <li>Azimuth angle deviation limits for stacks or mosaics : Images belonging to a stack or mosaic collection should be acquired within a certain azimuth angle range.</li> <li>Custom acquisition time windows not available as standard tasking options : For example 72-hour, or 96-hour time windows for each acquisition.</li> </ul> <p>Our tasking experts will be happy to try to accommodate any special tasking request that is required to meet your business needs.</p> <p></p> Figure 5: Custom ICEYE Tasking order flow."},{"location":"productguide/ordering/#quality-control-and-image-delivery","title":"Quality Control and Image Delivery","text":""},{"location":"productguide/ordering/#automatic-delivery","title":"Automatic delivery","text":"<p>All acquisition SAR data initially goes though an automated quick Quality Control process in which we ensure that it covers the intended target location. The data is then automatically and immediately delivered to your folder in the ICEYE SFTP server. This gives you access to the SAR data without delay.  </p>"},{"location":"productguide/ordering/#quality-control","title":"Quality Control","text":"<p>In addition to the automated quick Quality Control mentioned above, a detailed manual Quality Control is performed on all acquisition data. An ICEYE analyst will verify the acquired SAR Data conforms to the product specifications and that it does not contain any disqualifying ambiguities.</p>"},{"location":"productguide/ordering/#redelivery-if-required","title":"Redelivery (if required)","text":"<p>If defects are found during the detailed manual Quality Control steps, ICEYE will attempt to correct and redeliver the data to your SFTP folder as soon as possible. The most common type of defects that are detected and corrected in during Quality Control are geolocation inaccuracies. When performing Quality Control, sometimes ICEYE will have access to more refined satellite telemetry and orbit information that allows us to improve the geolocation accuracy. In such cases, the SAR data will be reprocessed to improve its geolocation accuracy and will be redelivered to you.</p>"},{"location":"productguide/ordering/#delivery-service-level","title":"Delivery service level","text":"<p>Automatic delivery will be completed within 8 hours of the data being acquired.  ICEYE will soon offer faster delivery times for customers that require near-real-time data.  New customers receive instructions from the Customer Operations and Satellite Planning team on how to access your SFTP account. Through the SFTP server, you will have access to download all of your SAR data. You will receive a notification (via email) every time a new acquisition has passed our detailed Quality Control process and the final version of the data is ready for you to download using your SFTP account.</p> <p>Info</p> <p>Images are stored in your SFTP account for a period of 30 days.</p>"},{"location":"productguide/ordering/#unforeseen-circumstances","title":"Unforeseen Circumstances","text":"<p>In very rare situations, it might not be possible to acquire an image within the agreed time window. In this case, the Customer Operations and Satellite Planning team will immediately inform you and will propose an extended acquisition time window or allow you to cancel the collection.</p>"},{"location":"productguide/ordering/#iceye-archive-imagery","title":"ICEYE Archive Imagery","text":"<p>As an ICEYE customer, you have access to a complete catalog of archive imagery that is available for ordering. This catalog is updated on a regular basis on your SFTP account. The catalog is available in kmz and geojson formats and it includes low resolution image thumbnails so you can get a feel for the content of the image. The archive catalog can be viewed in Google Earth, QGIS or your favorite GIS where you can browse image locations, filter by time or different image metadata and perform advanced searches. Please note that imagery is included in the ICEYE Archive Catalog at least seven days after its acquisition time.</p> <p></p> Figure 6: Browsing the ICEYE Archive catalog in Google Earth (kmz format). <p></p> Figure 7: Browsing the ICEYE Archive catalog in QGIS (geojson format). <p>Archive imagery orders can be submitted via email. To place an order, please fill out either the Standard Order Form or the Custom Order Form with your contact information, and include a list of the product names for the scenes that you wish to purchase. An example of a product name that identifies an image scene is :</p> <pre><code>ICEYE_ARCHIVE_SM_10306_20190918T125047\n</code></pre> <p>Once an order is received, the ICEYE Customer Success team will deliver the requested images to you within 12 hours (assuming a realistic number of archive images. eg. less than 50). Please note that all orders for archive imagery require no final confirmation from you. The images that you request in your order will be delivered to you. </p> <p></p> Figure 8: Archive imagery order flow. <p>Please note that orders for archive imagery do not go through additional quality control. However, if you are not satisfied with the quality of an archive image that you have received, you can make use of our return policy described below.</p>"},{"location":"productguide/ordering/#order-cancellation","title":"Order Cancellation","text":"<p>In order to support your evolving business requirements, ICEYE supports a user-friendly order cancellation policy.</p>"},{"location":"productguide/ordering/#cancellation-of-tasking-orders","title":"Cancellation of Tasking Orders","text":"<p>Standard Tasking orders confirmed by ICEYE can be cancelled free of charge up to 72 hours prior to the start of the acquisition time window.</p> <p>Custom Tasking orders may be cancelled or rescheduled within twenty four (24) hours after order confirmation at no cost, as long as the order is submitted at least 72 hours before the proposed data collection time. </p> <p>Cancellation policy conditions are presented in the table below. </p> CANCELLATION REQUEST TIME (HOURS) ADDITIONAL CONDITION CANCELLATION CHARGE Within 24 of order confirmation of a Custom Order Order submitted &gt;72h before the acquisition acquisition time window Free of charge More than 72h prior to the start of the acquisition time window N/A Free of charge 72 - 48h prior to the start of the acquisition time window N/A 10% of the image value 48 - 24h prior to the start of the acquisition time window N/A 20% of the image value Less than 24h prior to the start of the acquisition time window Order submitted &gt;24h before the start of the acquisition time window 100% of the image value Table 1: Cancellation Requests."},{"location":"productguide/ordering/#return-policy","title":"Return Policy","text":"<p>If you are not satisfied with your purchase, please contact our Customer Operations and Satellite Planning team at customer@iceye.com within 30 days of receiving your order. Your satisfaction is our priority, so we will work quickly to resolve your concerns. </p>"},{"location":"productguide/ordering/#invoicing","title":"Invoicing","text":"<p>ICEYE users can pay for imaging in a range of different ways in order to be as flexible as possible:</p> <ul> <li>Prepayment : In this option a number of images can be paid for up-front. When the prepayment has been paid, you can place orders and receive the amount of data up to your prepaid quota. This is designed for customers that know that they would like to purchase a number of images and offers imagery at a reduced rate.</li> <li>Net 30 : This is designed for larger or industrial customers wishing to purchase imagery in volume. In this case we will discuss your needs and enter into a contract with you. Images can then be tasked as and when you see fit and we will invoice you monthly. Payment then has to be made within 30 days of sending you the invoice.</li> </ul> <p>ICEYE Finance will send invoices during the first week of the month for all the products delivered to you within the previous month. The monthly invoice will not include the products that have been ordered but have not yet been delivered to you. If no products have been shipped to you during the previous month, invoice will not be extended.</p> <ol> <li> <p>T.S. Kelso. Celstrak. 1985. Accessed 2020 Dec 17. URL: http://www.celestrak.com.\u00a0\u21a9</p> </li> <li> <p>N2YO. Accessed 2020 Dec 17. URL: https://www.n2yo.com/.\u00a0\u21a9</p> </li> </ol>"},{"location":"productguide/sardataproducts/","title":"TYPES OF SAR DATA PRODUCTS","text":""},{"location":"productguide/sardataproducts/#product-types","title":"Product Types","text":"<p>SAR data can be made into a multitude of different product types. Some are better suited for human exploitation whereas others are better exploited by algorithms and signal-processing tools.</p> <p>On this page we describe the different SAR data products that ICEYE provides. Technical details about the format of these products, with some tips on how the use them are provided in the section on 'Technical Information'.</p> <p>Info</p> <p>The section \"What is SAR?\" provides a review of the technologies mentioned here. </p>"},{"location":"productguide/sardataproducts/#complex-images","title":"Complex Images","text":"<p>Unlike optical imagery, each pixel in a SAR image is represented as a complex number. The complex number represents two critical components of SAR imaging, amplitude and phase. The amplitude of a pixel is a measure of the amount of RADAR energy reflected back to the satellite and displayed as a grey-scale value when we look at a SAR image. The phase component is a measure of the position of the RADAR wave after it has interacted with all the scatterers within the pixel. After image formation, the phase information is usually discarded which reduces the size of the SAR image. Some advanced SAR capabilities such as interferometric SAR (INSAR) or coherent change detection (CCD) makes use of the phase information and therefore needs the complex image samples.</p> <p>All ICEYE images are available as Complex Datasets (with the exception of SCAN mode collections). More details about complex image file formats can be found in the 'Technical Information' section.</p>"},{"location":"productguide/sardataproducts/#complex-image-parameters","title":"Complex Image Parameters","text":"PARAMETER STRIP SPOT SPOT FINE DWELL DWELL FINE COMMENTS Focusing plane Slant Plane Slant Plane Slant Plane Slant Plane Slant Plane Slant range resolution [m] 0.5 to 2.5 0.5 0.25 0.5 0.25 Note 1 Slant azimuth resolution [m] 3 0.25 0.1 0.05 0.05 Impulse response weighing function (peak side level) Uniform (-13.3dB) Uniform (-13.3dB) Uniform (-13.3dB) Uniform (-13.3dB) Uniform (-13.3dB) Slant Range Sample Spacing [m] 0.4 to 2.4 &lt; 0.4 &lt; 0.2 &lt; 0.4 &lt; 0.2 Note 1 Slant Azimuth Sample Spacing [m] 1.6 &lt; 0.2 &lt; 0.09 &lt; 0.05 &lt; 0.05 Slant range product format HDF5 + XML HDF5 + XML HDF5 + XML HDF5 + XML HDF5 + XML SLC Product Size [GB] 3.4 to 2.9 0.6 to 7.2 &lt; 15 &lt; 15 &lt; 25 Dynamic Range (bits per pixel) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) Note 3 Table 1 : Parameters for ICEYE Complex Images <p>Info</p> <p>Complex Images are used for 'interferometric SAR' such as the formation of digital elevation models (DEM), land subsidence monitoring or coherent change analysis.</p>"},{"location":"productguide/sardataproducts/#amplitude-images","title":"Amplitude Images","text":"<p>These are the familiar SAR gray-scale images with amplitude-only pixels. They are \u201cmulti-looked\u201d to reduce the grainy effect of speckle, at the cost of slightly lower resolution. Amplitude images are projected to the ground surface and can be oriented with respect to the sensor or produced on an ellipsoid-based map projection. ICEYE produces amplitude images in the natural range-azimuth sensor orientation because they offer the most flexibility in exploitation. To be consistent with conventional terminology, these sensor-oriented images are called Ground Range Detected (GRD). This term may change in the future to be something more meaningful.</p> <p>Info</p> <p>Amplitude images are most useful for rapid observation of a location regardless of lighting or weather conditions.</p>"},{"location":"productguide/sardataproducts/#amplitude-image-parameters","title":"Amplitude Image Parameters","text":"PARAMETER STRIP SPOT/ SPOT EXTENDED AREA / DWELL SPOT FINE / DWELL FINE SCAN COMMENTS Nominal Ground Resolution [m] 3 1 0.5 15 Note 2 Ground Range Resolution [m] &lt; 3 1.46 to 0.78 0.73 to 0.39 &lt; 15 Note 1 Ground Azimuth Resolution [m] &lt; 3 &lt; 1 &lt; 0.5 &lt; 15 Impulse response weighing function (peak side level) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Ground Range Sample Spacing [m] 2.5 0.5 0.25 6 Ground Azimuth Sample Spacing [m] 2.5 0.5 0.25 6 Range Looks 1 1 1 1 Azimuth Looks 1 to 2 2 to 20 5 to 10 1 Note 3 Product format Geotiff + XML Geotiff + XML Geotiff + XML Geotiff + XML GRD Product Size [MB] 700 250 to 1500 &lt; 3000 800 Dynamic Range (bits per pixel) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) Note 4 Table 2 : Parameters for ICEYE Amplitude Images"},{"location":"productguide/sardataproducts/#notes-and-explanations","title":"Notes and Explanations","text":"<ol> <li>Slant Range Resolution: For Strip mode the transmitted bandwidth is varied to make sure that the resolution on the ground remains the same. For Spot mode the maximum bandwidth is transmitted at all times. This means that the slant resolution for Spot images is constant and the ground resolution changes with incidence angle.</li> <li>Nominal Ground Resolution:  Nominal ground resolution for all Spotlight modes (Spot, Spot Entended Area, Dwell and Spot fine) is the ground resolution at a 30\u00b0 incidence angle. </li> <li>Azimuth Looks: Spot amplitude images are produced using 4 looks, Spot Fine using 5 looks, Spot Extended Area using 2 looks, Dwell using 20 looks, and Dwell Fine using 10 looks.</li> <li>Complex Dynamic Range: A complex number with 16bit I and 16bit Q values. 32 bit float values can be provided by request.</li> </ol>"},{"location":"productguide/sardataproducts/#references","title":"References","text":"<ol> <li> <p>European Space Agency. The sentinel application platform - snap. Accessed 2020 Dec 17. URL: http://step.esa.int/main/toolboxes/snap/.\u00a0\u21a9</p> </li> </ol>"},{"location":"productguide/support/","title":"SUPPORT","text":""},{"location":"productguide/support/#customer-operations-and-satellite-planning-team","title":"Customer Operations and Satellite Planning Team","text":"<p>The Customer Operations and Satellite Planning (COSP) team is the department of ICEYE in charge of order processing and customer support. Customer Operations and Satellite Planning staff who interact directly with the customer are called Customer Operations and Satellite Planning Specialists. The responsibilities of the COSP Specialist are:</p> <ul> <li>Customer on-boarding and training</li> <li> <p>Customer order management:</p> <ul> <li>Receiving orders</li> <li>Confirming orders</li> <li>Processing orders</li> <li>Conducting Quality Control of the products</li> <li>Delivering orders</li> </ul> </li> <li> <p>Customer Communications regarding any issues within the framework of the current contract</p> </li> <li>Customer Satisfaction Surveys</li> <li>Improvement of the overall customer experience</li> </ul>"},{"location":"productguide/support/#working-hours","title":"Working Hours","text":"<p>The Customer Operations and Satellite Planning team is available 24 hours per day to answer any collection planning queries or to help you find solutions to technical problems.</p>"},{"location":"productguide/support/#contact-information","title":"Contact Information","text":"<p>The customer can reach out to the Customer Operations and Satellite Planning team via email to customer@iceye.com.</p>"},{"location":"productguide/typesofsarcollection/","title":"TYPES OF SAR COLLECTION","text":"<p>ICEYE satellites operate in one of three primary imaging modes called Strip Mode, Spot Mode and Scan Mode. These are available in both right and left-looking configurations. The design flexibility of our satellites allows their imaging modes to be continually evolved. We will be adding more modes, and more flexible illumination patterns, in future versions. A recent addition is an augmentation to our spotlight collections that we are calling Dwell imaging. </p> <p>On this page we provide an overview of each of the imaging modes. How the collection modes are packaged and delivered is covered in the section on SAR data products. Technical details on the content of the data products and how to exploit them is covered in the Technical information section. An explanation of SAR and how the imaging modes are collected can be found in An Overview of SAR Imaging.</p>"},{"location":"productguide/typesofsarcollection/#strip-imaging","title":"Strip Imaging","text":"<p> In this mode the ground swath is illuminated with a continuous sequence of pulses while the antenna beam is fixed in its orientation. The beam is pointed off to the side of the satellite at an angle broadside to the satellite flight path. This results in a long image strip parallel to the flight direction.</p> <p>ICEYE standard Strip products have a ground resolution of 3m in range and azimuth and cover an area of 30km (range) by 50km (azimuth). The strip length can be tailored up to a length of 840 km, in increments of 50 km.</p> <p>Info</p> <p>Having a wide area and a moderate resolution, Strip images are useful for 'situational awareness'. They allow a user to quickly asses what is occurring in the region. They are particularly useful for tasks such as deforestation monitoring, or iceberg / glacier monitoring. They are also our 'first responder' product in times of natural disaster to assess the impact of a flood, earthquake or volcano.</p>"},{"location":"productguide/typesofsarcollection/#scan-imaging","title":"Scan Imaging","text":"<p> This mode uses each satellite's phased array antenna to create multiple beams in the elevation direction. This beam steering illuminates a wide area via multiple adjacent strips, but it means that points on the ground are not illuminated for as long as conventional Strip Mode. This reduces the resolution of a Scan product.</p> <p>In conventional scan mode, ground points are illuminated by different parts of the radar beam resulting in brighter and darker regions in the image. We compensate for this in our scan by also steering the radar beam sideways during each burst of radar pulses. This improves image quality. This technique is called Terrain Observation by Progressive Scans (TOPS or TOPSAR<sup>1</sup>). Our Scan product produces imagery that covers an area of 100km x 100km with a resolution better than 15m. The length of a Scan product can be increased to 840km.</p> <p>Note</p> <p>Having the largest area coverage and a modest resolution, Scan images are highly suited to wide area surveillance and mapping projects. Being able to operate in all weather and lighting conditions, they provide an excellent opportunity to image the oceans and to detect ships and monitor shipping lanes.</p> <p>Caution</p> <p>Scan mode products are not radiometrically calibrated. Whilst imagery is visually and spatially exploitable, there may be slight errors when converting image sample values to a mean RADAR cross section number.</p> PARAMETER STRIP SCAN COMMENTS Product Short Name 'SM' 'SC' Note 1 Nominal final product ground resolution [m] 3 15 Radar Beams Used 1 4 Note 2 Nominal swath width [km] 30 100 Note 3 Nominal product length (Azimuth Direction) [km] 50 100 Note 4 Nominal collection duration [sec] 10 15 Maximum collection duration [sec] 120 120 Note 5 Maximum Scene Length [km] 840 840 Note 5 Noise Equivalent Sigma-Zero [ dBm<sup>2</sup>/m<sup>2</sup> ] -21.5 to -20 -22.2 to -21.5 Note 6 Azimuth Ambiguity Ratio [dB] -17 -17 Range Ambiguity Ratio [dB] &lt;-20 &lt;-20 Geospatial Accuracy [m RMSE] 6 15 Note 14 ESA Copernicus Contributing Mission (CCM) Class<sup>2</sup> VHR2 VHR2 Polarization VV VV RNIIRS 3.6 2.1 Note 8 RGIQE [bits/\\(m^2\\)] 0.8 0.1 Note 9 Performant Incidence Range [deg] 15-35 21-29 Note 12 Time Dominant Incidence Range [deg] 5-45 N/A Note 13 Table 1 : ICEYE Strip and Scan Imaging Summary"},{"location":"productguide/typesofsarcollection/#spotlight-modes","title":"Spotlight Modes","text":""},{"location":"productguide/typesofsarcollection/#spot-imaging","title":"Spot Imaging","text":"<p> In Spot mode the radar beam is steered to illuminate a fixed point. This increases the illumination time and therefore increases the length of the synthetic aperture and improves azimuth resolution. </p> <p>ICEYE's Spot collection  uses a 300 MHz transmit bandwidth and covers an area of 5km x 5km. This produces an image with a 1 meter ground resolution for multi-looked amplitude images. These are formed from 4 independent looks to suppress speckle and increase image quality.</p> <p>Note</p> <p>Spot images are useful for more detailed investigation of an area. They are used primarily to discriminate between different types of object such as boats or ships, different aircraft, or different types of building or infrastructure. The additional resolution also helps with coherence analysis techniques such as INSAR.</p>"},{"location":"productguide/typesofsarcollection/#spot-fine","title":"Spot Fine","text":"<p>Spot Fine is the utilizes the same collection strategy as Spot mode, but transmits at a 600 MHz transmit bandwidth to achieve a much higher resolution. It operates the same way as Spot mode, by pointing the RADAR beam at a single location for an extended amount of time. Each Spot Fine collection takes 15 seconds or radar illumination time to collect. Spot Fine amplitude images have a nominal groud resolution of 0.5 meters and are formed out of 5 independent looks.  </p> PARAMETER SPOT SPOT FINE COMMENTS Product Short Name 'SLH' 'SLF' Note 1 Nominal final product ground resolution [m] 1 0.5 Radar Beams Used 1 1 Note 2 Nominal swath width [km] 5 5 Note 3 Nominal product length (Azimuth Direction) [km] 5 5 Note 4 Nominal collection duration [sec] 10 15 Maximum collection duration [sec] N/A N/A Note 5 Maximum Scene Length [km] 5 5 Note 5 Noise Equivalent Sigma-Zero [ dBm<sup>2</sup>/m<sup>2</sup> ] -18 to -15 -15 to -11 Note 6 Azimuth Ambiguity Ratio [dB] -17 -17 Range Ambiguity Ratio [dB] &lt;-20 &lt;-20 Geospatial Accuracy [m RMSE] 6 6 Note 14 ESA Copernicus Contributing Mission (CCM) Class<sup>2</sup> VHR1 VHR1 Polarization VV VV RNIIRS 5.5 6.3 Note 8 RGIQE [bits/\\(m^2\\)] 22 83 Note 9 Performant Incidence Range [deg] 20-40 20-40 Note 12 Time Dominant Incidence Range [deg] 5-45 5-45 Note 13 Table 2 : ICEYE Spot and Spot Fine Summary"},{"location":"productguide/typesofsarcollection/#spot-extended-area","title":"Spot Extended Area","text":"<p>In Spotlight Extended Area (SLEA) mode we take a spotlight image by pointing the satellite at a location farther away, instead of at a point on the ground. The spot is seen to 'slide' over the ground which is why SLEA is also known as Sliding Spot mode. This means that more area is imaged than in standard Spot mode, but also each pixel in the scene is now no longer illuminated over the same range of angles. This implies a reduced resolution, but we can recover that by starting the spotlight operation earlier and finishing later.</p> <p>Within the covered area of 15km x 15km we achieve a 1 m ground resolution for multi-looked amplitude images. In comparison to the Spot mode we trade off a number of looks for extra area covered in SLEA. The Spot mode has 4 looks while SLEA has 1-2 looks instead. Due to the smaller number of looks the speckle noise in the imagery is slightly higher.</p> <p>Note</p> <p>The coverage of SLEA is a really nice choice because we can get a nine times greater coverage and the same ground resolution as with standard Spot mode. The SLEA mode can also be seen as big improvement over the Strip mode while still covering a quite large area of interest.</p> <p>.</p> PARAMETER SPOT EXTENDED AREA COMMENTS Product Short Name 'SLEA' Note 1 Nominal final product ground resolution [m] 1 Radar Beams Used 1 Note 2 Nominal swath width [km] 15 Note 3 Nominal product length (Azimuth Direction) [km] 15 Note 4 Nominal collection duration [sec] 10 Maximum collection duration [sec] N/A Note 5 Maximum Scene Length [km] 15 Note 5 Noise Equivalent Sigma-Zero [ dBm<sup>2</sup>/m<sup>2</sup> ] -18 to -15 Note 6 Azimuth Ambiguity Ratio [dB] -17 Range Ambiguity Ratio [dB] &lt;-20 Geospatial Accuracy [m RMSE] 6 Note 14 ESA Copernicus Contributing Mission (CCM) Class<sup>2</sup> VHR1 Polarization VV RNIIRS 5.5 Note 8 RGIQE [bits/\\(m^2\\)] 8.4 Note 9 Performant Incidence Range [deg] 20-40 Note 12 Time Dominant Incidence Range [deg] 5-45 Note 13 Table 3 : ICEYE Spot Extended Area Imaging Summary"},{"location":"productguide/typesofsarcollection/#dwell","title":"Dwell","text":"<p>ICEYE's Dwell collection mode is a very long spotlight mode SAR collection. The technique is not so easy to achieve with larger satellites, but the smaller mass and antenna size of ICEYE satellites allows them to stare at the same point for as long as 25 seconds. This results in a very fine azimuth resolution. Dwell mode utilizes a 300 MHz bandwidth which results in a nominal 1m ground resolution. The additional information acquired in the azimuth direction is utilized to form highy multi-looked amplitude products (20 looks) with significantly reduced speckle. Additionally, 'Color Sub-Aperture Image (CSI)' product and 'SAR Video' are produced form Dwell acquisitions.</p> <p>Note</p> <p>Dwell imaging is a good collection strategy for getting the most information from complex scenes, such as human objects in forested areas or moving objects such as ships.</p>"},{"location":"productguide/typesofsarcollection/#dwell-fine","title":"Dwell Fine","text":"<p>Dwell Fine is the utilizes the same collection strategy as Dwell mode, but transmits at a 600 MHz transmit bandwidth to achieve a much higher resolution. It operates the same way as Dwell mode, staring at the same point for 25 seconds. Dwell amplitude images have a nominal ground resolution of 0.5 meters and are formed out of 10 independent looks. Dwell Fine acquisitions also include 'Color Sub-Aperture Image (CSI)' product and 'SAR Video'. </p> PARAMETER DWELL DWELL FINE COMMENTS Product Short Name 'DWELL' 'DWELL FINE' Note 1 Nominal final product ground resolution [m] 1 0.5 Radar Beams Used 1 1 Note 2 Nominal swath width [km] 5 5 Note 3 Nominal product length (Azimuth Direction) [km] 5 5 Note 4 Nominal collection duration [sec] 25 25 Maximum collection duration [sec] 30 30 Note 5 Maximum Scene Length [km] 5 5 Note 5 Noise Equivalent Sigma-Zero [ dBm<sup>2</sup>/m<sup>2</sup> ] -18 to -15 -18 to -15 Note 6 Azimuth Ambiguity Ratio [dB] -17 -17 Range Ambiguity Ratio [dB] &lt;-20 &lt;-20 Geospatial Accuracy [m RMSE] 6 6 Note 14 ESA Copernicus Contributing Mission (CCM) Class<sup>2</sup> VHR1 VHR1 Polarization VV VV RNIIRS 6.4 6.7 Note 8 RGIQE [bits/\\(m^2\\)] 125 185 Note 9 Performant Incidence Range [deg] 20-40 20-40 Note 12 Time Dominant Incidence Range [deg] 5-45 5-45 Note 13 Table 4 : ICEYE Dwell and Dwell Fine Imaging Summary"},{"location":"productguide/typesofsarcollection/#notes-and-explanations","title":"Notes and Explanations","text":"<ol> <li>Short Name: For example, Strip mode has 'SM' : ICEYE_X7_GRD_SM_36535_20201020T175609</li> <li>Radar Beams: The current generation of ICEYE satellites use electronically steered elements to control multiple radar beams. Usually this is only one beam but Scan products use multiple beams to image different ranges (at the cost of reduced resolution) </li> <li>Nominal Swath Width: The actual image size will be slightly larger than this to guarantee that the tasked area is covered.</li> <li>Nominal Swath Length: The actual image length may be slightly larger to guarantee that the tasked area is covered. The maximum value can vary from satellite to satellite due to power/data/thermal limitations.</li> <li>Maximum Collection Duration/Length: Spot images do not have a maximum collection duration as they image for the required amount of time to obtain a tasked azimuth resolution. For Strip and Scan modes the maximum collection duration (and therefore the maximum image length) is limited by the amount of on-board memory storage or satellite thermal limitations. As different incidence angles have different slant range resolutions in order to provide the same ground range resolution, then the maximum collection duration is also a function of incidence angle. </li> <li>NESZ: The noise equivalent sigma zero values are taken at scene center for near and far range extents.</li> <li>Slant Range Resolution: For Strip mode the transmitted bandwidth is varied to make sure that the resolution on the ground remains the same. For Spot mode the maximum bandwidth is transmitted at all times. This means that the slant resolution for Spot images is constant and the ground resolution changes with incidence angle.</li> <li>RNIIRS: Radar National Imagery Interpretability Rating Scale is a subjective assessment of Radar Image Quality used primarily by military analysts. The scale is from 0 (\"interpretability of the imagery is precluded by obscuration, degradation, or very poor resolution\") to the highest quality figure of merit, 10 <sup>3</sup>.</li> <li> <p>RGIQE: This is the Radar General Image Quality Equation. It is an adaptation of the concept of a General Image Quality Equation <sup>4</sup> Developed by NGA . Unlike the RNIIRS scale which is a largely subjective assessment of image quality, the RGIQE uses maximum channel capacity (measured in bits of information) as a figure of merit. From the Shannon-Hartley Theorem <sup>5</sup> the maximum information that can be carried in a signal (conventionally called a channel due to the origins in communications) is given by :</p> \\[ C = B \\log_2\\left(1+\\frac{S}{N}\\right) \\] <p>Where \\(C\\) is measured in bits per second, \\(B\\) is the bandwidth of the system and \\(\\frac{S}{N}\\) is the signal to noise ratio. Recognising that a resolution cell in a SAR image is ultimately defined in range by the transmitted bandwidth and in azimuth by the Doppler bandwidth, a measure of the maximum information content of a resolution cell in bits/\\(m^2\\) can be formulated :</p> \\[ I = B_{az} B_{R_{ground}} \\log_2\\left(1 + \\frac{S}{N}\\right) \\] <p>Where \\(I\\) is the information content measured in bits/\\(m^2\\), \\(B_{az}\\) is the Doppler bandwidth used to form the azimuth extent of a pixel and \\(B_{R_{ground}}\\) is the range bandwidth in the ground plane used to form the range extent of a pixel. The noise in this case is made up from all the  noise elements that contribute to reduced image quality in the final image (Thermal noise, quantization noise, sidelobes, ambiguities). In this scale the higher the figure then the more 'information' is available for exploitation within the pixel.</p> </li> <li> <p>Complex Dynamic Range: A complex number with 16bit I and 16bit Q values. 32 bit float values can be provided by request.</p> </li> <li>Amplitude Dynamic Range: Stored as an unsigned 16 bit integer. 32 bit float values can be provided by request.</li> <li>Performant Incidence Range: This is the nominal or standard range of incidence angles that the ICEYE Fleet operates over. The parameters in these tables are correct within this range of angles.</li> <li>Time  Dominant  Incidence Range: Being quite small and agile, and having an electronically steered antenna, ICEYE satellites can collect radar imagery from a wide range of angles. Outside of the Performant Incidence Range, SAR image quality may be degraded. However in some situations it may be more important to obtain a SAR image quickly rather than wait for an opportunity to image the location with the performant range of angles. For this reason ICEYE offers time dominant tasking as either a Tactical or a Custom order.</li> <li>Geospatial Accuracy: Each satellite in the ICEYE fleet is periodically evaluated against ground based calibration targets to obtain the geospatial accuracy of the system. This process involves measuring the location of each target in the SAR imagery after the image has been terrain corrected (see here for why this step is essential) and comparing the location to the known ground truth. Each calibration target will have its own slightly different error. The RMSE is the root mean square error of all the measured calibration points from all the satellites.</li> </ol>"},{"location":"productguide/typesofsarcollection/#references","title":"References","text":"<ol> <li> <p>F. De Zan and A. Monti Guarnieri. Topsar: terrain observation by progressive scans. IEEE Transactions on Geoscience and Remote Sensing, 44(9):2352\u20132360, 2006. doi:10.1109/TGRS.2006.873853.\u00a0\u21a9</p> </li> <li> <p>V. Amans B. Hoersch. Copernicus Space Component Data Access Portfolio: Data Warehouse 2014 - 2020. resolution classes for EO SAR Image products. ESRIN, ESA, Via Galileo Galilei Casella Postale 64 00044 Frascati Italy, March 2015. URL: https://spacedata.copernicus.eu/documents/20126/0/DAP_Release_Phase_2_1.0_final.pdf.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>National Geospatial-Intelligence Agency (NGA). National imagery interoperability rating scale standards 2017-03-10 version 1.1.1. December\u00a04 2019. URL: https://nsgreg.nga.mil/doc/view?i=5104.\u00a0\u21a9</p> </li> <li> <p>Jon C Leachtenauer, William Malila, John Irvine, Linda Colburn, and Nanette Salvaggio. General image-quality equation: giqe. Applied optics, 36(32):8322\u20138328, 1997.\u00a0\u21a9</p> </li> <li> <p>Claude E Shannon. Communication in the presence of noise. Proceedings of the IEEE, 72(9):1192\u20131201, 1984.\u00a0\u21a9</p> </li> </ol>"}]}