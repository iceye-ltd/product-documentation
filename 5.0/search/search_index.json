{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"WELCOME How To Read This Document Previously if you wanted to find out about ICEYE satellites or our data we asked you to check out our Product Guide in pdf format. This is still available for download but we thought that it wasn't as easy to read or use as a more interactive web-based set of documents. Thats what this site is (and hopefully a bit more). If you want to learn more about ICEYE the company, its initiatives and projects then we would encourage you to visit the ICEYE website . It has many examples and stories about the company, what it has done and where it wants to go. The list of contents on the left should guide you through the information you need from this site in a sensible order. First there is a description of the current ICEYE Fleet of satellites with some useful information on where each satellite is right now. This is followed by a section on ICEYE data products . This is where you can find out about the different types of SAR images you can buy and contains a useful summary of what performance parameters you can expect when you receive your imagery. Once you know what ICEYE data products best support your requirements, you will want to know how to order some imagery. This is covered in the next section on Ordering SAR imagery . This section also describes the level of support you can expect to receive. The next section is for those users that want to explore the techical content of their ICEYE SAR imagery. It contains the product specification for each image product and describes how each imaged is stored and formatted. It also contains details of all the metadata elements stored in ICEYE images. It provides some guides and explanations on some foundation principles related to the practical exploitation of SAR imagery. Following this is a section for those curious to understand how SAR works . SAR truly is an amazing type of imaging sensor with many unique properties that are all too easy to overlook so we pulled this section together to explain the basic principles. The last section provides a teaser of some of the things we are working on now and expect to make available to customers in the near future. Finally, if you are not quite sure where to find what you are looking for you can just type a short query in the search bar at the top of each page. How To Get in Touch - http://iceye.com - @ICEYEcom \u2013 @iceyefi \u2013 @iceye \u2013 https://www.linkedin.com/company/iceye/","title":"Welcome"},{"location":"#welcome","text":"","title":"WELCOME"},{"location":"#how-to-read-this-document","text":"Previously if you wanted to find out about ICEYE satellites or our data we asked you to check out our Product Guide in pdf format. This is still available for download but we thought that it wasn't as easy to read or use as a more interactive web-based set of documents. Thats what this site is (and hopefully a bit more). If you want to learn more about ICEYE the company, its initiatives and projects then we would encourage you to visit the ICEYE website . It has many examples and stories about the company, what it has done and where it wants to go. The list of contents on the left should guide you through the information you need from this site in a sensible order. First there is a description of the current ICEYE Fleet of satellites with some useful information on where each satellite is right now. This is followed by a section on ICEYE data products . This is where you can find out about the different types of SAR images you can buy and contains a useful summary of what performance parameters you can expect when you receive your imagery. Once you know what ICEYE data products best support your requirements, you will want to know how to order some imagery. This is covered in the next section on Ordering SAR imagery . This section also describes the level of support you can expect to receive. The next section is for those users that want to explore the techical content of their ICEYE SAR imagery. It contains the product specification for each image product and describes how each imaged is stored and formatted. It also contains details of all the metadata elements stored in ICEYE images. It provides some guides and explanations on some foundation principles related to the practical exploitation of SAR imagery. Following this is a section for those curious to understand how SAR works . SAR truly is an amazing type of imaging sensor with many unique properties that are all too easy to overlook so we pulled this section together to explain the basic principles. The last section provides a teaser of some of the things we are working on now and expect to make available to customers in the near future. Finally, if you are not quite sure where to find what you are looking for you can just type a short query in the search bar at the top of each page.","title":"How To Read This Document"},{"location":"#how-to-get-in-touch","text":"- http://iceye.com - @ICEYEcom \u2013 @iceyefi \u2013 @iceye \u2013 https://www.linkedin.com/company/iceye/","title":"How To Get in Touch"},{"location":"about/","text":"WELCOME TO ICEYE Your Choice for Persistent Monitoring ICEYE empowers commercial and government partners with unmatched persistent monitoring capabilities for any location on Earth. We do this with our continually growing SAR satellite constellation, currently in orbit and delivering SAR data. This product guide reviews our constellation, products, imaging modes and ordering process. This is a living document because our innovative small SARs are flexible and they welcome our routine upgrades to their resolution, coverage and quality. We\u2019ll release new versions of this guide as we improve our sensors, expand our constellation, and streamline our order and delivery systems. SAR sensors see through clouds and darkness. They measure pulse echoes with a precision much smaller than a single wavelength. Their resolution is independent of distance. They are capable of pristine geolocation, and they are change detection machines. We Look Forward to Serving You The Small SAR Revolution in Earth Imaging During the Middle Ages, if you wanted to understand the way the world worked you would consult your local religious leader. A Priest or Prophet would interpret the Word of God from beautifully written tomes that were transcribed by hand over many years. These books were ornate and so precious that they could not be widely distributed, and most people did not know how to read. In these years, the thoughts of nations were controlled by various religious and political leaders. Then everything changed. The Renaissance and Reformation spurred new ways of thinking, and their ideas were recorded in printed books that were produced at low cost and in great volumes. People learned to read for themselves and think for themselves. Information spread across the globe. Sometimes disruption can be good. Hundreds of years later, in 2012, a small team of students working in the Nanosatellite Group of Aalto University considered the sequestered world of earth observation. The team was bothered by the limitations of government satellite programs in the same way that Renaissance and Reformation advocates challenged the knowledge control of the Middle Ages. Satellite imagery has been mostly provided by massive, government-owned or government-sponsored, exquisite systems. Like the tomes of old, these are beautifully implemented and precious. But normal people rarely have access to their images, and even when they are available, they do not have the timeliness to support the quick decisions needed in this rapidly changing world. The Nanosatellite students thought that timely, always available fine-resolution imagery should become a part of everyday life in the 21st century in the same way that GPS became integrated to nearly all businesses in the last decade of the 20th century. The humanitarian applications of easily-accessible imagery would include earthquakes, floods, volcanoes, glacial flow, and numerous environmental indicators. But if earth-observation imagery were to become as available, reliable and timely as the pace of our modern lives requires, things needed to change. Fueled by curiosity, passion, and long, dark Helsinki nights, the students decided that Synthetic Aperture Radar (SAR) would be the most useful way to obtain guaranteed, all-weather, day-night, observations of this cloud-covered planet. They reconsidered the conventional thinking regarding the mass and size needed to build SAR satellites, and then developed experimental sensors to prove and revise their thinking. In 2015 ICEYE Oy was born. And thanks to several backers who shared our vision, on January 12th, 2018 the world\u2019s first micro-SAR satellite was launched. In contrast to the existing SAR systems that each weigh several tons, our ICEYE-X1 weighed only 75kg. It provided beautiful 3-meter resolution imagery, and it allowed our company to evaluate many natural disasters. The ICEYE fleet is now growing rapidly. We began 2021 with 7 satellites, and we\u2019ll expand this to a constellation of 18 by mid-2022. Change is natural to our flexible systems. We upgrade our satellites the way programmers update code. Our resolution and coverage improves with each new version. And our low-cost, low-mass satellites are so highly maneuverable that we can reposition them to optimize revisit rates and support global change detection. We will bring our users access to highly accurate, highly reliable monitoring, whenever and wherever they need it, at a pace that has never before existed. Welcome to the Earth Observation Renaissance ! Read The ICEYE Story","title":"About"},{"location":"about/#welcome-to-iceye","text":"","title":"WELCOME TO ICEYE"},{"location":"about/#your-choice-for-persistent-monitoring","text":"ICEYE empowers commercial and government partners with unmatched persistent monitoring capabilities for any location on Earth. We do this with our continually growing SAR satellite constellation, currently in orbit and delivering SAR data. This product guide reviews our constellation, products, imaging modes and ordering process. This is a living document because our innovative small SARs are flexible and they welcome our routine upgrades to their resolution, coverage and quality. We\u2019ll release new versions of this guide as we improve our sensors, expand our constellation, and streamline our order and delivery systems. SAR sensors see through clouds and darkness. They measure pulse echoes with a precision much smaller than a single wavelength. Their resolution is independent of distance. They are capable of pristine geolocation, and they are change detection machines. We Look Forward to Serving You","title":"Your Choice for Persistent Monitoring"},{"location":"about/#the-small-sar-revolution-in-earth-imaging","text":"During the Middle Ages, if you wanted to understand the way the world worked you would consult your local religious leader. A Priest or Prophet would interpret the Word of God from beautifully written tomes that were transcribed by hand over many years. These books were ornate and so precious that they could not be widely distributed, and most people did not know how to read. In these years, the thoughts of nations were controlled by various religious and political leaders. Then everything changed. The Renaissance and Reformation spurred new ways of thinking, and their ideas were recorded in printed books that were produced at low cost and in great volumes. People learned to read for themselves and think for themselves. Information spread across the globe. Sometimes disruption can be good. Hundreds of years later, in 2012, a small team of students working in the Nanosatellite Group of Aalto University considered the sequestered world of earth observation. The team was bothered by the limitations of government satellite programs in the same way that Renaissance and Reformation advocates challenged the knowledge control of the Middle Ages. Satellite imagery has been mostly provided by massive, government-owned or government-sponsored, exquisite systems. Like the tomes of old, these are beautifully implemented and precious. But normal people rarely have access to their images, and even when they are available, they do not have the timeliness to support the quick decisions needed in this rapidly changing world. The Nanosatellite students thought that timely, always available fine-resolution imagery should become a part of everyday life in the 21st century in the same way that GPS became integrated to nearly all businesses in the last decade of the 20th century. The humanitarian applications of easily-accessible imagery would include earthquakes, floods, volcanoes, glacial flow, and numerous environmental indicators. But if earth-observation imagery were to become as available, reliable and timely as the pace of our modern lives requires, things needed to change. Fueled by curiosity, passion, and long, dark Helsinki nights, the students decided that Synthetic Aperture Radar (SAR) would be the most useful way to obtain guaranteed, all-weather, day-night, observations of this cloud-covered planet. They reconsidered the conventional thinking regarding the mass and size needed to build SAR satellites, and then developed experimental sensors to prove and revise their thinking. In 2015 ICEYE Oy was born. And thanks to several backers who shared our vision, on January 12th, 2018 the world\u2019s first micro-SAR satellite was launched. In contrast to the existing SAR systems that each weigh several tons, our ICEYE-X1 weighed only 75kg. It provided beautiful 3-meter resolution imagery, and it allowed our company to evaluate many natural disasters. The ICEYE fleet is now growing rapidly. We began 2021 with 7 satellites, and we\u2019ll expand this to a constellation of 18 by mid-2022. Change is natural to our flexible systems. We upgrade our satellites the way programmers update code. Our resolution and coverage improves with each new version. And our low-cost, low-mass satellites are so highly maneuverable that we can reposition them to optimize revisit rates and support global change detection. We will bring our users access to highly accurate, highly reliable monitoring, whenever and wherever they need it, at a pace that has never before existed. Welcome to the Earth Observation Renaissance ! Read The ICEYE Story","title":"The Small SAR Revolution in Earth Imaging"},{"location":"comingsoon/","text":"The Advantage Of Experimentation Having a flexible constellation of SAR satellites provides a rich source of experimental data. Here we present some of the ideas that we feel confident enough to share. Not everything here will make it into the wild but if you like some of these, or even have your own ideas, then we would love to hear from you. SAR Video You have probably seen the video. Because ICEYE satellites can stare at a point for a long time, it allows us to make a video of the ground. We have been making animated gifs from these for a while now but these are hardly exploitable by scientists. We have an idea though on how to present SAR video in a way that the geospatial community can use. SAR Video Orbital Demonstration Color Multilook Extended Dwell Imaging This is related to SAR Video as it uses the satellite's agility to collect an image over a wide range of angles. We noticed that some objects are more visible when observed from certain directions. The color multilook image may present more options to detect subtle objects in SAR imagery like powerlines or moving targets. Orthorectified imagery This is a tricky one for ICEYE. We hate the way that orthorectified imagery warps and distorts our beautiful imagery and as SAR professionals we prefer to use GIS tools to correct for SAR layover and geometric distortions. But we have come to realise that there are still a lot of people out there that just want to buy a map-like product. So we are going to do our best to provide it. Access to Phase History Data At ICEYE we want to demystify SAR and encourage people to learn about signal processing and make their own SAR images from our data. We think that a good way to do this is to provide raw radar pulse data in a standardised way (eg the NGA CPHD format) so that others can use our received RF signal. Its very niche but may be new developments and applications will come from it thereby making SAR more useful and accessible.","title":"Coming Soon"},{"location":"comingsoon/#the-advantage-of-experimentation","text":"Having a flexible constellation of SAR satellites provides a rich source of experimental data. Here we present some of the ideas that we feel confident enough to share. Not everything here will make it into the wild but if you like some of these, or even have your own ideas, then we would love to hear from you.","title":"The Advantage Of Experimentation"},{"location":"comingsoon/#sar-video","text":"You have probably seen the video. Because ICEYE satellites can stare at a point for a long time, it allows us to make a video of the ground. We have been making animated gifs from these for a while now but these are hardly exploitable by scientists. We have an idea though on how to present SAR video in a way that the geospatial community can use. SAR Video Orbital Demonstration","title":"SAR Video"},{"location":"comingsoon/#color-multilook-extended-dwell-imaging","text":"This is related to SAR Video as it uses the satellite's agility to collect an image over a wide range of angles. We noticed that some objects are more visible when observed from certain directions. The color multilook image may present more options to detect subtle objects in SAR imagery like powerlines or moving targets.","title":"Color Multilook Extended Dwell Imaging"},{"location":"comingsoon/#orthorectified-imagery","text":"This is a tricky one for ICEYE. We hate the way that orthorectified imagery warps and distorts our beautiful imagery and as SAR professionals we prefer to use GIS tools to correct for SAR layover and geometric distortions. But we have come to realise that there are still a lot of people out there that just want to buy a map-like product. So we are going to do our best to provide it.","title":"Orthorectified imagery"},{"location":"comingsoon/#access-to-phase-history-data","text":"At ICEYE we want to demystify SAR and encourage people to learn about signal processing and make their own SAR images from our data. We think that a good way to do this is to provide raw radar pulse data in a standardised way (eg the NGA CPHD format) so that others can use our received RF signal. Its very niche but may be new developments and applications will come from it thereby making SAR more useful and accessible.","title":"Access to Phase History Data"},{"location":"glossary/","text":"Terminology, Acronyms and Symbols SAR Glossary TERM DEFINITION Azimuth Direction aligned with the relative spaceborne platform velocity vector. Detection Processing step in which the phase information is removed and only the signal amplitude is preserved. Normally the detection uses a magnitude squared method and has units of voltage square per pixel. Focusing Data processing finalized to focus the SAR image in range and azimuth through bidimensional signal compression. Geocoded The data contains geographic information or coordinates corresponding to the location of the data. Georeference The internal coordinate system of the image can be related to a ground system of geographic coordinates Ground range Projection of the slant range into the ground. Incidence angle Local incidence angle on ground calculated using the ellipsoidal Earth model. Looks Image obtained using only part of the spectrum to focus the image (subaperture). It can be done in range and in azimuth, and normally is used to reduce the speckle noise from SAR images through incoherent sum (multi-look process). Range Direction orthogonal to the satellite velocity. Slant range vector Line-Of-Sight distance between the antenna and the target on ground. Slant range plane Plane containing the relative sensor velocity vector and the slant range vector for a given target. | Orthorectification |A subtopic of georeferencing\u2014 The process of converting images into a form suitable for maps by removing sensor motion and terrain-related geometric distortions from raw imagery. | List of Acronyms TERM DEFINITION ASCII American Standard Code for Information Interchange BSD Berkeley Software Distribution CF Calibration Factor Cn Coefficient \u2018n\u2019 in a polynomial DC Doppler Centroid DN Digital Number ECEF Earth-Centered, Earth-Fixed GR Ground Range GRD Ground Range Detected GRSR Ground Range to Slant Range conversion HDF Hierarchical Data Format KML Keyhole Markup Language PNG Portal Network Graphics PRF Pulse Repetition Frequency RMSE Root Mean Square Error RPC Rapid Positioning Capability (or Rational Polynomial Coefficient) SR Slant Range SAR Synthetic Aperture Radar SLC Single Look Complex UTC Coordinated Universal Time VV Polarization (Vertical transmitted and Vertical received) WGS84 World Geodetic System (1984) XML eXtensible Markup Language","title":"Terminology"},{"location":"glossary/#terminology-acronyms-and-symbols","text":"","title":"Terminology, Acronyms and Symbols"},{"location":"glossary/#sar-glossary","text":"TERM DEFINITION Azimuth Direction aligned with the relative spaceborne platform velocity vector. Detection Processing step in which the phase information is removed and only the signal amplitude is preserved. Normally the detection uses a magnitude squared method and has units of voltage square per pixel. Focusing Data processing finalized to focus the SAR image in range and azimuth through bidimensional signal compression. Geocoded The data contains geographic information or coordinates corresponding to the location of the data. Georeference The internal coordinate system of the image can be related to a ground system of geographic coordinates Ground range Projection of the slant range into the ground. Incidence angle Local incidence angle on ground calculated using the ellipsoidal Earth model. Looks Image obtained using only part of the spectrum to focus the image (subaperture). It can be done in range and in azimuth, and normally is used to reduce the speckle noise from SAR images through incoherent sum (multi-look process). Range Direction orthogonal to the satellite velocity. Slant range vector Line-Of-Sight distance between the antenna and the target on ground. Slant range plane Plane containing the relative sensor velocity vector and the slant range vector for a given target. | Orthorectification |A subtopic of georeferencing\u2014 The process of converting images into a form suitable for maps by removing sensor motion and terrain-related geometric distortions from raw imagery. |","title":"SAR Glossary"},{"location":"glossary/#list-of-acronyms","text":"TERM DEFINITION ASCII American Standard Code for Information Interchange BSD Berkeley Software Distribution CF Calibration Factor Cn Coefficient \u2018n\u2019 in a polynomial DC Doppler Centroid DN Digital Number ECEF Earth-Centered, Earth-Fixed GR Ground Range GRD Ground Range Detected GRSR Ground Range to Slant Range conversion HDF Hierarchical Data Format KML Keyhole Markup Language PNG Portal Network Graphics PRF Pulse Repetition Frequency RMSE Root Mean Square Error RPC Rapid Positioning Capability (or Rational Polynomial Coefficient) SR Slant Range SAR Synthetic Aperture Radar SLC Single Look Complex UTC Coordinated Universal Time VV Polarization (Vertical transmitted and Vertical received) WGS84 World Geodetic System (1984) XML eXtensible Markup Language","title":"List of Acronyms"},{"location":"OverviewOfSAR/beautifulEquations/","text":"The Beautiful Equations The brute force method of real-aperture radar cannot produce high-resolution images. In synthetic-aperture radar we take advantage of the natural coherence of radar illumination to produce structured and consistent pulses. These enable the measurement of slight pulse-to-pulse phase shifts and the use of frequency-modulated chirps. The innovations of aperture synthesis, modulated waveforms and pulse compression produce images capable of a remarkable pixel resolution and which does not degrade as distance to the ground increases. Even though they are handled differently, the azimuth and range processes have a fundamental similarity: Azimuth resolution is based on phase variations across the collection interval. These are compared to known phase variations across that area to produce a long \u201csynthetic\u201d aperture and a resolution cell narrow in azimuth. Range resolution is based on frequency variations across the returned pulse. These are compared to known frequency variations in the reference pulse to produce a short \u201csynthetic\u201d pulse and a resolution cell narrow in range. These processes result in two of the most simple and powerful equations in all of remote sensing. They are the equations that describe the spatial resolution of a SAR sensor. They are The Beautiful Equations : \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[ \\delta_{sr} = \\frac{c}{2B} \\] with \\(\\delta_{az}\\) and \\(\\delta_{sr}\\) being the azimuth resolution and the slant range resolution respectively.","title":"The Beautiful Equations"},{"location":"OverviewOfSAR/beautifulEquations/#the-beautiful-equations","text":"The brute force method of real-aperture radar cannot produce high-resolution images. In synthetic-aperture radar we take advantage of the natural coherence of radar illumination to produce structured and consistent pulses. These enable the measurement of slight pulse-to-pulse phase shifts and the use of frequency-modulated chirps. The innovations of aperture synthesis, modulated waveforms and pulse compression produce images capable of a remarkable pixel resolution and which does not degrade as distance to the ground increases. Even though they are handled differently, the azimuth and range processes have a fundamental similarity: Azimuth resolution is based on phase variations across the collection interval. These are compared to known phase variations across that area to produce a long \u201csynthetic\u201d aperture and a resolution cell narrow in azimuth. Range resolution is based on frequency variations across the returned pulse. These are compared to known frequency variations in the reference pulse to produce a short \u201csynthetic\u201d pulse and a resolution cell narrow in range. These processes result in two of the most simple and powerful equations in all of remote sensing. They are the equations that describe the spatial resolution of a SAR sensor. They are The Beautiful Equations : \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[ \\delta_{sr} = \\frac{c}{2B} \\] with \\(\\delta_{az}\\) and \\(\\delta_{sr}\\) being the azimuth resolution and the slant range resolution respectively.","title":"The Beautiful Equations"},{"location":"OverviewOfSAR/noise/","text":"Separating Signals from Noise The Whisper As a radar pulse travels from the antenna to the ground surface its total power remains constant, but as it moves away from the antenna, it spreads out into space and its power density weakens. As shown in Figure 17, it is as if the \u201cskin\u201d of the pulse becomes thinner with distance. This weakening is dramatic; it decreases with the square of the distance from the antenna. Figure 17: Expanding Surface Area of a Pulse Given that the ground might be 750 km from the antenna, the pulse is quite weak by the time it finally reflects from surface objects. This presents even more of a problem because only a portion of the weakened pulse is reflected toward the receive antenna, and then it has to travel all the way back, weakening again with the square of the distance. By the time the microwaves return to the antenna, they are microscopically faint. The antenna and radar receiver manage to detect, amplify, and record these echoes so that they can be processed into SAR resolution cells that span more than 100,000 brightness values. SAR is amazing. The Challenge of Noise Those backscattered microwaves are so weak when they arrive at the antenna that they are perturbed by any noise sources that get mixed in with them. Noise is an artifact of random microwave emissions caused mostly by onboard sensor hardware. One of the tenets of remote sensing is that all objects emit electromagnetic energy based on their temperature. The thermal noise of heated receiver hardware spans wide swaths of the spectrum, including the microwave bands, and this competes with those whispering pulse echoes. As they struggle to capture those fading backscatter whispers, radar receivers also record random, interfering microwaves that they themselves produce. One of the disappointing aspects of the noise level is that it increases as range bandwidth increases. The large signal bandwidth that the receiver has to be capable of recording also lets more noise enter the receiver. One of the ways that noise is quantified for SAR sensors is called the Noise Equivalent Sigma Zero (NESZ). This parameter describes the noise floor of an image. All received signals have to be stronger than the NESZ value to rise above the noise level, so it is best for NESZ to be as low as possible. Images with high NESZ values look grainy. Unfortunately, NESZ is mystifying to SAR users who are not familiar with the dB language of engineering. Many users are confused by NESZ values like -20 dB, which actually indicates a fractional level of 1%. That is, an NESZ of -20 dB means the noise level is 1% as strong as a reference reflection from an idealized metal sphere. An NESZ of -17 dB would means the noise level is 2% as strong as the reference. System designers have to consider many competing imaging parameters to balance image quality, resolution and noise. For spacecraft, the best choices are increased average power, larger antennas, the use of high-quality receivers with low noise factors, steeper illumination angles, and lower orbits.","title":"Separating Signals From Noise"},{"location":"OverviewOfSAR/noise/#separating-signals-from-noise","text":"","title":"Separating Signals from Noise"},{"location":"OverviewOfSAR/noise/#the-whisper","text":"As a radar pulse travels from the antenna to the ground surface its total power remains constant, but as it moves away from the antenna, it spreads out into space and its power density weakens. As shown in Figure 17, it is as if the \u201cskin\u201d of the pulse becomes thinner with distance. This weakening is dramatic; it decreases with the square of the distance from the antenna. Figure 17: Expanding Surface Area of a Pulse Given that the ground might be 750 km from the antenna, the pulse is quite weak by the time it finally reflects from surface objects. This presents even more of a problem because only a portion of the weakened pulse is reflected toward the receive antenna, and then it has to travel all the way back, weakening again with the square of the distance. By the time the microwaves return to the antenna, they are microscopically faint. The antenna and radar receiver manage to detect, amplify, and record these echoes so that they can be processed into SAR resolution cells that span more than 100,000 brightness values. SAR is amazing.","title":"The Whisper"},{"location":"OverviewOfSAR/noise/#the-challenge-of-noise","text":"Those backscattered microwaves are so weak when they arrive at the antenna that they are perturbed by any noise sources that get mixed in with them. Noise is an artifact of random microwave emissions caused mostly by onboard sensor hardware. One of the tenets of remote sensing is that all objects emit electromagnetic energy based on their temperature. The thermal noise of heated receiver hardware spans wide swaths of the spectrum, including the microwave bands, and this competes with those whispering pulse echoes. As they struggle to capture those fading backscatter whispers, radar receivers also record random, interfering microwaves that they themselves produce. One of the disappointing aspects of the noise level is that it increases as range bandwidth increases. The large signal bandwidth that the receiver has to be capable of recording also lets more noise enter the receiver. One of the ways that noise is quantified for SAR sensors is called the Noise Equivalent Sigma Zero (NESZ). This parameter describes the noise floor of an image. All received signals have to be stronger than the NESZ value to rise above the noise level, so it is best for NESZ to be as low as possible. Images with high NESZ values look grainy. Unfortunately, NESZ is mystifying to SAR users who are not familiar with the dB language of engineering. Many users are confused by NESZ values like -20 dB, which actually indicates a fractional level of 1%. That is, an NESZ of -20 dB means the noise level is 1% as strong as a reference reflection from an idealized metal sphere. An NESZ of -17 dB would means the noise level is 2% as strong as the reference. System designers have to consider many competing imaging parameters to balance image quality, resolution and noise. For spacecraft, the best choices are increased average power, larger antennas, the use of high-quality receivers with low noise factors, steeper illumination angles, and lower orbits.","title":"The Challenge of Noise"},{"location":"OverviewOfSAR/overviewOfSAR/","text":"An Overview of SAR Imaging Note This overview is excerpted with permission from The Essentials of SAR , by Thomas P. Ager 1 This comprehensive text was written for SAR users, not electrical engineers. It reviews the many interesting aspects of SAR and its uses that we cannot cover in this short overview. The Value of SAR Imaging Synthetic aperture radar is well known as the imaging technique that can see through clouds and darkness. But SAR provides a number of other capabilities that are simply not available from optical sources. These include: High Resolution Independent of Distance : One of the outstanding characteristics of SAR is that it is capable of detailed resolution regardless of how far away the sensor is from the ground. SAR sensors can provide very high resolution, even from space. Variable Resolution and Coverage : SAR illumination is controlled electronically, and it can be manipulated to vary resolution and coverage. Images can be collected over small areas at fine resolution, over medium-sized areas at medium resolution or over large areas at coarse resolution. Precision Geolocation : SAR measurements are inherently precise. Properly calibrated images can have geolocation accuracy less than the scale of a single pixel for well-defined features. Coherent Illumination and Many Products : The controlled nature of SAR imaging enables the formation of images and many other products. These include sub-aperture image stacks that highlight glinting features and motion, dense elevation models, precise measurements of surface motion, and amplitude and coherent change images or series. Radar Bands There are several radar bands ranging from wavelengths at the millimeter level to a full meter (Table 1). X-Band has the best combination of cloud-penetration and resolution for spaceborne sensors. In addition to atmospheric gases, there are larger atmospheric particles that scatter visible light but which are transparent to microwaves. In addition to penetrating clouds, X-band radar waves travel through smog, volcanic ash, and sandstorms. BAND WAVELENGTH [CM] FREQUENCY [GHZ] ORIGIN UHF 30 to 100 1 to 0.3 Ultra High Frequency P 60 to 120 0.5 to 0.25 P for \"previous\", as the British used the band for the earliest radars, but later switched to higher frequencies. L 15 to 30 2 to 1 for 'Long Wave' S 7.5 to 15 4 to 2 for 'Short Wave'. Not to be confused with the radio band C 3.75 to 7.5 8 to 4 Originally for 'compromise' between S and X band X 2.5 to 3.75 12 to 8 Used in WWII for fire control, X for cross as in crosshair Ku 1.67 to 2.5 18 to 12 for \"Kurz-under\" K 1.11 to 1.67 27 to 18 German \"kurz\" means short, another reference to short wavelength Ka 0.75 to 1.11 40 to 27 Ka for \"kurz-above\" V 0.40 to 0.75 75 to 40 V for 'very' high frequency - not to be confused with VHF W 0.27 to 0.40 110 to 75 W follows V in the alphabet mm 0.10 to 0.27 300 to 110 millimeter wave Table 1 : Radar Bands References Thomas P. Ager. The Essentials of SAR: A Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities . 2021. ISBN-13 \u200f : \u200e 979-8512864487. \u21a9","title":"The Value Of SAR Imaging"},{"location":"OverviewOfSAR/overviewOfSAR/#an-overview-of-sar-imaging","text":"Note This overview is excerpted with permission from The Essentials of SAR , by Thomas P. Ager 1 This comprehensive text was written for SAR users, not electrical engineers. It reviews the many interesting aspects of SAR and its uses that we cannot cover in this short overview.","title":"An Overview of SAR Imaging"},{"location":"OverviewOfSAR/overviewOfSAR/#the-value-of-sar-imaging","text":"Synthetic aperture radar is well known as the imaging technique that can see through clouds and darkness. But SAR provides a number of other capabilities that are simply not available from optical sources. These include: High Resolution Independent of Distance : One of the outstanding characteristics of SAR is that it is capable of detailed resolution regardless of how far away the sensor is from the ground. SAR sensors can provide very high resolution, even from space. Variable Resolution and Coverage : SAR illumination is controlled electronically, and it can be manipulated to vary resolution and coverage. Images can be collected over small areas at fine resolution, over medium-sized areas at medium resolution or over large areas at coarse resolution. Precision Geolocation : SAR measurements are inherently precise. Properly calibrated images can have geolocation accuracy less than the scale of a single pixel for well-defined features. Coherent Illumination and Many Products : The controlled nature of SAR imaging enables the formation of images and many other products. These include sub-aperture image stacks that highlight glinting features and motion, dense elevation models, precise measurements of surface motion, and amplitude and coherent change images or series.","title":"The Value of SAR Imaging"},{"location":"OverviewOfSAR/overviewOfSAR/#radar-bands","text":"There are several radar bands ranging from wavelengths at the millimeter level to a full meter (Table 1). X-Band has the best combination of cloud-penetration and resolution for spaceborne sensors. In addition to atmospheric gases, there are larger atmospheric particles that scatter visible light but which are transparent to microwaves. In addition to penetrating clouds, X-band radar waves travel through smog, volcanic ash, and sandstorms. BAND WAVELENGTH [CM] FREQUENCY [GHZ] ORIGIN UHF 30 to 100 1 to 0.3 Ultra High Frequency P 60 to 120 0.5 to 0.25 P for \"previous\", as the British used the band for the earliest radars, but later switched to higher frequencies. L 15 to 30 2 to 1 for 'Long Wave' S 7.5 to 15 4 to 2 for 'Short Wave'. Not to be confused with the radio band C 3.75 to 7.5 8 to 4 Originally for 'compromise' between S and X band X 2.5 to 3.75 12 to 8 Used in WWII for fire control, X for cross as in crosshair Ku 1.67 to 2.5 18 to 12 for \"Kurz-under\" K 1.11 to 1.67 27 to 18 German \"kurz\" means short, another reference to short wavelength Ka 0.75 to 1.11 40 to 27 Ka for \"kurz-above\" V 0.40 to 0.75 75 to 40 V for 'very' high frequency - not to be confused with VHF W 0.27 to 0.40 110 to 75 W follows V in the alphabet mm 0.10 to 0.27 300 to 110 millimeter wave Table 1 : Radar Bands","title":"Radar Bands"},{"location":"OverviewOfSAR/overviewOfSAR/#references","text":"Thomas P. Ager. The Essentials of SAR: A Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities . 2021. ISBN-13 \u200f : \u200e 979-8512864487. \u21a9","title":"References"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/","text":"An Overview of SAR Imaging Note This overview is exercepted with permission from The Essentials of SAR , by Thomas P. Ager 1 This comprehensive text was written for SAR users, not electrical engineers. It reviews the many interesting aspects of SAR and its uses that we cannot cover in this short overview. The Value of SAR Imaging Synthetic aperture radar is well known as the imaging technique that can see through clouds and darkness. But SAR provides a number of other capabilities that are simply not available from optical sources. These include: High Resolution Independent of Distance : One of the outstanding characteristics of SAR is that it is capable of detailed resolution regardless of how far away the sensor is from the ground. SAR sensors can provide very high resolution, even from space. Variable Resolution and Coverage : SAR illumination is controlled electronically, and it can be manipulated to vary resolution and coverage. Images can be collected over small areas at fine resolution, over medium-sized areas at medium resolution or over large areas at coarse resolution. Precision Geolocation : SAR measurements are inherently precise. Properly calibrated images can have geolocation accuracy less than the scale of a single pixel for well-defined features. Coherent Illumination and Many Products : The controlled nature of SAR imaging enables the formation of images and many other products. These include sub-aperture image stacks that highlight glinting features and motion, dense elevation models, precise measurements of surface motion, and amplitude and coherent change images or series. Radar Bands There are several radar bands ranging from wavelengths at the millimeter level to a full meter (Table 1). X-Band has the best combination of cloud-penetration and resolution for spaceborne sensors. In addition to atmospheric gases, there are larger atmospheric particles that scatter visible light but which are transparent to microwaves. In addition to penetrating clouds, X-band radar waves travel through smog, volcanic ash, and sandstorms. BAND WAVELENGTH [cm] FREQUENCY [GHZ] Origin UHF 30 to 100 1 to 0.3 Ultra High Frequency P 60 to 120 0.5 to 0.25 P for \"previous\", as the British used the band for the earliest radars, but later switched to higher frequencies. L 15 to 30 2 to 1 for 'Long Wave' S 7.5 to 15 4 to 2 for 'Short Wave'. Not to be confused with the radio band C 3.75 to 7.5 8 to 4 Originally for 'compromise' between S and X band X 2.5 to 3.75 12 to 8 Used in WWII for fire control, X for cross as in crosshair Ku 1.67 to 2.5 18 to 12 for \"Kurz-under\" K 1.11 to 1.67 27 to 18 German \"kurz\" means short, another reference to short wavelength Ka 0.75 to 1.11 40 to 27 Ka for \"kurz-above\" V 0.40 to 0.75 75 to 40 V for 'very' high frequency - not to be confused with VHF W 0.27 to 0.40 110 to 75 W follows V in the alphabet mm 0.10 to 0.27 300 to 110 millimeter wave Table 1 : Radar Bands A Simple Form of Radar Imaging As seen in Figure 1 the radar antenna emits a series of pulses toward the ground where they are scattered in many directions. The sensor records the \u201cbackscatter\u201d, which is the portion reflected toward the antenna. It measures the strength of the echo and the time it took for the pulse to travel to the ground and back. Figure 1: Pulse Transmission and Backscatter Signal strength corresponds to pixel brightness and the timing provides range information. The range is one-half the total travel time. In the equation below, \\(\\Delta T\\) is the travel time and \\(c\\) is the speed of light: \\[Range = \\frac{\\Delta T\\ c}{2}\\] Side-Looking Illumination Since the pixels of a radar imaging system are placed on the image based partly on their range, the antenna cannot illuminate the ground in a vertical orientation. If it did, features on the same imaging line at equivalent angles off nadir would have identical ranges, like the two purple diamonds in Figure 2, and they would occupy the same pixel location. Figure 2: Vertical Illumination Radar imaging must be side-looking so that ground points from the near to far range have different range values (Figure 3). The illumination is typically broadside, or perpendicular, to the flight direction. Figure 3: Side-Looking Illumination Radar Angles The angles associated with radar illumination are shown in Figure 4, which is based on a spherical earth surface. Most radar imaging is broadside to the flight direction, but some systems can collect off-broadside in a squinted orientation. The angle down from the local level at the sensor is called the depression angle. The angle between the line-of-sight ray and the local vertical is the incidence angle. The angle between the tangent to the surface and the line of sight is the grazing angle. Note that the incidence and grazing angles are complements in that they form a right angle when combined. This means that a 60\u00b0 incidence angle is the same as a 30\u00b0 grazing angle. Figure 4: Radar Imaging Angles Side Looking Airborne Radar The first useful radar imaging technique was a form called Side-Looking Airborne Radar (SLAR) (Figure 5). The image is built up via the forward motion of the antenna, one line at a time. The pulses are emitted at a rate called the pulse repetition frequency (PRF), which can range from a few hundred pulses each second for airborne systems to thousands each second for spacecraft. In the SLAR technique, the individual pulses create each image line. The angular width of the pulse on the ground along the direction of flight, or azimuth direction, determines one component of resolution. The range measurements are collected in the \u201cslant range\u201d direction, and range variations to different objects form the second dimension of resolution. Figure 5: Side-Looking Airborne Radar SLAR was used the early days of radar imaging but it had serious limitations. Range resolution was one-half the length of the pulse in the range direction. Since the pulses are emitted at light speed, even a very brief pulse of one-millionth of a second would be 300 meters long and produce range resolution of 150 meters (Figure 6). Azimuth resolution was based on the angular width of the pulse in the azimuth direction ( \\(\\beta\\) ). Long antennas create narrow beams, but the beam spreads out from the antenna to the distant ground surface. Antennas cannot be made long enough to produce good azimuth resolution, and SLAR produced images with resolutions in the hundreds of meters, even from aircraft. This is why the brilliant concept of synthesizing a long antenna from the actions of a small one was developed. We call this Synthetic Aperture Radar. Figure 6: SLAR Pulse Dimensions The Remarkable Story of Synthetic Aperture Radar Improving Azimuth Resolution by Synthesizing a Long Antenna It takes a long antenna to create narrow radar beams, but the aperture itself does not have to be a giant physical antenna. Instead, a \u201csynthetic\u201d aperture can be created from a small antenna and a linear extent of recording locations. Figure 7 shows a radar antenna sequentially emitting a series of pulses, like a microwave strobe light, and recording the echoes from a string of receive positions. Figure 7: Linear Extent of Recording Locations In the SAR technique all of the measurements are stored and later processed together. It is as if they were collected from one long antenna equal in length to the extent of the sensor locations that received the echoes. Synthetic Aperture Radar is a post-processing scheme applied to data collected by a standard radar antenna and receiver. Stripmap and Spotlight Apertures There are a few methods to illuminate the ground in SAR imaging. These collection modes trade off resolution and coverage in different ways. To establish how we can simulate long apertures we\u2019ll contrast the two most common forms of SAR imaging: stripmap and spotlight. In stripmap mode the pulses are sent out at a constant angle, usually broadside to the flight direction. In this case, the length of this simulated aperture ( \\(L\\) ) is the same as the width of the beam on the ground (Figure 8). Wider beams produced by smaller antennas mean longer apertures and better azimuth resolution. This directly contrasts with the real-aperture radar of SLAR where the beam was kept as narrow as possible to obtain good resolution. Figure 8: Stripmap Synthetic Aperture The spotlight form of SAR varies the boresight angle in the azimuth direction to illuminate a fixed ground location (Figure 9). This technique greatly increases the synthetic-aperture length and offers excellent azimuth resolution, at the cost of limited ground coverage. At ICEYE we are capable of illuminating a fixed spot for as long as 30 seconds. Given the velocity of low-earth orbits (7.5 km/sec), this yields a synthetic aperture more than 225 kilometers long ! Figure 9: Spotlight Synthetic Aperture Phase History Data and SAR Azimuth Resolution We can create long \u201csynthetic\u201d apertures because radar illumination is coherent. That is, the sensor controls the structure of the transmitted pulses and they all have the same form. It emits pulses and measures the details of each echo: time, strength and \u201cphase\u201d. Phase refers to the position of the wave in its cycle, denoting whether it is at its peak, trough or somewhere in between. The SAR antenna moves only slightly from pulse to pulse. It turns out that the change in location must be less than one-half the antenna length. But this small change in location causes the successive measurements of the range to some object to change as well. The slight change in position imparts a slight change in range. Since the phase is dependent on the range, the small change in adjacent sensor locations also imparts a slight change in phase. These phase changes form a pattern across the aperture, which changes depending on the azimuth location of a ground feature. The record of all the changing phases for all the scatterers in the scene is called phase history data. For a particular object, this is the \u201chistory\u201d of how phase changed from one receive location to the next. Given carefully measured sensor locations, the phase histories for each location across the scene are predictable. The azimuth position of each scatterer can be calculated by comparing the predicted phase pattern of some location to the measured phase history pattern for that point. This is the essence of azimuth resolution. Phase history data and their reference patterns are compared to discriminate the azimuth position of scatterers in the scene. Now that we have that huge aperture and the equation for azimuth resolution becomes: \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] where \\(\\delta_{az}\\) is the SAR azimuth resolution. This equation is gorgeous. It says that azimuth resolution is based on the wavelength of our radar waves and the change in the integration angle ( \\(\\Delta \\theta\\) ) while the point was being imaged (Figure 10). Resolution improves when the wavelength is small and the integration angle change is large. Figure 10: Spotlight Synthetic Aperture Angle Now let\u2019s use SAR with an integration angle change of 0.07 radians (4.5\u00b0). This is reasonable because the current operational performance of ICEYE's spotlight mode can easily exceed this angle. \\[\\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[\\delta_{az} = \\frac{3 cm}{2 \\times 0.07} \\] \\[\\delta_{az} = 0.21m \\] For stripmap mode the azimuth resolution equation reduces to a simpler form, where \\(D_A\\) is the length of the antenna in the azimuth direction: \\[\\delta_{az} = \\frac{D_A}{2} \\] This is just a special stripmap case of the more general equation, but it seems to imply that we could make the antenna really small to achieve good stripmap resolution. While this is literally true, the small size of the antenna would lessen the total power that could be transmitted and also degrade the ability to record the weak backscattered echoes. Noise would increase significantly. It would also require the PRF to get unreasonably large because a pulse is required at least every one-half antenna length. Stripmap cannot support high-resolution SAR. For that we need to steer the beam during illumination to increase the synthetic aperture, as with a spotlight collection. This mode is capable of fine resolution and it can use a larger, and therefore more powerful and sensitive antenna. Something Is Missing These elegant equations are an astonishing statement about resolution, but it is even more amazing when we consider what is missing. Notice that the SAR azimuth resolution equations do not include a term for distance. Use it on an aircraft or move it all the way out into space, and azimuth resolution does not change. Of course, distance does impact signal strength. When the sensor is further away, the signal strength weakens dramatically and this poses serious challenges to the SAR imaging process. We will not discuss this issue in this overview, but we can say here that radar antennas are very sensitive. Spaceborne SARs successfully record very weak backscatters. Fixing Range Resolution by Synthesizing a Short Pulse In our discussions about aperture synthesis, we did not say anything about range resolution. This is because the \u201csynthetic aperture\u201d technique itself deals only with azimuth. It does not do anything to address the problem we saw with brute-force range resolution. Recall that this is one-half of the pulse length, which is the speed of light ( \\(c\\) ) times the pulse duration, \\(T\\) : \\[\\delta_{ra} = \\frac{c\\ T}{2}\\] where \\(\\delta_{ra}\\) is the slant range resolution. Thus far, we have described our radar pulses as if they have a fixed frequency, like X-band pulses of 10 GHz frequency and a 3 cm wavelength. But most radars actually transmit chirped pulses in which the frequency changes (Figure 11). Notice how the wavelength of the green pulse is manipulated and varies from long to short Figure 11: Chirped Pulse When we state the frequency or wavelength of a SAR sensor, those values typically apply at the mid-way time of the pulse. This is known as the radar center frequency or wavelength. The actual transmitted wavelengths are varied quite a bit on either side to form chirped pulses (Figure 12). Figure 12: Centre Frequency There are many different pulse modulation techniques, but the chirp with a smoothly varying frequency is most common. A chirped pulse is easy to produce and since the total transmitted energy is a product of amplitude and duration, a long pulse can contain a substantial amount of energy without needing a large peak power. A chirped pulse enables high range resolution because its form is exactly specified and its echo is a reversed and weakened copy. The reflection has the same shape as the emitted signal, it\u2019s just flipped and has a much smaller amplitude. The two are compared in what is called a matched filter process. The known structure of the emitted pulse is compared to the echo at various locations. A calculation is performed, and if they are misaligned the result of this calculation is zero. At the exact location where they match there is a strong signal that indicates the match. A synthetic pulse that is narrow in range replaces the spread-out pulse (Figure 13). Figure 13: Range Compression The width of the compressed pulse is based entirely on the bandwidth of the emitted pulse. The slant range resolution equation is transformed: \\[ \\delta_{slant\\ range\\ chirp\\ compressed} = \\frac{c}{2B} \\] This is a really beautiful equation. It is so simple and powerful. Resolution in range is entirely based on how much bandwidth we impart to chirped pulses, and like its azimuth counterpart it has nothing whatsoever to do with distance to the ground. Slant Range Resolution Examples So how much can we vary pulse frequency? Well, bandwidths can be made really large. Consider an X-band system capable of 300,000,000 cycles per second (300 MHz) of bandwidth. We can calculate resolution in the slant range: \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300MHz} \\] \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300\\times10^8Hz} \\] \\[ \\delta_{sr} = 0.5 metres \\] Plans for the next generation of ICEYE satellites include pulse bandwidths of 600 MHz and 1200 MHz. These will yield a slant range resolution cell of 0.25 meters and better from a satellite that is perhaps 750,000 meters away from the imaged area. Ground Range Resolution The slant range is the distance between the antenna and the target, and that is the direction where range resolution is measured. To produce images along the ground surface, the pixels have to be projected to the \u201cground range\u201d from their original slant range orientation (Figure 14). This has the effect of elongating the pixels in range. Figure 14: Ground Range Resolution The illustration shows the relationship between slant range resolution, shown in blue, and the length of the equivalent resolution distance along the ground, shown in green. When the illumination is steep, as in this example, the projection to the ground surface results in a much longer ground range cell. You can imagine what would happen as the steepness continued to approach nadir. This is exactly opposite to the situation with optical imaging resolution, which is best at nadir. Slant range and ground range resolution comparisons for two incidence angles are shown in Table 2. Notice the dramatic increase for the steeper illumination. Incidence Angle 30\u00b0 Incidence Angle 60\u00b0 Slant Range 0.50m 0.50m Ground Range 1.00m 0.55m Table 2: Resolution comparison between slant range and ground range While slant range resolution seems \u201cbetter\u201d than ground range resolution, keep in mind that it refers to the sensor\u2019s ability to discriminate features along the oblique path of the energy. Most of the features we care about lie along the ground surface, and ground range resolution is a useful way to describe image resolution. The Beautiful Equations The brute force method of real-aperture radar cannot produce high-resolution images. In synthetic-aperture radar we take advantage of the natural coherence of radar illumination to produce structured and consistent pulses. These enable the measurement of slight pulse-to-pulse phase shifts and the use of frequency-modulated chirps. The innovations of aperture synthesis, modulated waveforms and pulse compression produce images capable of a remarkable pixel resolution and which does not degrade as distance to the ground increases. Even though they are handled differently, the azimuth and range processes have a fundamental similarity: Azimuth resolution is based on phase variations across the collection interval. These are compared to known phase variations across that area to produce a long \u201csynthetic\u201d aperture and a resolution cell narrow in azimuth. Range resolution is based on frequency variations across the returned pulse. These are compared to known frequency variations in the reference pulse to produce a short \u201csynthetic\u201d pulse and a resolution cell narrow in range. These processes result in two of the most simple and powerful equations in all of remote sensing. They are the equations that describe the spatial resolution of a SAR sensor. They are The Beautiful Equations : \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[ \\delta_{sr} = \\frac{c}{2B} \\] with \\(\\delta_{az}\\) and \\(\\delta_{sr}\\) being the azimuth resolution and the slant range resolution respectively. The SAR Processing Flow and Its Products SAR image generation begins with the emission of thousands of coherent pulses and the decomposition of each echo into raw measurements of time, amplitude and phase. The first part of the processing flow is called Phase History Processing because it accounts for the changes over time of the phase values of each scatterer. Phase history data are focused into the azimuth and range components of each resolution cell to produce an image product called a \u201ccomplex image\u201d (Figure 15). Figure 15: The SAR Processing Flow and Its Products The Complex Image Info By the way, you will hear SAR engineers refer to the two parameters of a complex image as \u201cIn-Phase\u201d and \u201cQuadrature\u201d. These are just another way to describe the complex values. The left image in Figure 16 is a ICEYE amplitude image of agricultural fields. In this image each pixel has a brightness value assigned to it. This is what many people consider to be the base SAR product, but this is really only half of the full image. The SAR processor calculates the average phase value for each pixel as well. The matching \u201cphase image\u201d of that same scene is on the right in the figure. The combination of these two images is called a complex image, in which every pixel has amplitude and phase values. We use the term \u201ccomplex\u201d because the pixels are described by a mathematical construct called a complex number, where every number has two components. Figure 16: Amplitude and Phase Structure of a Complex Image Of course, phase data are not useful for direct human interpretation. And while they may look like random noise, phase pixels are a unique and valuable aspect of SAR imaging. Phase data can be used to manipulate the synthetic aperture in different ways to extract useful information that is not available from amplitude images. Moreover, changes in the phase measurements of the same object on different images can be used to detect small surface structure characteristics. In the next section we\u2019ll discuss how we can use phase data to refine images and create other products. SAR Products Derived from Complex Data Amplitude Images Info You should also be aware that an engineering calculation called \u201cdetection\u201d converts in-phase and quadrature values to amplitude values. Engineers often refer to SAR amplitude images as \u201cdetected\u201d images. An amplitude image is certainly the most common SAR product, but you need to appreciate that this image is produced for human viewing and analysis. It is not the core image product. Amplitude images do not contain any phase information. Furthermore, the version of the amplitude image used for human viewing is not a direct copy of the amplitude values in a complex image. This is because radar sensors record an enormous span of brightness levels for each complex pixel. The maximum intensity of amplitude in a complex image is usually more than 100,000 times (50 dB) the minimum intensity, and for the best-quality images with bright targets, it is much greater. ICEYE images are produced with 16 bits of dynamic range per pixel (65536 gray levels) but even this is not sufficient to record the full dynamic range of SAR. As valuable as they are, amplitude images have no phase data and they lose much of the dynamic range of complex pixels. You can imagine the growing potential for computers and algorithms to process those complex pixels in ways the human visual system cannot. Multi-look Amplitude Images One way in which we can use complex data is to produce different versions of the seemingly simple amplitude image. One common form of an amplitude image, for example, is called a multi-look image. Consider that azimuth and range resolution are handled independently. One is based on the length of the synthetic aperture and the other is based on the signal bandwidth, and sometimes these are quite different in magnitude. It is common for azimuth resolution to be collected at a higher fidelity than range resolution. If a full-resolution image were produced from such data it would look compressed in range. To view the image in a more natural aspect we need to \u201csquare the pixels\u201d so that the range and azimuth scales are the same. Info Speckle is a grainy, noise-like feature of SAR images. It is caused by the coherent nature of SAR illumination. The reflections from small scatterers within a resolution cell combine constructively and destructively to brighten or darken the returns. This is done by manipulating the synthetic aperture into smaller sub-apertures and then combining them. The sub-apertures are called \u201clooks\u201d and they each produce an image with lower azimuth resolution. This may sound disappointing, but when these individual sub-aperture images are combined, they form a multi-look image in which the noisy effect of speckle is reduced. Complex images are stored at full-resolution and are called single-look complex (SLC) images. Amplitude images are typically multi-looked in azimuth using two to 12 sub-apertures. If range resolution exceeds azimuth resolution a similar multi-look process can be applied in the range dimension. Sub-aperture Stack or Video Image Suppose we take the aperture splitting further and create six or seven segments to produce multiple sub-aperture images. One advantage of this sub-aperture stack is that it can indicate glints that are bright in only a portion of the full aperture. This signature might be washed out on the full-resolution image by the bulk of the aperture in which there was no glinting, but it can be very noticeable in one of the low-resolution sub-apertures. Glints tend to be important signatures because they are usually caused by human-made features. We could even loop the stack like a short movie, or SAR video image, to look for such glints and moving objects. This product works best for long spotlight exposures of ten seconds or more. Amplitude and Coherent Change Images Perhaps the most useful SAR products are the amplitude and coherent change images (ACI, CCI). Two or more images of the same site are collected at different times to detect scene changes. For ACD only the brightness values are compared, while CCD uses phase data. In order for change detection to work, the images have to be collected from nearly the same location in space with similar illumination geometries. For ACD the two images can be overlaid in the complementary colors (eg red and cyan). In this way, features with similar backscatters will be gray, but features with backscatters that changed during the imaging period will appear in one of the two colors. It is conventional for the first image to be displayed in red and the second in cyan. If something on the ground changes between the two collections you will see whichever color signature is dominant. A mnemonic is used to help interpret ACD products: \u201cRed is fled. Blue is new\u201d. That is, a red signature indicates a feature that was present on the first image but left the scene prior to the second image, and a blue signature indicates a feature that appears only on the second image. This mnemonic is an easy way to help remember the order of the images, but appreciate that the second image is actually cyan, not blue. The intentional sloppiness of the mnemonic is acceptable here because verbal precision would ruin the rhyme. In contrast to amplitude change detection, CCD compares the phase values of two nearly identical images taken at different times. CCD is far more sensitive to changes because it is based on phase differences rather than pixel brightness differences and, as we know, phase is measured to within a small fraction of a wavelength. The collection constraints to ensure image-to-image coherence are tighter for CCD than ACD. When the collection parameters are nearly identical, the phase values are also nearly identical, and any changes are due to backscatter differences at a scale of less than one wavelength. It is typical for CCD images to display pixels where phase is consistent in white and the pixels where the phase has changed are dark. These are areas where the two images have \u201cdecorrelated\u201d, or lost phase consistency, due to some subtle change in the scene. Other Multi-image SAR Products The amplitude and phase data of SAR images can be combined to produce other useful products that are too numerous to describe in detail in this overview. These include digital elevation models derived from pixel brightness values or phase data, millimeter-level surface motion measurements derived phase comparisons of sets of matching images, and automated detections of ships, oil spills and other features. Once constellations of small SARs are established it will be possible to monitor any site in the world with large stacks of exactly matching images whose consistent signatures are linked to known ground features. These images could be collected within hours of each other and they will be the basis of intelligent site monitoring services that will not only detect changes, but which will also say what has changed and how it has changed. Separating Signals from Noise The Whisper As a radar pulse travels from the antenna to the ground surface its total power remains constant, but as it moves away from the antenna, it spreads out into space and its power density weakens. As shown in Figure 17, it is as if the \u201cskin\u201d of the pulse becomes thinner with distance. This weakening is dramatic; it decreases with the square of the distance from the antenna. Figure 17: Expanding Surface Area of a Pulse Given that the ground might be 750 km from the antenna, the pulse is quite weak by the time it finally reflects from surface objects. This presents even more of a problem because only a portion of the weakened pulse is reflected toward the receive antenna, and then it has to travel all the way back, weakening again with the square of the distance. By the time the microwaves return to the antenna, they are microscopically faint. The antenna and radar receiver manage to detect, amplify, and record these echoes so that they can be processed into SAR resolution cells that span more than 100,000 brightness values. SAR is amazing. The Challenge of Noise Those backscattered microwaves are so weak when they arrive at the antenna that they are perturbed by any noise sources that get mixed in with them. Noise is an artifact of random microwave emissions caused mostly by onboard sensor hardware. One of the tenets of remote sensing is that all objects emit electromagnetic energy based on their temperature. The thermal noise of heated receiver hardware spans wide swaths of the spectrum, including the microwave bands, and this competes with those whispering pulse echoes. As they struggle to capture those fading backscatter whispers, radar receivers also record random, interfering microwaves that they themselves produce. One of the disappointing aspects of the noise level is that it increases as range bandwidth increases. The large signal bandwidth that the receiver has to be capable of recording also lets more noise enter the receiver. One of the ways that noise is quantified for SAR sensors is called the Noise Equivalent Sigma Zero (NESZ). This parameter describes the noise floor of an image. All received signals have to be stronger than the NESZ value to rise above the noise level, so it is best for NESZ to be as low as possible. Images with high NESZ values look grainy. Unfortunately, NESZ is mystifying to SAR users who are not familiar with the dB language of engineering. Many users are confused by NESZ values like -20 dB, which actually indicates a fractional level of 1%. That is, an NESZ of -20 dB means the noise level is 1% as strong as a reference reflection from an idealized metal sphere. An NESZ of -17 dB would means the noise level is 2% as strong as the reference. System designers have to consider many competing imaging parameters to balance image quality, resolution and noise. For spacecraft, the best choices are increased average power, larger antennas, the use of high-quality receivers with low noise factors, steeper illumination angles, and lower orbits. The ICEYE Innovation In this overview of SAR, we have discussed several remarkable capabilities beyond its famous ability to penetrate clouds. These include image resolution independent of distance, electronic beam control to vary resolution and coverage, pristine geolocation, and the natural ability to measure phase to within a small fraction of a wavelength. We\u2019ve seen that SAR pixels have both amplitude and phase, and from these we can produce many useful products. At ICEYE, we have developed an innovative way to incorporate all of these aspects of SAR in our small and adaptable systems. We are launching a full constellation of small SARs, and we\u2019ll upgrade them routinely to better image this ocean planet. References Thomas P. Ager. The Essentials of SAR: A Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities . 2021. ISBN-13 \u200f : \u200e 979-8512864487. \u21a9","title":"An Overview of SAR Imaging"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#an-overview-of-sar-imaging","text":"Note This overview is exercepted with permission from The Essentials of SAR , by Thomas P. Ager 1 This comprehensive text was written for SAR users, not electrical engineers. It reviews the many interesting aspects of SAR and its uses that we cannot cover in this short overview.","title":"An Overview of SAR Imaging"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-value-of-sar-imaging","text":"Synthetic aperture radar is well known as the imaging technique that can see through clouds and darkness. But SAR provides a number of other capabilities that are simply not available from optical sources. These include: High Resolution Independent of Distance : One of the outstanding characteristics of SAR is that it is capable of detailed resolution regardless of how far away the sensor is from the ground. SAR sensors can provide very high resolution, even from space. Variable Resolution and Coverage : SAR illumination is controlled electronically, and it can be manipulated to vary resolution and coverage. Images can be collected over small areas at fine resolution, over medium-sized areas at medium resolution or over large areas at coarse resolution. Precision Geolocation : SAR measurements are inherently precise. Properly calibrated images can have geolocation accuracy less than the scale of a single pixel for well-defined features. Coherent Illumination and Many Products : The controlled nature of SAR imaging enables the formation of images and many other products. These include sub-aperture image stacks that highlight glinting features and motion, dense elevation models, precise measurements of surface motion, and amplitude and coherent change images or series.","title":"The Value of SAR Imaging"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#radar-bands","text":"There are several radar bands ranging from wavelengths at the millimeter level to a full meter (Table 1). X-Band has the best combination of cloud-penetration and resolution for spaceborne sensors. In addition to atmospheric gases, there are larger atmospheric particles that scatter visible light but which are transparent to microwaves. In addition to penetrating clouds, X-band radar waves travel through smog, volcanic ash, and sandstorms. BAND WAVELENGTH [cm] FREQUENCY [GHZ] Origin UHF 30 to 100 1 to 0.3 Ultra High Frequency P 60 to 120 0.5 to 0.25 P for \"previous\", as the British used the band for the earliest radars, but later switched to higher frequencies. L 15 to 30 2 to 1 for 'Long Wave' S 7.5 to 15 4 to 2 for 'Short Wave'. Not to be confused with the radio band C 3.75 to 7.5 8 to 4 Originally for 'compromise' between S and X band X 2.5 to 3.75 12 to 8 Used in WWII for fire control, X for cross as in crosshair Ku 1.67 to 2.5 18 to 12 for \"Kurz-under\" K 1.11 to 1.67 27 to 18 German \"kurz\" means short, another reference to short wavelength Ka 0.75 to 1.11 40 to 27 Ka for \"kurz-above\" V 0.40 to 0.75 75 to 40 V for 'very' high frequency - not to be confused with VHF W 0.27 to 0.40 110 to 75 W follows V in the alphabet mm 0.10 to 0.27 300 to 110 millimeter wave Table 1 : Radar Bands","title":"Radar Bands"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#a-simple-form-of-radar-imaging","text":"As seen in Figure 1 the radar antenna emits a series of pulses toward the ground where they are scattered in many directions. The sensor records the \u201cbackscatter\u201d, which is the portion reflected toward the antenna. It measures the strength of the echo and the time it took for the pulse to travel to the ground and back. Figure 1: Pulse Transmission and Backscatter Signal strength corresponds to pixel brightness and the timing provides range information. The range is one-half the total travel time. In the equation below, \\(\\Delta T\\) is the travel time and \\(c\\) is the speed of light: \\[Range = \\frac{\\Delta T\\ c}{2}\\]","title":"A Simple Form of Radar Imaging"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#side-looking-illumination","text":"Since the pixels of a radar imaging system are placed on the image based partly on their range, the antenna cannot illuminate the ground in a vertical orientation. If it did, features on the same imaging line at equivalent angles off nadir would have identical ranges, like the two purple diamonds in Figure 2, and they would occupy the same pixel location. Figure 2: Vertical Illumination Radar imaging must be side-looking so that ground points from the near to far range have different range values (Figure 3). The illumination is typically broadside, or perpendicular, to the flight direction. Figure 3: Side-Looking Illumination","title":"Side-Looking Illumination"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#radar-angles","text":"The angles associated with radar illumination are shown in Figure 4, which is based on a spherical earth surface. Most radar imaging is broadside to the flight direction, but some systems can collect off-broadside in a squinted orientation. The angle down from the local level at the sensor is called the depression angle. The angle between the line-of-sight ray and the local vertical is the incidence angle. The angle between the tangent to the surface and the line of sight is the grazing angle. Note that the incidence and grazing angles are complements in that they form a right angle when combined. This means that a 60\u00b0 incidence angle is the same as a 30\u00b0 grazing angle. Figure 4: Radar Imaging Angles","title":"Radar Angles"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#side-looking-airborne-radar","text":"The first useful radar imaging technique was a form called Side-Looking Airborne Radar (SLAR) (Figure 5). The image is built up via the forward motion of the antenna, one line at a time. The pulses are emitted at a rate called the pulse repetition frequency (PRF), which can range from a few hundred pulses each second for airborne systems to thousands each second for spacecraft. In the SLAR technique, the individual pulses create each image line. The angular width of the pulse on the ground along the direction of flight, or azimuth direction, determines one component of resolution. The range measurements are collected in the \u201cslant range\u201d direction, and range variations to different objects form the second dimension of resolution. Figure 5: Side-Looking Airborne Radar SLAR was used the early days of radar imaging but it had serious limitations. Range resolution was one-half the length of the pulse in the range direction. Since the pulses are emitted at light speed, even a very brief pulse of one-millionth of a second would be 300 meters long and produce range resolution of 150 meters (Figure 6). Azimuth resolution was based on the angular width of the pulse in the azimuth direction ( \\(\\beta\\) ). Long antennas create narrow beams, but the beam spreads out from the antenna to the distant ground surface. Antennas cannot be made long enough to produce good azimuth resolution, and SLAR produced images with resolutions in the hundreds of meters, even from aircraft. This is why the brilliant concept of synthesizing a long antenna from the actions of a small one was developed. We call this Synthetic Aperture Radar. Figure 6: SLAR Pulse Dimensions","title":"Side Looking Airborne Radar"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-remarkable-story-of-synthetic-aperture-radar","text":"","title":"The Remarkable Story of Synthetic Aperture Radar"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#improving-azimuth-resolution-by-synthesizing-a-long-antenna","text":"It takes a long antenna to create narrow radar beams, but the aperture itself does not have to be a giant physical antenna. Instead, a \u201csynthetic\u201d aperture can be created from a small antenna and a linear extent of recording locations. Figure 7 shows a radar antenna sequentially emitting a series of pulses, like a microwave strobe light, and recording the echoes from a string of receive positions. Figure 7: Linear Extent of Recording Locations In the SAR technique all of the measurements are stored and later processed together. It is as if they were collected from one long antenna equal in length to the extent of the sensor locations that received the echoes. Synthetic Aperture Radar is a post-processing scheme applied to data collected by a standard radar antenna and receiver.","title":"Improving Azimuth Resolution by Synthesizing a Long Antenna"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#stripmap-and-spotlight-apertures","text":"There are a few methods to illuminate the ground in SAR imaging. These collection modes trade off resolution and coverage in different ways. To establish how we can simulate long apertures we\u2019ll contrast the two most common forms of SAR imaging: stripmap and spotlight. In stripmap mode the pulses are sent out at a constant angle, usually broadside to the flight direction. In this case, the length of this simulated aperture ( \\(L\\) ) is the same as the width of the beam on the ground (Figure 8). Wider beams produced by smaller antennas mean longer apertures and better azimuth resolution. This directly contrasts with the real-aperture radar of SLAR where the beam was kept as narrow as possible to obtain good resolution. Figure 8: Stripmap Synthetic Aperture The spotlight form of SAR varies the boresight angle in the azimuth direction to illuminate a fixed ground location (Figure 9). This technique greatly increases the synthetic-aperture length and offers excellent azimuth resolution, at the cost of limited ground coverage. At ICEYE we are capable of illuminating a fixed spot for as long as 30 seconds. Given the velocity of low-earth orbits (7.5 km/sec), this yields a synthetic aperture more than 225 kilometers long ! Figure 9: Spotlight Synthetic Aperture","title":"Stripmap and Spotlight Apertures"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#phase-history-data-and-sar-azimuth-resolution","text":"We can create long \u201csynthetic\u201d apertures because radar illumination is coherent. That is, the sensor controls the structure of the transmitted pulses and they all have the same form. It emits pulses and measures the details of each echo: time, strength and \u201cphase\u201d. Phase refers to the position of the wave in its cycle, denoting whether it is at its peak, trough or somewhere in between. The SAR antenna moves only slightly from pulse to pulse. It turns out that the change in location must be less than one-half the antenna length. But this small change in location causes the successive measurements of the range to some object to change as well. The slight change in position imparts a slight change in range. Since the phase is dependent on the range, the small change in adjacent sensor locations also imparts a slight change in phase. These phase changes form a pattern across the aperture, which changes depending on the azimuth location of a ground feature. The record of all the changing phases for all the scatterers in the scene is called phase history data. For a particular object, this is the \u201chistory\u201d of how phase changed from one receive location to the next. Given carefully measured sensor locations, the phase histories for each location across the scene are predictable. The azimuth position of each scatterer can be calculated by comparing the predicted phase pattern of some location to the measured phase history pattern for that point. This is the essence of azimuth resolution. Phase history data and their reference patterns are compared to discriminate the azimuth position of scatterers in the scene. Now that we have that huge aperture and the equation for azimuth resolution becomes: \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] where \\(\\delta_{az}\\) is the SAR azimuth resolution. This equation is gorgeous. It says that azimuth resolution is based on the wavelength of our radar waves and the change in the integration angle ( \\(\\Delta \\theta\\) ) while the point was being imaged (Figure 10). Resolution improves when the wavelength is small and the integration angle change is large. Figure 10: Spotlight Synthetic Aperture Angle Now let\u2019s use SAR with an integration angle change of 0.07 radians (4.5\u00b0). This is reasonable because the current operational performance of ICEYE's spotlight mode can easily exceed this angle. \\[\\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[\\delta_{az} = \\frac{3 cm}{2 \\times 0.07} \\] \\[\\delta_{az} = 0.21m \\] For stripmap mode the azimuth resolution equation reduces to a simpler form, where \\(D_A\\) is the length of the antenna in the azimuth direction: \\[\\delta_{az} = \\frac{D_A}{2} \\] This is just a special stripmap case of the more general equation, but it seems to imply that we could make the antenna really small to achieve good stripmap resolution. While this is literally true, the small size of the antenna would lessen the total power that could be transmitted and also degrade the ability to record the weak backscattered echoes. Noise would increase significantly. It would also require the PRF to get unreasonably large because a pulse is required at least every one-half antenna length. Stripmap cannot support high-resolution SAR. For that we need to steer the beam during illumination to increase the synthetic aperture, as with a spotlight collection. This mode is capable of fine resolution and it can use a larger, and therefore more powerful and sensitive antenna.","title":"Phase History Data and SAR Azimuth Resolution"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#something-is-missing","text":"These elegant equations are an astonishing statement about resolution, but it is even more amazing when we consider what is missing. Notice that the SAR azimuth resolution equations do not include a term for distance. Use it on an aircraft or move it all the way out into space, and azimuth resolution does not change. Of course, distance does impact signal strength. When the sensor is further away, the signal strength weakens dramatically and this poses serious challenges to the SAR imaging process. We will not discuss this issue in this overview, but we can say here that radar antennas are very sensitive. Spaceborne SARs successfully record very weak backscatters.","title":"Something Is Missing"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#fixing-range-resolution-by-synthesizing-a-short-pulse","text":"In our discussions about aperture synthesis, we did not say anything about range resolution. This is because the \u201csynthetic aperture\u201d technique itself deals only with azimuth. It does not do anything to address the problem we saw with brute-force range resolution. Recall that this is one-half of the pulse length, which is the speed of light ( \\(c\\) ) times the pulse duration, \\(T\\) : \\[\\delta_{ra} = \\frac{c\\ T}{2}\\] where \\(\\delta_{ra}\\) is the slant range resolution. Thus far, we have described our radar pulses as if they have a fixed frequency, like X-band pulses of 10 GHz frequency and a 3 cm wavelength. But most radars actually transmit chirped pulses in which the frequency changes (Figure 11). Notice how the wavelength of the green pulse is manipulated and varies from long to short Figure 11: Chirped Pulse When we state the frequency or wavelength of a SAR sensor, those values typically apply at the mid-way time of the pulse. This is known as the radar center frequency or wavelength. The actual transmitted wavelengths are varied quite a bit on either side to form chirped pulses (Figure 12). Figure 12: Centre Frequency There are many different pulse modulation techniques, but the chirp with a smoothly varying frequency is most common. A chirped pulse is easy to produce and since the total transmitted energy is a product of amplitude and duration, a long pulse can contain a substantial amount of energy without needing a large peak power. A chirped pulse enables high range resolution because its form is exactly specified and its echo is a reversed and weakened copy. The reflection has the same shape as the emitted signal, it\u2019s just flipped and has a much smaller amplitude. The two are compared in what is called a matched filter process. The known structure of the emitted pulse is compared to the echo at various locations. A calculation is performed, and if they are misaligned the result of this calculation is zero. At the exact location where they match there is a strong signal that indicates the match. A synthetic pulse that is narrow in range replaces the spread-out pulse (Figure 13). Figure 13: Range Compression The width of the compressed pulse is based entirely on the bandwidth of the emitted pulse. The slant range resolution equation is transformed: \\[ \\delta_{slant\\ range\\ chirp\\ compressed} = \\frac{c}{2B} \\] This is a really beautiful equation. It is so simple and powerful. Resolution in range is entirely based on how much bandwidth we impart to chirped pulses, and like its azimuth counterpart it has nothing whatsoever to do with distance to the ground.","title":"Fixing Range Resolution by Synthesizing a Short Pulse"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#slant-range-resolution-examples","text":"So how much can we vary pulse frequency? Well, bandwidths can be made really large. Consider an X-band system capable of 300,000,000 cycles per second (300 MHz) of bandwidth. We can calculate resolution in the slant range: \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300MHz} \\] \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300\\times10^8Hz} \\] \\[ \\delta_{sr} = 0.5 metres \\] Plans for the next generation of ICEYE satellites include pulse bandwidths of 600 MHz and 1200 MHz. These will yield a slant range resolution cell of 0.25 meters and better from a satellite that is perhaps 750,000 meters away from the imaged area.","title":"Slant Range Resolution Examples"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#ground-range-resolution","text":"The slant range is the distance between the antenna and the target, and that is the direction where range resolution is measured. To produce images along the ground surface, the pixels have to be projected to the \u201cground range\u201d from their original slant range orientation (Figure 14). This has the effect of elongating the pixels in range. Figure 14: Ground Range Resolution The illustration shows the relationship between slant range resolution, shown in blue, and the length of the equivalent resolution distance along the ground, shown in green. When the illumination is steep, as in this example, the projection to the ground surface results in a much longer ground range cell. You can imagine what would happen as the steepness continued to approach nadir. This is exactly opposite to the situation with optical imaging resolution, which is best at nadir. Slant range and ground range resolution comparisons for two incidence angles are shown in Table 2. Notice the dramatic increase for the steeper illumination. Incidence Angle 30\u00b0 Incidence Angle 60\u00b0 Slant Range 0.50m 0.50m Ground Range 1.00m 0.55m Table 2: Resolution comparison between slant range and ground range While slant range resolution seems \u201cbetter\u201d than ground range resolution, keep in mind that it refers to the sensor\u2019s ability to discriminate features along the oblique path of the energy. Most of the features we care about lie along the ground surface, and ground range resolution is a useful way to describe image resolution.","title":"Ground Range Resolution"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-beautiful-equations","text":"The brute force method of real-aperture radar cannot produce high-resolution images. In synthetic-aperture radar we take advantage of the natural coherence of radar illumination to produce structured and consistent pulses. These enable the measurement of slight pulse-to-pulse phase shifts and the use of frequency-modulated chirps. The innovations of aperture synthesis, modulated waveforms and pulse compression produce images capable of a remarkable pixel resolution and which does not degrade as distance to the ground increases. Even though they are handled differently, the azimuth and range processes have a fundamental similarity: Azimuth resolution is based on phase variations across the collection interval. These are compared to known phase variations across that area to produce a long \u201csynthetic\u201d aperture and a resolution cell narrow in azimuth. Range resolution is based on frequency variations across the returned pulse. These are compared to known frequency variations in the reference pulse to produce a short \u201csynthetic\u201d pulse and a resolution cell narrow in range. These processes result in two of the most simple and powerful equations in all of remote sensing. They are the equations that describe the spatial resolution of a SAR sensor. They are The Beautiful Equations : \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[ \\delta_{sr} = \\frac{c}{2B} \\] with \\(\\delta_{az}\\) and \\(\\delta_{sr}\\) being the azimuth resolution and the slant range resolution respectively.","title":"The Beautiful Equations"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-sar-processing-flow-and-its-products","text":"SAR image generation begins with the emission of thousands of coherent pulses and the decomposition of each echo into raw measurements of time, amplitude and phase. The first part of the processing flow is called Phase History Processing because it accounts for the changes over time of the phase values of each scatterer. Phase history data are focused into the azimuth and range components of each resolution cell to produce an image product called a \u201ccomplex image\u201d (Figure 15). Figure 15: The SAR Processing Flow and Its Products","title":"The SAR Processing Flow and Its Products"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-complex-image","text":"Info By the way, you will hear SAR engineers refer to the two parameters of a complex image as \u201cIn-Phase\u201d and \u201cQuadrature\u201d. These are just another way to describe the complex values. The left image in Figure 16 is a ICEYE amplitude image of agricultural fields. In this image each pixel has a brightness value assigned to it. This is what many people consider to be the base SAR product, but this is really only half of the full image. The SAR processor calculates the average phase value for each pixel as well. The matching \u201cphase image\u201d of that same scene is on the right in the figure. The combination of these two images is called a complex image, in which every pixel has amplitude and phase values. We use the term \u201ccomplex\u201d because the pixels are described by a mathematical construct called a complex number, where every number has two components. Figure 16: Amplitude and Phase Structure of a Complex Image Of course, phase data are not useful for direct human interpretation. And while they may look like random noise, phase pixels are a unique and valuable aspect of SAR imaging. Phase data can be used to manipulate the synthetic aperture in different ways to extract useful information that is not available from amplitude images. Moreover, changes in the phase measurements of the same object on different images can be used to detect small surface structure characteristics. In the next section we\u2019ll discuss how we can use phase data to refine images and create other products.","title":"The Complex Image"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#sar-products-derived-from-complex-data","text":"","title":"SAR Products Derived from Complex Data"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#amplitude-images","text":"Info You should also be aware that an engineering calculation called \u201cdetection\u201d converts in-phase and quadrature values to amplitude values. Engineers often refer to SAR amplitude images as \u201cdetected\u201d images. An amplitude image is certainly the most common SAR product, but you need to appreciate that this image is produced for human viewing and analysis. It is not the core image product. Amplitude images do not contain any phase information. Furthermore, the version of the amplitude image used for human viewing is not a direct copy of the amplitude values in a complex image. This is because radar sensors record an enormous span of brightness levels for each complex pixel. The maximum intensity of amplitude in a complex image is usually more than 100,000 times (50 dB) the minimum intensity, and for the best-quality images with bright targets, it is much greater. ICEYE images are produced with 16 bits of dynamic range per pixel (65536 gray levels) but even this is not sufficient to record the full dynamic range of SAR. As valuable as they are, amplitude images have no phase data and they lose much of the dynamic range of complex pixels. You can imagine the growing potential for computers and algorithms to process those complex pixels in ways the human visual system cannot.","title":"Amplitude Images"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#multi-look-amplitude-images","text":"One way in which we can use complex data is to produce different versions of the seemingly simple amplitude image. One common form of an amplitude image, for example, is called a multi-look image. Consider that azimuth and range resolution are handled independently. One is based on the length of the synthetic aperture and the other is based on the signal bandwidth, and sometimes these are quite different in magnitude. It is common for azimuth resolution to be collected at a higher fidelity than range resolution. If a full-resolution image were produced from such data it would look compressed in range. To view the image in a more natural aspect we need to \u201csquare the pixels\u201d so that the range and azimuth scales are the same. Info Speckle is a grainy, noise-like feature of SAR images. It is caused by the coherent nature of SAR illumination. The reflections from small scatterers within a resolution cell combine constructively and destructively to brighten or darken the returns. This is done by manipulating the synthetic aperture into smaller sub-apertures and then combining them. The sub-apertures are called \u201clooks\u201d and they each produce an image with lower azimuth resolution. This may sound disappointing, but when these individual sub-aperture images are combined, they form a multi-look image in which the noisy effect of speckle is reduced. Complex images are stored at full-resolution and are called single-look complex (SLC) images. Amplitude images are typically multi-looked in azimuth using two to 12 sub-apertures. If range resolution exceeds azimuth resolution a similar multi-look process can be applied in the range dimension.","title":"Multi-look Amplitude Images"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#sub-aperture-stack-or-video-image","text":"Suppose we take the aperture splitting further and create six or seven segments to produce multiple sub-aperture images. One advantage of this sub-aperture stack is that it can indicate glints that are bright in only a portion of the full aperture. This signature might be washed out on the full-resolution image by the bulk of the aperture in which there was no glinting, but it can be very noticeable in one of the low-resolution sub-apertures. Glints tend to be important signatures because they are usually caused by human-made features. We could even loop the stack like a short movie, or SAR video image, to look for such glints and moving objects. This product works best for long spotlight exposures of ten seconds or more.","title":"Sub-aperture Stack or Video Image"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#amplitude-and-coherent-change-images","text":"Perhaps the most useful SAR products are the amplitude and coherent change images (ACI, CCI). Two or more images of the same site are collected at different times to detect scene changes. For ACD only the brightness values are compared, while CCD uses phase data. In order for change detection to work, the images have to be collected from nearly the same location in space with similar illumination geometries. For ACD the two images can be overlaid in the complementary colors (eg red and cyan). In this way, features with similar backscatters will be gray, but features with backscatters that changed during the imaging period will appear in one of the two colors. It is conventional for the first image to be displayed in red and the second in cyan. If something on the ground changes between the two collections you will see whichever color signature is dominant. A mnemonic is used to help interpret ACD products: \u201cRed is fled. Blue is new\u201d. That is, a red signature indicates a feature that was present on the first image but left the scene prior to the second image, and a blue signature indicates a feature that appears only on the second image. This mnemonic is an easy way to help remember the order of the images, but appreciate that the second image is actually cyan, not blue. The intentional sloppiness of the mnemonic is acceptable here because verbal precision would ruin the rhyme. In contrast to amplitude change detection, CCD compares the phase values of two nearly identical images taken at different times. CCD is far more sensitive to changes because it is based on phase differences rather than pixel brightness differences and, as we know, phase is measured to within a small fraction of a wavelength. The collection constraints to ensure image-to-image coherence are tighter for CCD than ACD. When the collection parameters are nearly identical, the phase values are also nearly identical, and any changes are due to backscatter differences at a scale of less than one wavelength. It is typical for CCD images to display pixels where phase is consistent in white and the pixels where the phase has changed are dark. These are areas where the two images have \u201cdecorrelated\u201d, or lost phase consistency, due to some subtle change in the scene.","title":"Amplitude and Coherent Change Images"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#other-multi-image-sar-products","text":"The amplitude and phase data of SAR images can be combined to produce other useful products that are too numerous to describe in detail in this overview. These include digital elevation models derived from pixel brightness values or phase data, millimeter-level surface motion measurements derived phase comparisons of sets of matching images, and automated detections of ships, oil spills and other features. Once constellations of small SARs are established it will be possible to monitor any site in the world with large stacks of exactly matching images whose consistent signatures are linked to known ground features. These images could be collected within hours of each other and they will be the basis of intelligent site monitoring services that will not only detect changes, but which will also say what has changed and how it has changed.","title":"Other Multi-image SAR Products"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#separating-signals-from-noise","text":"","title":"Separating Signals from Noise"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-whisper","text":"As a radar pulse travels from the antenna to the ground surface its total power remains constant, but as it moves away from the antenna, it spreads out into space and its power density weakens. As shown in Figure 17, it is as if the \u201cskin\u201d of the pulse becomes thinner with distance. This weakening is dramatic; it decreases with the square of the distance from the antenna. Figure 17: Expanding Surface Area of a Pulse Given that the ground might be 750 km from the antenna, the pulse is quite weak by the time it finally reflects from surface objects. This presents even more of a problem because only a portion of the weakened pulse is reflected toward the receive antenna, and then it has to travel all the way back, weakening again with the square of the distance. By the time the microwaves return to the antenna, they are microscopically faint. The antenna and radar receiver manage to detect, amplify, and record these echoes so that they can be processed into SAR resolution cells that span more than 100,000 brightness values. SAR is amazing.","title":"The Whisper"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-challenge-of-noise","text":"Those backscattered microwaves are so weak when they arrive at the antenna that they are perturbed by any noise sources that get mixed in with them. Noise is an artifact of random microwave emissions caused mostly by onboard sensor hardware. One of the tenets of remote sensing is that all objects emit electromagnetic energy based on their temperature. The thermal noise of heated receiver hardware spans wide swaths of the spectrum, including the microwave bands, and this competes with those whispering pulse echoes. As they struggle to capture those fading backscatter whispers, radar receivers also record random, interfering microwaves that they themselves produce. One of the disappointing aspects of the noise level is that it increases as range bandwidth increases. The large signal bandwidth that the receiver has to be capable of recording also lets more noise enter the receiver. One of the ways that noise is quantified for SAR sensors is called the Noise Equivalent Sigma Zero (NESZ). This parameter describes the noise floor of an image. All received signals have to be stronger than the NESZ value to rise above the noise level, so it is best for NESZ to be as low as possible. Images with high NESZ values look grainy. Unfortunately, NESZ is mystifying to SAR users who are not familiar with the dB language of engineering. Many users are confused by NESZ values like -20 dB, which actually indicates a fractional level of 1%. That is, an NESZ of -20 dB means the noise level is 1% as strong as a reference reflection from an idealized metal sphere. An NESZ of -17 dB would means the noise level is 2% as strong as the reference. System designers have to consider many competing imaging parameters to balance image quality, resolution and noise. For spacecraft, the best choices are increased average power, larger antennas, the use of high-quality receivers with low noise factors, steeper illumination angles, and lower orbits.","title":"The Challenge of Noise"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#the-iceye-innovation","text":"In this overview of SAR, we have discussed several remarkable capabilities beyond its famous ability to penetrate clouds. These include image resolution independent of distance, electronic beam control to vary resolution and coverage, pristine geolocation, and the natural ability to measure phase to within a small fraction of a wavelength. We\u2019ve seen that SAR pixels have both amplitude and phase, and from these we can produce many useful products. At ICEYE, we have developed an innovative way to incorporate all of these aspects of SAR in our small and adaptable systems. We are launching a full constellation of small SARs, and we\u2019ll upgrade them routinely to better image this ocean planet.","title":"The ICEYE Innovation"},{"location":"OverviewOfSAR/overviewofSAR-fulltext/#references","text":"Thomas P. Ager. The Essentials of SAR: A Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities . 2021. ISBN-13 \u200f : \u200e 979-8512864487. \u21a9","title":"References"},{"location":"OverviewOfSAR/rangeResolution/","text":"Range Resolution Fixing Range Resolution by Synthesizing a Short Pulse In our discussions about aperture synthesis, we did not say anything about range resolution. This is because the \u201csynthetic aperture\u201d technique itself deals only with azimuth. It does not do anything to address the problem we saw with brute-force range resolution. Recall that this is one-half of the pulse length, which is the speed of light ( \\(c\\) ) times the pulse duration, \\(T\\) : \\[\\delta_{ra} = \\frac{c\\ T}{2}\\] where \\(\\delta_{ra}\\) is the slant range resolution. Thus far, we have described our radar pulses as if they have a fixed frequency, like X-band pulses of 10 GHz frequency and a 3 cm wavelength. But most radars actually transmit chirped pulses in which the frequency changes (Figure 11). Notice how the wavelength of the green pulse is manipulated and varies from long to short Figure 11: Chirped Pulse When we state the frequency or wavelength of a SAR sensor, those values typically apply at the mid-way time of the pulse. This is known as the radar center frequency or wavelength. The actual transmitted wavelengths are varied quite a bit on either side to form chirped pulses (Figure 12). Figure 12: Centre Frequency There are many different pulse modulation techniques, but the chirp with a smoothly varying frequency is most common. A chirped pulse is easy to produce and since the total transmitted energy is a product of amplitude and duration, a long pulse can contain a substantial amount of energy without needing a large peak power. A chirped pulse enables high range resolution because its form is exactly specified and its echo is a reversed and weakened copy. The reflection has the same shape as the emitted signal, it\u2019s just flipped and has a much smaller amplitude. The two are compared in what is called a matched filter process. The known structure of the emitted pulse is compared to the echo at various locations. A calculation is performed, and if they are misaligned the result of this calculation is zero. At the exact location where they match there is a strong signal that indicates the match. A synthetic pulse that is narrow in range replaces the spread-out pulse (Figure 13). Figure 13: Range Compression The width of the compressed pulse is based entirely on the bandwidth of the emitted pulse. The slant range resolution equation is transformed: \\[ \\delta_{slant\\ range\\ chirp\\ compressed} = \\frac{c}{2B} \\] This is a really beautiful equation. It is so simple and powerful. Resolution in range is entirely based on how much bandwidth we impart to chirped pulses, and like its azimuth counterpart it has nothing whatsoever to do with distance to the ground. Slant Range Resolution Examples So how much can we vary pulse frequency? Well, bandwidths can be made really large. Consider an X-band system capable of 300,000,000 cycles per second (300 MHz) of bandwidth. We can calculate resolution in the slant range: \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300MHz} \\] \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300\\times10^8Hz} \\] \\[ \\delta_{sr} = 0.5 metres \\] Plans for the next generation of ICEYE satellites include pulse bandwidths of 600 MHz and 1200 MHz. These will yield a slant range resolution cell of 0.25 meters and better from a satellite that is perhaps 750,000 meters away from the imaged area. Ground Range Resolution The slant range is the distance between the antenna and the target, and that is the direction where range resolution is measured. To produce images along the ground surface, the pixels have to be projected to the \u201cground range\u201d from their original slant range orientation (Figure 14). This has the effect of elongating the pixels in range. Figure 14: Ground Range Resolution The illustration shows the relationship between slant range resolution, shown in blue, and the length of the equivalent resolution distance along the ground, shown in green. When the illumination is steep, as in this example, the projection to the ground surface results in a much longer ground range cell. You can imagine what would happen as the steepness continued to approach nadir. This is exactly opposite to the situation with optical imaging resolution, which is best at nadir. Slant range and ground range resolution comparisons for two incidence angles are shown in Table 2. Notice the dramatic increase for the steeper illumination. INCIDENCE ANGLE 30\u00b0 INCIDENCE ANGLE 60\u00b0 Slant Range 0.50m 0.50m Ground Range 1.00m 0.55m Table 2: Resolution comparison between slant range and ground range While slant range resolution seems \u201cbetter\u201d than ground range resolution, keep in mind that it refers to the sensor\u2019s ability to discriminate features along the oblique path of the energy. Most of the features we care about lie along the ground surface, and ground range resolution is a useful way to describe image resolution.","title":"Range Resolution"},{"location":"OverviewOfSAR/rangeResolution/#range-resolution","text":"","title":"Range Resolution"},{"location":"OverviewOfSAR/rangeResolution/#fixing-range-resolution-by-synthesizing-a-short-pulse","text":"In our discussions about aperture synthesis, we did not say anything about range resolution. This is because the \u201csynthetic aperture\u201d technique itself deals only with azimuth. It does not do anything to address the problem we saw with brute-force range resolution. Recall that this is one-half of the pulse length, which is the speed of light ( \\(c\\) ) times the pulse duration, \\(T\\) : \\[\\delta_{ra} = \\frac{c\\ T}{2}\\] where \\(\\delta_{ra}\\) is the slant range resolution. Thus far, we have described our radar pulses as if they have a fixed frequency, like X-band pulses of 10 GHz frequency and a 3 cm wavelength. But most radars actually transmit chirped pulses in which the frequency changes (Figure 11). Notice how the wavelength of the green pulse is manipulated and varies from long to short Figure 11: Chirped Pulse When we state the frequency or wavelength of a SAR sensor, those values typically apply at the mid-way time of the pulse. This is known as the radar center frequency or wavelength. The actual transmitted wavelengths are varied quite a bit on either side to form chirped pulses (Figure 12). Figure 12: Centre Frequency There are many different pulse modulation techniques, but the chirp with a smoothly varying frequency is most common. A chirped pulse is easy to produce and since the total transmitted energy is a product of amplitude and duration, a long pulse can contain a substantial amount of energy without needing a large peak power. A chirped pulse enables high range resolution because its form is exactly specified and its echo is a reversed and weakened copy. The reflection has the same shape as the emitted signal, it\u2019s just flipped and has a much smaller amplitude. The two are compared in what is called a matched filter process. The known structure of the emitted pulse is compared to the echo at various locations. A calculation is performed, and if they are misaligned the result of this calculation is zero. At the exact location where they match there is a strong signal that indicates the match. A synthetic pulse that is narrow in range replaces the spread-out pulse (Figure 13). Figure 13: Range Compression The width of the compressed pulse is based entirely on the bandwidth of the emitted pulse. The slant range resolution equation is transformed: \\[ \\delta_{slant\\ range\\ chirp\\ compressed} = \\frac{c}{2B} \\] This is a really beautiful equation. It is so simple and powerful. Resolution in range is entirely based on how much bandwidth we impart to chirped pulses, and like its azimuth counterpart it has nothing whatsoever to do with distance to the ground.","title":"Fixing Range Resolution by Synthesizing a Short Pulse"},{"location":"OverviewOfSAR/rangeResolution/#slant-range-resolution-examples","text":"So how much can we vary pulse frequency? Well, bandwidths can be made really large. Consider an X-band system capable of 300,000,000 cycles per second (300 MHz) of bandwidth. We can calculate resolution in the slant range: \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300MHz} \\] \\[ \\delta_{sr} = \\frac{3\\times10^8\\ m/sec}{2\\times300\\times10^8Hz} \\] \\[ \\delta_{sr} = 0.5 metres \\] Plans for the next generation of ICEYE satellites include pulse bandwidths of 600 MHz and 1200 MHz. These will yield a slant range resolution cell of 0.25 meters and better from a satellite that is perhaps 750,000 meters away from the imaged area.","title":"Slant Range Resolution Examples"},{"location":"OverviewOfSAR/rangeResolution/#ground-range-resolution","text":"The slant range is the distance between the antenna and the target, and that is the direction where range resolution is measured. To produce images along the ground surface, the pixels have to be projected to the \u201cground range\u201d from their original slant range orientation (Figure 14). This has the effect of elongating the pixels in range. Figure 14: Ground Range Resolution The illustration shows the relationship between slant range resolution, shown in blue, and the length of the equivalent resolution distance along the ground, shown in green. When the illumination is steep, as in this example, the projection to the ground surface results in a much longer ground range cell. You can imagine what would happen as the steepness continued to approach nadir. This is exactly opposite to the situation with optical imaging resolution, which is best at nadir. Slant range and ground range resolution comparisons for two incidence angles are shown in Table 2. Notice the dramatic increase for the steeper illumination. INCIDENCE ANGLE 30\u00b0 INCIDENCE ANGLE 60\u00b0 Slant Range 0.50m 0.50m Ground Range 1.00m 0.55m Table 2: Resolution comparison between slant range and ground range While slant range resolution seems \u201cbetter\u201d than ground range resolution, keep in mind that it refers to the sensor\u2019s ability to discriminate features along the oblique path of the energy. Most of the features we care about lie along the ground surface, and ground range resolution is a useful way to describe image resolution.","title":"Ground Range Resolution"},{"location":"OverviewOfSAR/remarkableStory/","text":"The Remarkable Story of Synthetic Aperture Radar Improving Azimuth Resolution by Synthesizing a Long Antenna It takes a long antenna to create narrow radar beams, but the aperture itself does not have to be a giant physical antenna. Instead, a \u201csynthetic\u201d aperture can be created from a small antenna and a linear extent of recording locations. Figure 7 shows a radar antenna sequentially emitting a series of pulses, like a microwave strobe light, and recording the echoes from a string of receive positions. Figure 7: Linear Extent of Recording Locations In the SAR technique all of the measurements are stored and later processed together. It is as if they were collected from one long antenna equal in length to the extent of the sensor locations that received the echoes. Synthetic Aperture Radar is a post-processing scheme applied to data collected by a standard radar antenna and receiver. Stripmap and Spotlight Apertures There are a few methods to illuminate the ground in SAR imaging. These collection modes trade off resolution and coverage in different ways. To establish how we can simulate long apertures we\u2019ll contrast the two most common forms of SAR imaging: stripmap and spotlight. In stripmap mode the pulses are sent out at a constant angle, usually broadside to the flight direction. In this case, the length of this simulated aperture ( \\(L\\) ) is the same as the width of the beam on the ground (Figure 8). Wider beams produced by smaller antennas mean longer apertures and better azimuth resolution. This directly contrasts with the real-aperture radar of SLAR where the beam was kept as narrow as possible to obtain good resolution. Figure 8: Stripmap Synthetic Aperture The spotlight form of SAR varies the boresight angle in the azimuth direction to illuminate a fixed ground location (Figure 9). This technique greatly increases the synthetic-aperture length and offers excellent azimuth resolution, at the cost of limited ground coverage. At ICEYE we are capable of illuminating a fixed spot for as long as 30 seconds. Given the velocity of low-earth orbits (7.5 km/sec), this yields a synthetic aperture more than 225 kilometers long ! Figure 9: Spotlight Synthetic Aperture Phase History Data and SAR Azimuth Resolution We can create long \u201csynthetic\u201d apertures because radar illumination is coherent. That is, the sensor controls the structure of the transmitted pulses and they all have the same form. It emits pulses and measures the details of each echo: time, strength and \u201cphase\u201d. Phase refers to the position of the wave in its cycle, denoting whether it is at its peak, trough or somewhere in between. The SAR antenna moves only slightly from pulse to pulse. It turns out that the change in location must be less than one-half the antenna length. But this small change in location causes the successive measurements of the range to some object to change as well. The slight change in position imparts a slight change in range. Since the phase is dependent on the range, the small change in adjacent sensor locations also imparts a slight change in phase. These phase changes form a pattern across the aperture, which changes depending on the azimuth location of a ground feature. The record of all the changing phases for all the scatterers in the scene is called phase history data. For a particular object, this is the \u201chistory\u201d of how phase changed from one receive location to the next. Given carefully measured sensor locations, the phase histories for each location across the scene are predictable. The azimuth position of each scatterer can be calculated by comparing the predicted phase pattern of some location to the measured phase history pattern for that point. This is the essence of azimuth resolution. Phase history data and their reference patterns are compared to discriminate the azimuth position of scatterers in the scene. Now that we have that huge aperture and the equation for azimuth resolution becomes: \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] where \\(\\delta_{az}\\) is the SAR azimuth resolution. This equation is gorgeous. It says that azimuth resolution is based on the wavelength of our radar waves and the change in the integration angle ( \\(\\Delta \\theta\\) ) while the point was being imaged (Figure 10). Resolution improves when the wavelength is small and the integration angle change is large. Figure 10: Spotlight Synthetic Aperture Angle Now let\u2019s use SAR with an integration angle change of 0.07 radians (4.5\u00b0). This is reasonable because the current operational performance of ICEYE's spotlight mode can easily exceed this angle. \\[\\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[\\delta_{az} = \\frac{3 cm}{2 \\times 0.07} \\] \\[\\delta_{az} = 0.21m \\] For stripmap mode the azimuth resolution equation reduces to a simpler form, where \\(D_A\\) is the length of the antenna in the azimuth direction: \\[\\delta_{az} = \\frac{D_A}{2} \\] This is just a special stripmap case of the more general equation, but it seems to imply that we could make the antenna really small to achieve good stripmap resolution. While this is literally true, the small size of the antenna would lessen the total power that could be transmitted and also degrade the ability to record the weak backscattered echoes. Noise would increase significantly. It would also require the PRF to get unreasonably large because a pulse is required at least every one-half antenna length. Stripmap cannot support high-resolution SAR. For that we need to steer the beam during illumination to increase the synthetic aperture, as with a spotlight collection. This mode is capable of fine resolution and it can use a larger, and therefore more powerful and sensitive antenna. Something Is Missing These elegant equations are an astonishing statement about resolution, but it is even more amazing when we consider what is missing. Notice that the SAR azimuth resolution equations do not include a term for distance. Use it on an aircraft or move it all the way out into space, and azimuth resolution does not change. Of course, distance does impact signal strength. When the sensor is further away, the signal strength weakens dramatically and this poses serious challenges to the SAR imaging process. We will not discuss this issue in this overview, but we can say here that radar antennas are very sensitive. Spaceborne SARs successfully record very weak backscatters.","title":"The Remarkable Story Of SAR"},{"location":"OverviewOfSAR/remarkableStory/#the-remarkable-story-of-synthetic-aperture-radar","text":"","title":"The Remarkable Story of Synthetic Aperture Radar"},{"location":"OverviewOfSAR/remarkableStory/#improving-azimuth-resolution-by-synthesizing-a-long-antenna","text":"It takes a long antenna to create narrow radar beams, but the aperture itself does not have to be a giant physical antenna. Instead, a \u201csynthetic\u201d aperture can be created from a small antenna and a linear extent of recording locations. Figure 7 shows a radar antenna sequentially emitting a series of pulses, like a microwave strobe light, and recording the echoes from a string of receive positions. Figure 7: Linear Extent of Recording Locations In the SAR technique all of the measurements are stored and later processed together. It is as if they were collected from one long antenna equal in length to the extent of the sensor locations that received the echoes. Synthetic Aperture Radar is a post-processing scheme applied to data collected by a standard radar antenna and receiver.","title":"Improving Azimuth Resolution by Synthesizing a Long Antenna"},{"location":"OverviewOfSAR/remarkableStory/#stripmap-and-spotlight-apertures","text":"There are a few methods to illuminate the ground in SAR imaging. These collection modes trade off resolution and coverage in different ways. To establish how we can simulate long apertures we\u2019ll contrast the two most common forms of SAR imaging: stripmap and spotlight. In stripmap mode the pulses are sent out at a constant angle, usually broadside to the flight direction. In this case, the length of this simulated aperture ( \\(L\\) ) is the same as the width of the beam on the ground (Figure 8). Wider beams produced by smaller antennas mean longer apertures and better azimuth resolution. This directly contrasts with the real-aperture radar of SLAR where the beam was kept as narrow as possible to obtain good resolution. Figure 8: Stripmap Synthetic Aperture The spotlight form of SAR varies the boresight angle in the azimuth direction to illuminate a fixed ground location (Figure 9). This technique greatly increases the synthetic-aperture length and offers excellent azimuth resolution, at the cost of limited ground coverage. At ICEYE we are capable of illuminating a fixed spot for as long as 30 seconds. Given the velocity of low-earth orbits (7.5 km/sec), this yields a synthetic aperture more than 225 kilometers long ! Figure 9: Spotlight Synthetic Aperture","title":"Stripmap and Spotlight Apertures"},{"location":"OverviewOfSAR/remarkableStory/#phase-history-data-and-sar-azimuth-resolution","text":"We can create long \u201csynthetic\u201d apertures because radar illumination is coherent. That is, the sensor controls the structure of the transmitted pulses and they all have the same form. It emits pulses and measures the details of each echo: time, strength and \u201cphase\u201d. Phase refers to the position of the wave in its cycle, denoting whether it is at its peak, trough or somewhere in between. The SAR antenna moves only slightly from pulse to pulse. It turns out that the change in location must be less than one-half the antenna length. But this small change in location causes the successive measurements of the range to some object to change as well. The slight change in position imparts a slight change in range. Since the phase is dependent on the range, the small change in adjacent sensor locations also imparts a slight change in phase. These phase changes form a pattern across the aperture, which changes depending on the azimuth location of a ground feature. The record of all the changing phases for all the scatterers in the scene is called phase history data. For a particular object, this is the \u201chistory\u201d of how phase changed from one receive location to the next. Given carefully measured sensor locations, the phase histories for each location across the scene are predictable. The azimuth position of each scatterer can be calculated by comparing the predicted phase pattern of some location to the measured phase history pattern for that point. This is the essence of azimuth resolution. Phase history data and their reference patterns are compared to discriminate the azimuth position of scatterers in the scene. Now that we have that huge aperture and the equation for azimuth resolution becomes: \\[ \\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] where \\(\\delta_{az}\\) is the SAR azimuth resolution. This equation is gorgeous. It says that azimuth resolution is based on the wavelength of our radar waves and the change in the integration angle ( \\(\\Delta \\theta\\) ) while the point was being imaged (Figure 10). Resolution improves when the wavelength is small and the integration angle change is large. Figure 10: Spotlight Synthetic Aperture Angle Now let\u2019s use SAR with an integration angle change of 0.07 radians (4.5\u00b0). This is reasonable because the current operational performance of ICEYE's spotlight mode can easily exceed this angle. \\[\\delta_{az} = \\frac{\\lambda}{2\\Delta \\theta} \\] \\[\\delta_{az} = \\frac{3 cm}{2 \\times 0.07} \\] \\[\\delta_{az} = 0.21m \\] For stripmap mode the azimuth resolution equation reduces to a simpler form, where \\(D_A\\) is the length of the antenna in the azimuth direction: \\[\\delta_{az} = \\frac{D_A}{2} \\] This is just a special stripmap case of the more general equation, but it seems to imply that we could make the antenna really small to achieve good stripmap resolution. While this is literally true, the small size of the antenna would lessen the total power that could be transmitted and also degrade the ability to record the weak backscattered echoes. Noise would increase significantly. It would also require the PRF to get unreasonably large because a pulse is required at least every one-half antenna length. Stripmap cannot support high-resolution SAR. For that we need to steer the beam during illumination to increase the synthetic aperture, as with a spotlight collection. This mode is capable of fine resolution and it can use a larger, and therefore more powerful and sensitive antenna.","title":"Phase History Data and SAR Azimuth Resolution"},{"location":"OverviewOfSAR/remarkableStory/#something-is-missing","text":"These elegant equations are an astonishing statement about resolution, but it is even more amazing when we consider what is missing. Notice that the SAR azimuth resolution equations do not include a term for distance. Use it on an aircraft or move it all the way out into space, and azimuth resolution does not change. Of course, distance does impact signal strength. When the sensor is further away, the signal strength weakens dramatically and this poses serious challenges to the SAR imaging process. We will not discuss this issue in this overview, but we can say here that radar antennas are very sensitive. Spaceborne SARs successfully record very weak backscatters.","title":"Something Is Missing"},{"location":"OverviewOfSAR/sarProcessing/","text":"SAR Processing Overview The SAR Processing Flow and Its Products SAR image generation begins with the emission of thousands of coherent pulses and the decomposition of each echo into raw measurements of time, amplitude and phase. The first part of the processing flow is called Phase History Processing because it accounts for the changes over time of the phase values of each scatterer. Phase history data are focused into the azimuth and range components of each resolution cell to produce an image product called a \u201ccomplex image\u201d (Figure 15). Figure 15: The SAR Processing Flow and Its Products The Complex Image Info By the way, you will hear SAR engineers refer to the two parameters of a complex image as \u201cIn-Phase\u201d and \u201cQuadrature\u201d. These are just another way to describe the complex values. The left image in Figure 16 is a ICEYE amplitude image of agricultural fields. In this image each pixel has a brightness value assigned to it. This is what many people consider to be the base SAR product, but this is really only half of the full image. The SAR processor calculates the average phase value for each pixel as well. The matching \u201cphase image\u201d of that same scene is on the right in the figure. The combination of these two images is called a complex image, in which every pixel has amplitude and phase values. We use the term \u201ccomplex\u201d because the pixels are described by a mathematical construct called a complex number, where every number has two components. Figure 16: Amplitude and Phase Structure of a Complex Image Of course, phase data are not useful for direct human interpretation. And while they may look like random noise, phase pixels are a unique and valuable aspect of SAR imaging. Phase data can be used to manipulate the synthetic aperture in different ways to extract useful information that is not available from amplitude images. Moreover, changes in the phase measurements of the same object on different images can be used to detect small surface structure characteristics. In the next section we\u2019ll discuss how we can use phase data to refine images and create other products. SAR Products Derived from Complex Data Amplitude Images Info You should also be aware that an engineering calculation called \u201cdetection\u201d converts in-phase and quadrature values to amplitude values. Engineers often refer to SAR amplitude images as \u201cdetected\u201d images. An amplitude image is certainly the most common SAR product, but you need to appreciate that this image is produced for human viewing and analysis. It is not the core image product. Amplitude images do not contain any phase information. Furthermore, the version of the amplitude image used for human viewing is not a direct copy of the amplitude values in a complex image. This is because radar sensors record an enormous span of brightness levels for each complex pixel. The maximum intensity of amplitude in a complex image is usually more than 100,000 times (50 dB) the minimum intensity, and for the best-quality images with bright targets, it is much greater. ICEYE images are produced with 16 bits of dynamic range per pixel (65536 gray levels) but even this is not sufficient to record the full dynamic range of SAR. As valuable as they are, amplitude images have no phase data and they lose much of the dynamic range of complex pixels. You can imagine the growing potential for computers and algorithms to process those complex pixels in ways the human visual system cannot. Multi-look Amplitude Images One way in which we can use complex data is to produce different versions of the seemingly simple amplitude image. One common form of an amplitude image, for example, is called a multi-look image. Consider that azimuth and range resolution are handled independently. One is based on the length of the synthetic aperture and the other is based on the signal bandwidth, and sometimes these are quite different in magnitude. It is common for azimuth resolution to be collected at a higher fidelity than range resolution. If a full-resolution image were produced from such data it would look compressed in range. To view the image in a more natural aspect we need to \u201csquare the pixels\u201d so that the range and azimuth scales are the same. Info Speckle is a grainy, noise-like feature of SAR images. It is caused by the coherent nature of SAR illumination. The reflections from small scatterers within a resolution cell combine constructively and destructively to brighten or darken the returns. This is done by manipulating the synthetic aperture into smaller sub-apertures and then combining them. The sub-apertures are called \u201clooks\u201d and they each produce an image with lower azimuth resolution. This may sound disappointing, but when these individual sub-aperture images are combined, they form a multi-look image in which the noisy effect of speckle is reduced. Complex images are stored at full-resolution and are called single-look complex (SLC) images. Amplitude images are typically multi-looked in azimuth using two to 12 sub-apertures. If range resolution exceeds azimuth resolution a similar multi-look process can be applied in the range dimension. Sub-aperture Stack or Video Image Suppose we take the aperture splitting further and create six or seven segments to produce multiple sub-aperture images. One advantage of this sub-aperture stack is that it can indicate glints that are bright in only a portion of the full aperture. This signature might be washed out on the full-resolution image by the bulk of the aperture in which there was no glinting, but it can be very noticeable in one of the low-resolution sub-apertures. Glints tend to be important signatures because they are usually caused by human-made features. We could even loop the stack like a short movie, or SAR video image, to look for such glints and moving objects. This product works best for long spotlight exposures of ten seconds or more. Amplitude and Coherent Change Images Perhaps the most useful SAR products are the amplitude and coherent change images (ACI, CCI). Two or more images of the same site are collected at different times to detect scene changes. For ACD only the brightness values are compared, while CCD uses phase data. In order for change detection to work, the images have to be collected from nearly the same location in space with similar illumination geometries. For ACD the two images can be overlaid in the complementary colors (eg red and cyan). In this way, features with similar backscatters will be gray, but features with backscatters that changed during the imaging period will appear in one of the two colors. It is conventional for the first image to be displayed in red and the second in cyan. If something on the ground changes between the two collections you will see whichever color signature is dominant. A mnemonic is used to help interpret ACD products: \u201cRed is fled. Blue is new\u201d. That is, a red signature indicates a feature that was present on the first image but left the scene prior to the second image, and a blue signature indicates a feature that appears only on the second image. This mnemonic is an easy way to help remember the order of the images, but appreciate that the second image is actually cyan, not blue. The intentional sloppiness of the mnemonic is acceptable here because verbal precision would ruin the rhyme. In contrast to amplitude change detection, CCD compares the phase values of two nearly identical images taken at different times. CCD is far more sensitive to changes because it is based on phase differences rather than pixel brightness differences and, as we know, phase is measured to within a small fraction of a wavelength. The collection constraints to ensure image-to-image coherence are tighter for CCD than ACD. When the collection parameters are nearly identical, the phase values are also nearly identical, and any changes are due to backscatter differences at a scale of less than one wavelength. It is typical for CCD images to display pixels where phase is consistent in white and the pixels where the phase has changed are dark. These are areas where the two images have \u201cdecorrelated\u201d, or lost phase consistency, due to some subtle change in the scene. Other Multi-image SAR Products The amplitude and phase data of SAR images can be combined to produce other useful products that are too numerous to describe in detail in this overview. These include digital elevation models derived from pixel brightness values or phase data, millimeter-level surface motion measurements derived phase comparisons of sets of matching images, and automated detections of ships, oil spills and other features. Once constellations of small SARs are established it will be possible to monitor any site in the world with large stacks of exactly matching images whose consistent signatures are linked to known ground features. These images could be collected within hours of each other and they will be the basis of intelligent site monitoring services that will not only detect changes, but which will also say what has changed and how it has changed.","title":"SAR Processing Overview"},{"location":"OverviewOfSAR/sarProcessing/#sar-processing-overview","text":"","title":"SAR Processing Overview"},{"location":"OverviewOfSAR/sarProcessing/#the-sar-processing-flow-and-its-products","text":"SAR image generation begins with the emission of thousands of coherent pulses and the decomposition of each echo into raw measurements of time, amplitude and phase. The first part of the processing flow is called Phase History Processing because it accounts for the changes over time of the phase values of each scatterer. Phase history data are focused into the azimuth and range components of each resolution cell to produce an image product called a \u201ccomplex image\u201d (Figure 15). Figure 15: The SAR Processing Flow and Its Products","title":"The SAR Processing Flow and Its Products"},{"location":"OverviewOfSAR/sarProcessing/#the-complex-image","text":"Info By the way, you will hear SAR engineers refer to the two parameters of a complex image as \u201cIn-Phase\u201d and \u201cQuadrature\u201d. These are just another way to describe the complex values. The left image in Figure 16 is a ICEYE amplitude image of agricultural fields. In this image each pixel has a brightness value assigned to it. This is what many people consider to be the base SAR product, but this is really only half of the full image. The SAR processor calculates the average phase value for each pixel as well. The matching \u201cphase image\u201d of that same scene is on the right in the figure. The combination of these two images is called a complex image, in which every pixel has amplitude and phase values. We use the term \u201ccomplex\u201d because the pixels are described by a mathematical construct called a complex number, where every number has two components. Figure 16: Amplitude and Phase Structure of a Complex Image Of course, phase data are not useful for direct human interpretation. And while they may look like random noise, phase pixels are a unique and valuable aspect of SAR imaging. Phase data can be used to manipulate the synthetic aperture in different ways to extract useful information that is not available from amplitude images. Moreover, changes in the phase measurements of the same object on different images can be used to detect small surface structure characteristics. In the next section we\u2019ll discuss how we can use phase data to refine images and create other products.","title":"The Complex Image"},{"location":"OverviewOfSAR/sarProcessing/#sar-products-derived-from-complex-data","text":"","title":"SAR Products Derived from Complex Data"},{"location":"OverviewOfSAR/sarProcessing/#amplitude-images","text":"Info You should also be aware that an engineering calculation called \u201cdetection\u201d converts in-phase and quadrature values to amplitude values. Engineers often refer to SAR amplitude images as \u201cdetected\u201d images. An amplitude image is certainly the most common SAR product, but you need to appreciate that this image is produced for human viewing and analysis. It is not the core image product. Amplitude images do not contain any phase information. Furthermore, the version of the amplitude image used for human viewing is not a direct copy of the amplitude values in a complex image. This is because radar sensors record an enormous span of brightness levels for each complex pixel. The maximum intensity of amplitude in a complex image is usually more than 100,000 times (50 dB) the minimum intensity, and for the best-quality images with bright targets, it is much greater. ICEYE images are produced with 16 bits of dynamic range per pixel (65536 gray levels) but even this is not sufficient to record the full dynamic range of SAR. As valuable as they are, amplitude images have no phase data and they lose much of the dynamic range of complex pixels. You can imagine the growing potential for computers and algorithms to process those complex pixels in ways the human visual system cannot.","title":"Amplitude Images"},{"location":"OverviewOfSAR/sarProcessing/#multi-look-amplitude-images","text":"One way in which we can use complex data is to produce different versions of the seemingly simple amplitude image. One common form of an amplitude image, for example, is called a multi-look image. Consider that azimuth and range resolution are handled independently. One is based on the length of the synthetic aperture and the other is based on the signal bandwidth, and sometimes these are quite different in magnitude. It is common for azimuth resolution to be collected at a higher fidelity than range resolution. If a full-resolution image were produced from such data it would look compressed in range. To view the image in a more natural aspect we need to \u201csquare the pixels\u201d so that the range and azimuth scales are the same. Info Speckle is a grainy, noise-like feature of SAR images. It is caused by the coherent nature of SAR illumination. The reflections from small scatterers within a resolution cell combine constructively and destructively to brighten or darken the returns. This is done by manipulating the synthetic aperture into smaller sub-apertures and then combining them. The sub-apertures are called \u201clooks\u201d and they each produce an image with lower azimuth resolution. This may sound disappointing, but when these individual sub-aperture images are combined, they form a multi-look image in which the noisy effect of speckle is reduced. Complex images are stored at full-resolution and are called single-look complex (SLC) images. Amplitude images are typically multi-looked in azimuth using two to 12 sub-apertures. If range resolution exceeds azimuth resolution a similar multi-look process can be applied in the range dimension.","title":"Multi-look Amplitude Images"},{"location":"OverviewOfSAR/sarProcessing/#sub-aperture-stack-or-video-image","text":"Suppose we take the aperture splitting further and create six or seven segments to produce multiple sub-aperture images. One advantage of this sub-aperture stack is that it can indicate glints that are bright in only a portion of the full aperture. This signature might be washed out on the full-resolution image by the bulk of the aperture in which there was no glinting, but it can be very noticeable in one of the low-resolution sub-apertures. Glints tend to be important signatures because they are usually caused by human-made features. We could even loop the stack like a short movie, or SAR video image, to look for such glints and moving objects. This product works best for long spotlight exposures of ten seconds or more.","title":"Sub-aperture Stack or Video Image"},{"location":"OverviewOfSAR/sarProcessing/#amplitude-and-coherent-change-images","text":"Perhaps the most useful SAR products are the amplitude and coherent change images (ACI, CCI). Two or more images of the same site are collected at different times to detect scene changes. For ACD only the brightness values are compared, while CCD uses phase data. In order for change detection to work, the images have to be collected from nearly the same location in space with similar illumination geometries. For ACD the two images can be overlaid in the complementary colors (eg red and cyan). In this way, features with similar backscatters will be gray, but features with backscatters that changed during the imaging period will appear in one of the two colors. It is conventional for the first image to be displayed in red and the second in cyan. If something on the ground changes between the two collections you will see whichever color signature is dominant. A mnemonic is used to help interpret ACD products: \u201cRed is fled. Blue is new\u201d. That is, a red signature indicates a feature that was present on the first image but left the scene prior to the second image, and a blue signature indicates a feature that appears only on the second image. This mnemonic is an easy way to help remember the order of the images, but appreciate that the second image is actually cyan, not blue. The intentional sloppiness of the mnemonic is acceptable here because verbal precision would ruin the rhyme. In contrast to amplitude change detection, CCD compares the phase values of two nearly identical images taken at different times. CCD is far more sensitive to changes because it is based on phase differences rather than pixel brightness differences and, as we know, phase is measured to within a small fraction of a wavelength. The collection constraints to ensure image-to-image coherence are tighter for CCD than ACD. When the collection parameters are nearly identical, the phase values are also nearly identical, and any changes are due to backscatter differences at a scale of less than one wavelength. It is typical for CCD images to display pixels where phase is consistent in white and the pixels where the phase has changed are dark. These are areas where the two images have \u201cdecorrelated\u201d, or lost phase consistency, due to some subtle change in the scene.","title":"Amplitude and Coherent Change Images"},{"location":"OverviewOfSAR/sarProcessing/#other-multi-image-sar-products","text":"The amplitude and phase data of SAR images can be combined to produce other useful products that are too numerous to describe in detail in this overview. These include digital elevation models derived from pixel brightness values or phase data, millimeter-level surface motion measurements derived phase comparisons of sets of matching images, and automated detections of ships, oil spills and other features. Once constellations of small SARs are established it will be possible to monitor any site in the world with large stacks of exactly matching images whose consistent signatures are linked to known ground features. These images could be collected within hours of each other and they will be the basis of intelligent site monitoring services that will not only detect changes, but which will also say what has changed and how it has changed.","title":"Other Multi-image SAR Products"},{"location":"OverviewOfSAR/simpleFormOfImaging/","text":"A Simple Form of Radar Imaging As seen in Figure 1 the radar antenna emits a series of pulses toward the ground where they are scattered in many directions. The sensor records the \u201cbackscatter\u201d, which is the portion reflected toward the antenna. It measures the strength of the echo and the time it took for the pulse to travel to the ground and back. Figure 1: Pulse Transmission and Backscatter Signal strength corresponds to pixel brightness and the timing provides range information. The range is one-half the total travel time. In the equation below, \\(\\Delta T\\) is the travel time and \\(c\\) is the speed of light: \\[Range = \\frac{\\Delta T\\ c}{2}\\] Side-Looking Illumination Since the pixels of a radar imaging system are placed on the image based partly on their range, the antenna cannot illuminate the ground in a vertical orientation. If it did, features on the same imaging line at equivalent angles off nadir would have identical ranges, like the two purple diamonds in Figure 2, and they would occupy the same pixel location. Figure 2: Vertical Illumination Radar imaging must be side-looking so that ground points from the near to far range have different range values (Figure 3). The illumination is typically broadside, or perpendicular, to the flight direction. Figure 3: Side-Looking Illumination Radar Angles The angles associated with radar illumination are shown in Figure 4, which is based on a spherical earth surface. Most radar imaging is broadside to the flight direction, but some systems can collect off-broadside in a squinted orientation. The angle down from the local level at the sensor is called the depression angle. The angle between the line-of-sight ray and the local vertical is the incidence angle. The angle between the tangent to the surface and the line of sight is the grazing angle. Note that the incidence and grazing angles are complements in that they form a right angle when combined. This means that a 60\u00b0 incidence angle is the same as a 30\u00b0 grazing angle. Figure 4: Radar Imaging Angles Side Looking Airborne Radar The first useful radar imaging technique was a form called Side-Looking Airborne Radar (SLAR) (Figure 5). The image is built up via the forward motion of the antenna, one line at a time. The pulses are emitted at a rate called the pulse repetition frequency (PRF), which can range from a few hundred pulses each second for airborne systems to thousands each second for spacecraft. In the SLAR technique, the individual pulses create each image line. The angular width of the pulse on the ground along the direction of flight, or azimuth direction, determines one component of resolution. The range measurements are collected in the \u201cslant range\u201d direction, and range variations to different objects form the second dimension of resolution. Figure 5: Side-Looking Airborne Radar SLAR was used the early days of radar imaging but it had serious limitations. Range resolution was one-half the length of the pulse in the range direction. Since the pulses are emitted at light speed, even a very brief pulse of one-millionth of a second would be 300 meters long and produce range resolution of 150 meters (Figure 6). Azimuth resolution was based on the angular width of the pulse in the azimuth direction ( \\(\\beta\\) ). Long antennas create narrow beams, but the beam spreads out from the antenna to the distant ground surface. Antennas cannot be made long enough to produce good azimuth resolution, and SLAR produced images with resolutions in the hundreds of meters, even from aircraft. This is why the brilliant concept of synthesizing a long antenna from the actions of a small one was developed. We call this Synthetic Aperture Radar. Figure 6: SLAR Pulse Dimensions","title":"A Simple Form Of RADAR Imaging"},{"location":"OverviewOfSAR/simpleFormOfImaging/#a-simple-form-of-radar-imaging","text":"As seen in Figure 1 the radar antenna emits a series of pulses toward the ground where they are scattered in many directions. The sensor records the \u201cbackscatter\u201d, which is the portion reflected toward the antenna. It measures the strength of the echo and the time it took for the pulse to travel to the ground and back. Figure 1: Pulse Transmission and Backscatter Signal strength corresponds to pixel brightness and the timing provides range information. The range is one-half the total travel time. In the equation below, \\(\\Delta T\\) is the travel time and \\(c\\) is the speed of light: \\[Range = \\frac{\\Delta T\\ c}{2}\\]","title":"A Simple Form of Radar Imaging"},{"location":"OverviewOfSAR/simpleFormOfImaging/#side-looking-illumination","text":"Since the pixels of a radar imaging system are placed on the image based partly on their range, the antenna cannot illuminate the ground in a vertical orientation. If it did, features on the same imaging line at equivalent angles off nadir would have identical ranges, like the two purple diamonds in Figure 2, and they would occupy the same pixel location. Figure 2: Vertical Illumination Radar imaging must be side-looking so that ground points from the near to far range have different range values (Figure 3). The illumination is typically broadside, or perpendicular, to the flight direction. Figure 3: Side-Looking Illumination","title":"Side-Looking Illumination"},{"location":"OverviewOfSAR/simpleFormOfImaging/#radar-angles","text":"The angles associated with radar illumination are shown in Figure 4, which is based on a spherical earth surface. Most radar imaging is broadside to the flight direction, but some systems can collect off-broadside in a squinted orientation. The angle down from the local level at the sensor is called the depression angle. The angle between the line-of-sight ray and the local vertical is the incidence angle. The angle between the tangent to the surface and the line of sight is the grazing angle. Note that the incidence and grazing angles are complements in that they form a right angle when combined. This means that a 60\u00b0 incidence angle is the same as a 30\u00b0 grazing angle. Figure 4: Radar Imaging Angles","title":"Radar Angles"},{"location":"OverviewOfSAR/simpleFormOfImaging/#side-looking-airborne-radar","text":"The first useful radar imaging technique was a form called Side-Looking Airborne Radar (SLAR) (Figure 5). The image is built up via the forward motion of the antenna, one line at a time. The pulses are emitted at a rate called the pulse repetition frequency (PRF), which can range from a few hundred pulses each second for airborne systems to thousands each second for spacecraft. In the SLAR technique, the individual pulses create each image line. The angular width of the pulse on the ground along the direction of flight, or azimuth direction, determines one component of resolution. The range measurements are collected in the \u201cslant range\u201d direction, and range variations to different objects form the second dimension of resolution. Figure 5: Side-Looking Airborne Radar SLAR was used the early days of radar imaging but it had serious limitations. Range resolution was one-half the length of the pulse in the range direction. Since the pulses are emitted at light speed, even a very brief pulse of one-millionth of a second would be 300 meters long and produce range resolution of 150 meters (Figure 6). Azimuth resolution was based on the angular width of the pulse in the azimuth direction ( \\(\\beta\\) ). Long antennas create narrow beams, but the beam spreads out from the antenna to the distant ground surface. Antennas cannot be made long enough to produce good azimuth resolution, and SLAR produced images with resolutions in the hundreds of meters, even from aircraft. This is why the brilliant concept of synthesizing a long antenna from the actions of a small one was developed. We call this Synthetic Aperture Radar. Figure 6: SLAR Pulse Dimensions","title":"Side Looking Airborne Radar"},{"location":"OverviewOfSAR/theInnovation/","text":"The ICEYE Innovation In this overview of SAR, we have discussed several remarkable capabilities beyond its famous ability to penetrate clouds. These include image resolution independent of distance, electronic beam control to vary resolution and coverage, pristine geolocation, and the natural ability to measure phase to within a small fraction of a wavelength. We\u2019ve seen that SAR pixels have both amplitude and phase, and from these we can produce many useful products. At ICEYE, we have developed an innovative way to incorporate all of these aspects of SAR in our small and adaptable systems. We are launching a full constellation of small SARs, and we\u2019ll upgrade them routinely to better image this ocean planet.","title":"The Innovation"},{"location":"OverviewOfSAR/theInnovation/#the-iceye-innovation","text":"In this overview of SAR, we have discussed several remarkable capabilities beyond its famous ability to penetrate clouds. These include image resolution independent of distance, electronic beam control to vary resolution and coverage, pristine geolocation, and the natural ability to measure phase to within a small fraction of a wavelength. We\u2019ve seen that SAR pixels have both amplitude and phase, and from these we can produce many useful products. At ICEYE, we have developed an innovative way to incorporate all of these aspects of SAR in our small and adaptable systems. We are launching a full constellation of small SARs, and we\u2019ll upgrade them routinely to better image this ocean planet.","title":"The ICEYE Innovation"},{"location":"archive/archive/","text":"ICEYE ARCHIVES Things change fast at ICEYE and we are constantly updating our skills and capabilities as well as our satellites. On this page you will find a collection of our external documents and some links to places that we have found useful when learning about SAR. Previous Product Documentation As we evolve our products, we also have to evolve our metadata and documentation. To allow users to search through previous ICEYE documents we provide them as links in the following table. DOCUMENT VERSION DATE SAR Product Guide 4.2 3 December 2021 Level 1 Product Format Specification 2.1 11 June 2020 Data Calibration and Validation 1.0 22 June 2020 Table 1: ICEYE Archive Documents ICEYE Publications Having such a large SAR constellation provides unique opportunities for scientific reasearch and experimentation. ICEYE encourages its staff to participate in reaseach activities and innovation is a core principal for the company. In the following table are some recent scientific publications that the team has been working on. REFERENCE CITE Radius A., Leprovost P., Ignatenko V., Muff D., Lamentowski L., Nottingham M., Dogan O., Seilonen T., March 2022, Phase Variant Analysis Algorithm for Azimuth Ambiguity Detection. In 2022 IEEE RADAR Conference Dogan O., Ignatenko V., Muff D., Lamentowski L., Nottingham M., Radius A., Leprovost P., Seilonen T., March 2022, Experimental Demonstration of a Novel End-to-End SAR Range Ambiguity Suppression Method.In 2022 IEEE RADAR Conference Muff, D., Ignatenko V., Dogan O., Lamentowski L., Leprovost P., Nottingham M., Radius A., Seilonen T., Tolpekin, V., The ICEYE Constellation - Some New Achievements. In 2022 IEEE RADAR Conference Ignatenko, V., Nottingham, M., Radius, A., Lamentowski, L. and Muff, D., 2021, July. ICEYE Microsatellite SAR Constellation Status Update: Long Dwell Spotlight and Wide Swath Imaging Modes. In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS (pp. 1493-1496). IEEE. Ignatenko, V., Laurila, P., Radius, A., Lamentowski, L., Antropov, O. and Muff, D., 2020, September. ICEYE Microsatellite SAR Constellation Status Update: Evaluation of first commercial imaging modes. In IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium (pp. 3581-3584). IEEE. Table 2: ICEYE Publications Useful Links and References REFERENCE Comment Thomas P. Ager. The Essentials of SAR: Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities. : 2021. ISBN-13 \u200f : \u200e 979-8512864487 Easy to read introduction to SAR for everyone Astri Polska, ESA SNAP workbook PDF with Radar data processing tools described Thuy Le Toan, Introduction to SAR Remote Sensing , lecture D1La1 of ESA Advanced Training Course on Land Remote Sensing Useful PDF for understanding of geometric properties and artifacts of SAR \" Step by Step: Recommended Practice Flood Mapping \", Office for Outer Space Affairs. UN-SPIDER Knowledge Portal Useful step-by-step instructions from the United Nations Echoes in space . EO College. A useful short course on SAR that we recommend to all our new customers. Table 3: Other useful links","title":"ICEYE Archives"},{"location":"archive/archive/#iceye-archives","text":"Things change fast at ICEYE and we are constantly updating our skills and capabilities as well as our satellites. On this page you will find a collection of our external documents and some links to places that we have found useful when learning about SAR.","title":"ICEYE ARCHIVES"},{"location":"archive/archive/#previous-product-documentation","text":"As we evolve our products, we also have to evolve our metadata and documentation. To allow users to search through previous ICEYE documents we provide them as links in the following table. DOCUMENT VERSION DATE SAR Product Guide 4.2 3 December 2021 Level 1 Product Format Specification 2.1 11 June 2020 Data Calibration and Validation 1.0 22 June 2020 Table 1: ICEYE Archive Documents","title":"Previous Product Documentation"},{"location":"archive/archive/#iceye-publications","text":"Having such a large SAR constellation provides unique opportunities for scientific reasearch and experimentation. ICEYE encourages its staff to participate in reaseach activities and innovation is a core principal for the company. In the following table are some recent scientific publications that the team has been working on. REFERENCE CITE Radius A., Leprovost P., Ignatenko V., Muff D., Lamentowski L., Nottingham M., Dogan O., Seilonen T., March 2022, Phase Variant Analysis Algorithm for Azimuth Ambiguity Detection. In 2022 IEEE RADAR Conference Dogan O., Ignatenko V., Muff D., Lamentowski L., Nottingham M., Radius A., Leprovost P., Seilonen T., March 2022, Experimental Demonstration of a Novel End-to-End SAR Range Ambiguity Suppression Method.In 2022 IEEE RADAR Conference Muff, D., Ignatenko V., Dogan O., Lamentowski L., Leprovost P., Nottingham M., Radius A., Seilonen T., Tolpekin, V., The ICEYE Constellation - Some New Achievements. In 2022 IEEE RADAR Conference Ignatenko, V., Nottingham, M., Radius, A., Lamentowski, L. and Muff, D., 2021, July. ICEYE Microsatellite SAR Constellation Status Update: Long Dwell Spotlight and Wide Swath Imaging Modes. In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS (pp. 1493-1496). IEEE. Ignatenko, V., Laurila, P., Radius, A., Lamentowski, L., Antropov, O. and Muff, D., 2020, September. ICEYE Microsatellite SAR Constellation Status Update: Evaluation of first commercial imaging modes. In IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium (pp. 3581-3584). IEEE. Table 2: ICEYE Publications","title":"ICEYE Publications"},{"location":"archive/archive/#useful-links-and-references","text":"REFERENCE Comment Thomas P. Ager. The Essentials of SAR: Conceptual View of Synthetic Aperture Radar and Its Remarkable Capabilities. : 2021. ISBN-13 \u200f : \u200e 979-8512864487 Easy to read introduction to SAR for everyone Astri Polska, ESA SNAP workbook PDF with Radar data processing tools described Thuy Le Toan, Introduction to SAR Remote Sensing , lecture D1La1 of ESA Advanced Training Course on Land Remote Sensing Useful PDF for understanding of geometric properties and artifacts of SAR \" Step by Step: Recommended Practice Flood Mapping \", Office for Outer Space Affairs. UN-SPIDER Knowledge Portal Useful step-by-step instructions from the United Nations Echoes in space . EO College. A useful short course on SAR that we recommend to all our new customers. Table 3: Other useful links","title":"Useful Links and References"},{"location":"productFormats/geospatialAccuracy/","text":"Geospatial Accuracy Background The complex image output of the SAR image-formation process is a set of focused pixels with phase and amplitude values. Each pixel pair of the image is referenced to the sensor by its range and azimuth coordinates. That is, each pair has a specific range to a sensor reference location and an azimuth location in the along-track direction. This range-azimuth geometry establishes an arc in space, which is the basis of the geolocation modeling of SAR images. The arc for each pixel is initially fit to the slant plant surface, and for amplitude images it is subsequently projected to a ground surface, such as the ground plane or ellipsoid or topographic surface. The geolocation accuracy of an image depends on how well that range-azimuth arc is measured. The relevant parameters for the arc are: the range and azimuth values, the sensor reference location, and the sensor velocity vector. We will consider each of them in turn. Range A SAR system is able to measure the range to a point on the ground very precisely. The theoretical precision of range is a fraction of a wavelength. However, as the RADAR pulse propagates through the atmosphere, it undergoes diffraction which curves the path of the pulse. This adds an unintended increase to the range of an object. The amount of increase depends on the look angle, the location of the satellite and scene, and even the time of day. The ICEYE SAR processor applies path length corrections (typically on the order of a couple of metres) using well established models. Azimuth The sensor also compares pulses to measure how the range to a point changes as the satellite moves along its trajectory. This provides precise information of the azimuth, or along-track, location of a pixel. Since this record is derived from precise pulse-to-pulse phase changes, it is the most accurate aspect of SAR data. On-Board Timing Errors A fundamental source of error for all RADAR systems relates to timing. In radar systems, precise electronic clocks are used to record the passage of time. All clocks have some sort of drift in their accuracy which, if not corrected, affects the measured range and focussing of the imagery. ICEYE satellites apply timing corrections to their internal clocks by periodically synchronising with GNSS (Global Navigation Satellite System) satellites. Orbit Knowledge A potentially large source of errors comes from not knowing precisely where the sensor is when each pulse is transmitted and received. This is determined by the satellite's orbit knowledge. ICEYE satellites constantly record their GNSS location. This information is transmitted to the ground during ground station telemetry downloads that occur usually once per orbit (sometimes more frequently). Additionally, the GNSS data is stored with the wideband radar data for rapid downlink and processing. Once on the ground, the orbit information is passed to ICEYE's orbit determination servers. These refine the orbit by taking into account the satellite's attitude and motion, the solar radiation pressure and the local gravitational field strength. The refinements are then used to improve the image geospatial accuracy and to provide accurate time/position/velocity estimates for future collections. In the future we plan on further refining the orbit fidelity using post-collected GNSS corrections combined with retroreflectors attached to the satellite. The Following table summarises the different levels of orbit fidelity. This information is stored in each image's metadata. ORBIT FIDELITY DESCRIPTION LATENCY Predicted Uses the latest orbit solution to predict where the satellite will be at some point in the future. It is used for collection planning and feasibility studies. It is not typically used for image formation processing because it has the largest errors. updated 6 hours before collection Rapid Uses GNSS stored samples collected during or near to the imaging operation. The spherical error (SE90) of the samples is 3 m. This allows imagery to be downlinked during or soon after collection to provide tactical SAR imagery to users with a modest geospatial error. This level is not yet available on all satellites. Immediate Precise This is the default orbit fidelity used for ICEYE satellites. The satellite position and velocity state vectors are refined after the imaging operation using downlinked telemetry and attitude data. The spherical error of the refined data is 1.5 m 10-45 minutes after imaging operation Scientific This uses GNSS corrections applied to the samples taken during imaging to significantly reduce the position velocity error. This is not yet available across the ICEYE Fleet. 2 to 4 days after collection Table 1 : Different Levels of Orbit Fidelity in ICEYE SAR Images Orbit Knowledge Metadata The location of the satellite during any imaging operation is made available by including the satellite and velocity information in the metadata for each image product. The data can be found under the orbit_state_vector metadata element. The accuracy of each element is determined by the orbit fidelity used to create the product which can be found in the orbit_processing_level metadata element which corresponds so one of the levels in table 1. Determining Ground Locations A sensor-orientation SAR amplitude image is a distillation of its richer complex image parent. It is the viewable version of SAR pixels and thus contains only microwave brightness values and no phase data. As with the complex image, its pixels have a range-azimuth structure. The difference is that it is usually projected to a ground surface, not the slant plane. It must be emphasized that the SAR image on its own cannot provide accurate ground locations. The chosen ground projection surface is typically an ellipsoid with a height set to the average height of the imaged area. This means that latitude and longitude image corner coordinates are for reference only. They are intended to layout the image footprint, and since they were projected to a single-elevation surface they cannot be used for accurate geolocation. SAR geolocation requires the projection of the natural range-azimuth arc of each pixel to an actual terrain height. This means that the image exploitation system must have a ground terrain height model on hand and it must use the coded SAR geometry model equations. This situation is exactly the same for optical images. The imaging conversion of 3D space to any 2D image, optical or SAR, means that proper geolocation requires pixel projections to elevation models on exploitation workstations. Elevation Models In the case of a calibrated SAR with accurate range-azimuth coordinates and precise orbit data, the most significant source of geospatial error comes from the way the data is measured and exploited on a workstation. The following animation explains why the measured location of a point on an accurate SAR image is dominated by errors in external terrain height information. Figure 2: The geospatial accuracy of a SAR image is a function of the accuracy of the terrain model used. The Geolocation Potential of SAR It is interesting to consider the pristine potential of SAR geolocation. Both SAR and optical satellite sensors can provide accurate orbit information, but optical sensors also need to physically measure the pointing orientation of the sensor to the ground. These data are derived from on-board gyroscopes and star sensors, and errors in the estimates of the sensor pointing direction project along the huge distance to the ground surface. A SAR satellite must also estimate pointing direction in order to illuminate the proper location on the ground. But once the image is formed, the angle to the ground location is determined by the azimuth coordinate, which is itself derived from ultra-precise pulse-to-pulse phase changes. The aspect of optical geolocation which contributes the most uncertainty, pointing direction, is not a significant factor for SAR geolocation. A well-calibrated SAR with accurate orbits, in conjunction with precise elevation data, can provide a geolocation accuracy of less than one meter for well-defined points. This is the precision to which ICEYE aspires. Geospatial Metadata It is interesting to note that the ground projection issue relates to any oblique looking imaging system (such as optical sensors) that are able to take images off-nadir . Fortunately a lot of geospatial viewers and exploitation tools have evolved to help the user deal with such issues. Some viewers have terrain models built in and can provide precise location information using parameters embedded in the metadata of each image. Two common approaches are Doppler Centroid Polynomials and Rapid Polynomial Coefficients . Fast and Simple Geolocation: Rapid Positioning Capability The range-azimuth arc and its associated geometry model equations form the rigorous, physics-based foundation of SAR geolocation. However, the actual implementation of this model is quite detailed and can include ponderous and slow iterative solutions. An engineering replacement to optical and SAR physics-based geometry models is commonly used to speed and simplify the calculation of ground locations. This replacement model takes the form of a ratio of polynomials that link a ground location (in latitude, longitude and height) to its associated image location. The replacement engineering model has been called Rational Polynomial Coefficients (RPC), but at ICEYE we prefer to call it Rapid Positioning Capability. The latter term instantly indicates its purpose and value, rather than referencing its mathematical structure. Because it is merely a polynomial replacement, the RPC data structure provided for ICEYE SAR images is exactly the same as the RPC model for all optical images. RPC is not only fast and simple; it is also sensor- and phenomenology-independent. It should be noted that RPC data are derived from an image\u2019s geometric metadata and the physics-based geometry model for that sensor. They are usually calculated during image formation and included in the output image file. RPC coefficients are provided for ICEYE\u2019s amplitude images in the GRD format. The model is described in [ 1 ] which extends the work for the National Imagery Transmission Format (NITF) 2 to GeoTIFFs. The translation of latitude, longitude and height to image pixel coordinates is described below. The approximation used in ICEYE products is a set of rational polynomials that describe the normalized row and column values ( \\(rn\\) , \\(cn\\) ) as a function of normalized geodetic latitude, longitude, and height. The link between the two is the ( \\(P\\) , \\(L\\) , \\(H\\) ) set of normalized polynomial coefficients ( LINE_NUM_COEF_n , LINE_DEN_COEF_n , SAMP_NUM_COEF_n , SAMP_DEN_COEF_n ) as applied in the RPC polynomial format. Normalized values, rather than actual values are used in order to minimize the introduction of errors during the calculations. The transformation between row and column values ( \\(r\\) , \\(c\\) ) and normalized row and column values ( \\(r_n\\) , \\(c_n\\) ), and between the geodetic latitude, longitude, and height ( \u03c6, \u03bb, h ), and normalized geodetic latitude, longitude, and height (P, L, H) is defined by a set of normalizing translations (offsets) and scales that ensure all values are contained within the range -1 to +1. The normalization of these parameters is given in Table 2. If you load ICEYE's images into RPC-compliant GIS Viewers (eg QGIS 3 ), with access to a ground elevation model, the Viewer will automatically perform conversion from image row, column to lat, long, height (WGS84 geoid). NORMALISED DEFINITION \\(P\\) (Latitude - LAT_OFF ) / LAT_SCALE \\(L\\) (Longitude - LONG_OFF ) / LONG_SCALE \\(H\\) (Height - HEIGHT_OFF ) / HEIGHT_SCALE \\(r_n\\) (Row - LINE_OFF ) / LINE_SCALE \\(c_n\\) (Column - SAMP_OFF ) / SAMP_SCALE Table 2 : Normalization of RPC parameters The GeoTIFF encoding of the RPC data in ICEYE data products is provided as a structure of 14 parameters described in Table 3. The equation to calculate the row and column number from the RPC values is given by: \\[ r_n= \\frac{ \\sum_{i=1}^{20} LINE\\_NUM\\_COEF_i \u22c5 \\rho_i(P,L,H) } { \\sum_{i=1}^{20} LINE\\_DEN\\_COEF_i \u22c5 \\rho_i(P,L,H) } \\] \\[ c_n = \\frac{\\sum_{i=1}^{20} SAMP\\_NUM\\_COEF_i \u22c5 \\rho_i(P,L,H) } {\\sum_{i=1}^{20} LINE\\_DEN\\_COEF_i \u22c5 \\rho_i(P,L,H) } \\] Where the rational polynomial numerators and denominators are each a 20-point cubic polynomial function of the form: RPC CUBIC POLYNOMIAL \\(\\sum_{i=1}^{20} C_i \u22c5 \\rho_i(P,L,H) =\\) \\(C_1\\) \\(+C_6 LH\\) \\(+C_{11} PLH\\) \\(+C_{16} P^3\\) \\(+C_2L\\) \\(+C_7 PH\\) \\(+C_{12} L^3\\) \\(+C_{17} PH^2\\) \\(+C_3P\\) \\(+C_8 L^2\\) \\(+C_{13} LP^2\\) \\(+C_{18} L^2 H\\) \\(+C_4H\\) \\(+C_9 P^2\\) \\(+C_{14} LH^2\\) \\(+C_{19} P^2 H\\) \\(+C_5LP\\) \\(+C_{10} H^2\\) \\(+C_{15} L^2P\\) \\(+C_{20} H^3\\) Where coefficients \\(C_1\u2026C_{20}\\) represent the vector coefficients provided in the product metadata : LINE_NUM_COEF_n , LINE_DEN_COEF_n , SAMP_NUM_COEF_n , SAMP_DEN_COEF_n . The image coordinates are in units of pixels. The ground coordinates are latitude and longitude in units of decimal degrees and the height above ellipsoid is in units of meters. The ground coordinates are referenced to WGS84. NAME DESCRIPTION VALUE RANGE UNITS LINE_OFF Line Offset >= 0 pixels SAMP_OFF Sample Offset >= 0 pixels LAT_OFF Geodetic Latitude Offset -90 to +90 degrees LONG_OFF Geodetic Longitude Offset -180 to +180 degrees HEIGHT_OFF Geodetic Height Offset unlimited meters LINE_SCALE Line Scale > 0 pixels SAMP_SCALE Sample Scale > 0 pixels LAT_SCALE Geodetic Latitude Scale 0 < LAT_SCALE <= 90 degrees LONG_SCALE Geodetic Longitude Scale 0 < LONG_SCALE <= 180 degrees HEIGHT_SCALE Geodetic Height Scale HEIGHT_SCALE > 0 meters LINE_NUM_COEFF (1-20) Line Numerator Coefficients. Twenty coefficients for the polynomial in the Numerator of the \\(r_n\\) equation. unlimited LINE_DEN_COEFF (1-20) Line Denominator Coefficients. Twenty coefficients for the polynomial in the Denominator of the \\(r_n\\) equation. unlimited SAMP_NUM_COEFF (1-20) Sample Numerator Coefficients. Twenty coefficients for the polynomial in the Numerator of the \\(c_n\\) equation. unlimited SAMP_DEN_COEFF (1-20) Sample Denominator Coefficients. Twenty coefficients for the polynomial in the Denominator of the \\(c_n\\) equation. unlimited Table 3 : RPC metadata parameters in ICEYE Products Geometric Calibration Process In order to monitor the geometric integrity of ICEYE images, the satellites routinely collect images over ground-surveyed calibration sites around the world. Each site consists of a set of calibration point targets such as trihedral corner reflectors . The position, orientation and size of these features are carefully measured and maintained, and they are often provided by organizations such as NASA JPL as a free service to the geospatial community. ICEYE engineers compare the target ground coordinates derived from the image coordinates and known elevation to the precisely surveyed ground-truth coordinates. These calibration comparisons provide a statistical measure of the horizontal accuracy of ICEYE images by comparing calibration point target locations in terrain corrected imagery to ground truth measurements of each calibration point target. The root, mean square error (RMSE) is then calculated from all the measured location errors. Currently the ICEYE fleet is achieving a worst-case RMSE of 6 m. In actual practice elevation models used during image exploitation have vertical uncertainties, and feature signatures are not as precise as those of corner reflectors. Together these increase the horizontal error of image-derived ground coordinates. Figure 3: a 2.4m trihedral at the NASA JPL Rosamond Calibration Array[^4]. References OSGeo. RPCs in GeoTIFF . URL: http://geotiff.maptools.org/rpc_prop.html . \u21a9 National Imagery and Mapping Agency. The Compendium of Controlled Extensions \\(CE\\) for the National Imagery Transmission Format \\(NITF\\) Version 2.1 . November 2000. URL: http://geotiff.maptools.org/STDI-0002_v2.1.pdf . \u21a9 QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/ . \u21a9 R.J. Muellerschoen. The rosamond corner reflector array for sar calibration; past, present, future. 7th Nov 2017. Accessed 30 December 2021. URL: https://trs.jpl.nasa.gov/handle/2014/48764 . \u21a9","title":"Geospatial Considerations"},{"location":"productFormats/geospatialAccuracy/#geospatial-accuracy","text":"","title":"Geospatial Accuracy"},{"location":"productFormats/geospatialAccuracy/#background","text":"The complex image output of the SAR image-formation process is a set of focused pixels with phase and amplitude values. Each pixel pair of the image is referenced to the sensor by its range and azimuth coordinates. That is, each pair has a specific range to a sensor reference location and an azimuth location in the along-track direction. This range-azimuth geometry establishes an arc in space, which is the basis of the geolocation modeling of SAR images. The arc for each pixel is initially fit to the slant plant surface, and for amplitude images it is subsequently projected to a ground surface, such as the ground plane or ellipsoid or topographic surface. The geolocation accuracy of an image depends on how well that range-azimuth arc is measured. The relevant parameters for the arc are: the range and azimuth values, the sensor reference location, and the sensor velocity vector. We will consider each of them in turn.","title":"Background"},{"location":"productFormats/geospatialAccuracy/#range","text":"A SAR system is able to measure the range to a point on the ground very precisely. The theoretical precision of range is a fraction of a wavelength. However, as the RADAR pulse propagates through the atmosphere, it undergoes diffraction which curves the path of the pulse. This adds an unintended increase to the range of an object. The amount of increase depends on the look angle, the location of the satellite and scene, and even the time of day. The ICEYE SAR processor applies path length corrections (typically on the order of a couple of metres) using well established models.","title":"Range"},{"location":"productFormats/geospatialAccuracy/#azimuth","text":"The sensor also compares pulses to measure how the range to a point changes as the satellite moves along its trajectory. This provides precise information of the azimuth, or along-track, location of a pixel. Since this record is derived from precise pulse-to-pulse phase changes, it is the most accurate aspect of SAR data.","title":"Azimuth"},{"location":"productFormats/geospatialAccuracy/#on-board-timing-errors","text":"A fundamental source of error for all RADAR systems relates to timing. In radar systems, precise electronic clocks are used to record the passage of time. All clocks have some sort of drift in their accuracy which, if not corrected, affects the measured range and focussing of the imagery. ICEYE satellites apply timing corrections to their internal clocks by periodically synchronising with GNSS (Global Navigation Satellite System) satellites.","title":"On-Board Timing Errors"},{"location":"productFormats/geospatialAccuracy/#orbit-knowledge","text":"A potentially large source of errors comes from not knowing precisely where the sensor is when each pulse is transmitted and received. This is determined by the satellite's orbit knowledge. ICEYE satellites constantly record their GNSS location. This information is transmitted to the ground during ground station telemetry downloads that occur usually once per orbit (sometimes more frequently). Additionally, the GNSS data is stored with the wideband radar data for rapid downlink and processing. Once on the ground, the orbit information is passed to ICEYE's orbit determination servers. These refine the orbit by taking into account the satellite's attitude and motion, the solar radiation pressure and the local gravitational field strength. The refinements are then used to improve the image geospatial accuracy and to provide accurate time/position/velocity estimates for future collections. In the future we plan on further refining the orbit fidelity using post-collected GNSS corrections combined with retroreflectors attached to the satellite. The Following table summarises the different levels of orbit fidelity. This information is stored in each image's metadata. ORBIT FIDELITY DESCRIPTION LATENCY Predicted Uses the latest orbit solution to predict where the satellite will be at some point in the future. It is used for collection planning and feasibility studies. It is not typically used for image formation processing because it has the largest errors. updated 6 hours before collection Rapid Uses GNSS stored samples collected during or near to the imaging operation. The spherical error (SE90) of the samples is 3 m. This allows imagery to be downlinked during or soon after collection to provide tactical SAR imagery to users with a modest geospatial error. This level is not yet available on all satellites. Immediate Precise This is the default orbit fidelity used for ICEYE satellites. The satellite position and velocity state vectors are refined after the imaging operation using downlinked telemetry and attitude data. The spherical error of the refined data is 1.5 m 10-45 minutes after imaging operation Scientific This uses GNSS corrections applied to the samples taken during imaging to significantly reduce the position velocity error. This is not yet available across the ICEYE Fleet. 2 to 4 days after collection Table 1 : Different Levels of Orbit Fidelity in ICEYE SAR Images","title":"Orbit Knowledge"},{"location":"productFormats/geospatialAccuracy/#orbit-knowledge-metadata","text":"The location of the satellite during any imaging operation is made available by including the satellite and velocity information in the metadata for each image product. The data can be found under the orbit_state_vector metadata element. The accuracy of each element is determined by the orbit fidelity used to create the product which can be found in the orbit_processing_level metadata element which corresponds so one of the levels in table 1.","title":"Orbit Knowledge Metadata"},{"location":"productFormats/geospatialAccuracy/#determining-ground-locations","text":"A sensor-orientation SAR amplitude image is a distillation of its richer complex image parent. It is the viewable version of SAR pixels and thus contains only microwave brightness values and no phase data. As with the complex image, its pixels have a range-azimuth structure. The difference is that it is usually projected to a ground surface, not the slant plane. It must be emphasized that the SAR image on its own cannot provide accurate ground locations. The chosen ground projection surface is typically an ellipsoid with a height set to the average height of the imaged area. This means that latitude and longitude image corner coordinates are for reference only. They are intended to layout the image footprint, and since they were projected to a single-elevation surface they cannot be used for accurate geolocation. SAR geolocation requires the projection of the natural range-azimuth arc of each pixel to an actual terrain height. This means that the image exploitation system must have a ground terrain height model on hand and it must use the coded SAR geometry model equations. This situation is exactly the same for optical images. The imaging conversion of 3D space to any 2D image, optical or SAR, means that proper geolocation requires pixel projections to elevation models on exploitation workstations.","title":"Determining Ground Locations"},{"location":"productFormats/geospatialAccuracy/#elevation-models","text":"In the case of a calibrated SAR with accurate range-azimuth coordinates and precise orbit data, the most significant source of geospatial error comes from the way the data is measured and exploited on a workstation. The following animation explains why the measured location of a point on an accurate SAR image is dominated by errors in external terrain height information. Figure 2: The geospatial accuracy of a SAR image is a function of the accuracy of the terrain model used.","title":"Elevation Models"},{"location":"productFormats/geospatialAccuracy/#the-geolocation-potential-of-sar","text":"It is interesting to consider the pristine potential of SAR geolocation. Both SAR and optical satellite sensors can provide accurate orbit information, but optical sensors also need to physically measure the pointing orientation of the sensor to the ground. These data are derived from on-board gyroscopes and star sensors, and errors in the estimates of the sensor pointing direction project along the huge distance to the ground surface. A SAR satellite must also estimate pointing direction in order to illuminate the proper location on the ground. But once the image is formed, the angle to the ground location is determined by the azimuth coordinate, which is itself derived from ultra-precise pulse-to-pulse phase changes. The aspect of optical geolocation which contributes the most uncertainty, pointing direction, is not a significant factor for SAR geolocation. A well-calibrated SAR with accurate orbits, in conjunction with precise elevation data, can provide a geolocation accuracy of less than one meter for well-defined points. This is the precision to which ICEYE aspires.","title":"The Geolocation Potential of SAR"},{"location":"productFormats/geospatialAccuracy/#geospatial-metadata","text":"It is interesting to note that the ground projection issue relates to any oblique looking imaging system (such as optical sensors) that are able to take images off-nadir . Fortunately a lot of geospatial viewers and exploitation tools have evolved to help the user deal with such issues. Some viewers have terrain models built in and can provide precise location information using parameters embedded in the metadata of each image. Two common approaches are Doppler Centroid Polynomials and Rapid Polynomial Coefficients .","title":"Geospatial Metadata"},{"location":"productFormats/geospatialAccuracy/#fast-and-simple-geolocation-rapid-positioning-capability","text":"The range-azimuth arc and its associated geometry model equations form the rigorous, physics-based foundation of SAR geolocation. However, the actual implementation of this model is quite detailed and can include ponderous and slow iterative solutions. An engineering replacement to optical and SAR physics-based geometry models is commonly used to speed and simplify the calculation of ground locations. This replacement model takes the form of a ratio of polynomials that link a ground location (in latitude, longitude and height) to its associated image location. The replacement engineering model has been called Rational Polynomial Coefficients (RPC), but at ICEYE we prefer to call it Rapid Positioning Capability. The latter term instantly indicates its purpose and value, rather than referencing its mathematical structure. Because it is merely a polynomial replacement, the RPC data structure provided for ICEYE SAR images is exactly the same as the RPC model for all optical images. RPC is not only fast and simple; it is also sensor- and phenomenology-independent. It should be noted that RPC data are derived from an image\u2019s geometric metadata and the physics-based geometry model for that sensor. They are usually calculated during image formation and included in the output image file. RPC coefficients are provided for ICEYE\u2019s amplitude images in the GRD format. The model is described in [ 1 ] which extends the work for the National Imagery Transmission Format (NITF) 2 to GeoTIFFs. The translation of latitude, longitude and height to image pixel coordinates is described below. The approximation used in ICEYE products is a set of rational polynomials that describe the normalized row and column values ( \\(rn\\) , \\(cn\\) ) as a function of normalized geodetic latitude, longitude, and height. The link between the two is the ( \\(P\\) , \\(L\\) , \\(H\\) ) set of normalized polynomial coefficients ( LINE_NUM_COEF_n , LINE_DEN_COEF_n , SAMP_NUM_COEF_n , SAMP_DEN_COEF_n ) as applied in the RPC polynomial format. Normalized values, rather than actual values are used in order to minimize the introduction of errors during the calculations. The transformation between row and column values ( \\(r\\) , \\(c\\) ) and normalized row and column values ( \\(r_n\\) , \\(c_n\\) ), and between the geodetic latitude, longitude, and height ( \u03c6, \u03bb, h ), and normalized geodetic latitude, longitude, and height (P, L, H) is defined by a set of normalizing translations (offsets) and scales that ensure all values are contained within the range -1 to +1. The normalization of these parameters is given in Table 2. If you load ICEYE's images into RPC-compliant GIS Viewers (eg QGIS 3 ), with access to a ground elevation model, the Viewer will automatically perform conversion from image row, column to lat, long, height (WGS84 geoid). NORMALISED DEFINITION \\(P\\) (Latitude - LAT_OFF ) / LAT_SCALE \\(L\\) (Longitude - LONG_OFF ) / LONG_SCALE \\(H\\) (Height - HEIGHT_OFF ) / HEIGHT_SCALE \\(r_n\\) (Row - LINE_OFF ) / LINE_SCALE \\(c_n\\) (Column - SAMP_OFF ) / SAMP_SCALE Table 2 : Normalization of RPC parameters The GeoTIFF encoding of the RPC data in ICEYE data products is provided as a structure of 14 parameters described in Table 3. The equation to calculate the row and column number from the RPC values is given by: \\[ r_n= \\frac{ \\sum_{i=1}^{20} LINE\\_NUM\\_COEF_i \u22c5 \\rho_i(P,L,H) } { \\sum_{i=1}^{20} LINE\\_DEN\\_COEF_i \u22c5 \\rho_i(P,L,H) } \\] \\[ c_n = \\frac{\\sum_{i=1}^{20} SAMP\\_NUM\\_COEF_i \u22c5 \\rho_i(P,L,H) } {\\sum_{i=1}^{20} LINE\\_DEN\\_COEF_i \u22c5 \\rho_i(P,L,H) } \\] Where the rational polynomial numerators and denominators are each a 20-point cubic polynomial function of the form: RPC CUBIC POLYNOMIAL \\(\\sum_{i=1}^{20} C_i \u22c5 \\rho_i(P,L,H) =\\) \\(C_1\\) \\(+C_6 LH\\) \\(+C_{11} PLH\\) \\(+C_{16} P^3\\) \\(+C_2L\\) \\(+C_7 PH\\) \\(+C_{12} L^3\\) \\(+C_{17} PH^2\\) \\(+C_3P\\) \\(+C_8 L^2\\) \\(+C_{13} LP^2\\) \\(+C_{18} L^2 H\\) \\(+C_4H\\) \\(+C_9 P^2\\) \\(+C_{14} LH^2\\) \\(+C_{19} P^2 H\\) \\(+C_5LP\\) \\(+C_{10} H^2\\) \\(+C_{15} L^2P\\) \\(+C_{20} H^3\\) Where coefficients \\(C_1\u2026C_{20}\\) represent the vector coefficients provided in the product metadata : LINE_NUM_COEF_n , LINE_DEN_COEF_n , SAMP_NUM_COEF_n , SAMP_DEN_COEF_n . The image coordinates are in units of pixels. The ground coordinates are latitude and longitude in units of decimal degrees and the height above ellipsoid is in units of meters. The ground coordinates are referenced to WGS84. NAME DESCRIPTION VALUE RANGE UNITS LINE_OFF Line Offset >= 0 pixels SAMP_OFF Sample Offset >= 0 pixels LAT_OFF Geodetic Latitude Offset -90 to +90 degrees LONG_OFF Geodetic Longitude Offset -180 to +180 degrees HEIGHT_OFF Geodetic Height Offset unlimited meters LINE_SCALE Line Scale > 0 pixels SAMP_SCALE Sample Scale > 0 pixels LAT_SCALE Geodetic Latitude Scale 0 < LAT_SCALE <= 90 degrees LONG_SCALE Geodetic Longitude Scale 0 < LONG_SCALE <= 180 degrees HEIGHT_SCALE Geodetic Height Scale HEIGHT_SCALE > 0 meters LINE_NUM_COEFF (1-20) Line Numerator Coefficients. Twenty coefficients for the polynomial in the Numerator of the \\(r_n\\) equation. unlimited LINE_DEN_COEFF (1-20) Line Denominator Coefficients. Twenty coefficients for the polynomial in the Denominator of the \\(r_n\\) equation. unlimited SAMP_NUM_COEFF (1-20) Sample Numerator Coefficients. Twenty coefficients for the polynomial in the Numerator of the \\(c_n\\) equation. unlimited SAMP_DEN_COEFF (1-20) Sample Denominator Coefficients. Twenty coefficients for the polynomial in the Denominator of the \\(c_n\\) equation. unlimited Table 3 : RPC metadata parameters in ICEYE Products","title":"Fast and Simple Geolocation: Rapid Positioning Capability"},{"location":"productFormats/geospatialAccuracy/#geometric-calibration-process","text":"In order to monitor the geometric integrity of ICEYE images, the satellites routinely collect images over ground-surveyed calibration sites around the world. Each site consists of a set of calibration point targets such as trihedral corner reflectors . The position, orientation and size of these features are carefully measured and maintained, and they are often provided by organizations such as NASA JPL as a free service to the geospatial community. ICEYE engineers compare the target ground coordinates derived from the image coordinates and known elevation to the precisely surveyed ground-truth coordinates. These calibration comparisons provide a statistical measure of the horizontal accuracy of ICEYE images by comparing calibration point target locations in terrain corrected imagery to ground truth measurements of each calibration point target. The root, mean square error (RMSE) is then calculated from all the measured location errors. Currently the ICEYE fleet is achieving a worst-case RMSE of 6 m. In actual practice elevation models used during image exploitation have vertical uncertainties, and feature signatures are not as precise as those of corner reflectors. Together these increase the horizontal error of image-derived ground coordinates. Figure 3: a 2.4m trihedral at the NASA JPL Rosamond Calibration Array[^4].","title":"Geometric Calibration Process"},{"location":"productFormats/geospatialAccuracy/#references","text":"OSGeo. RPCs in GeoTIFF . URL: http://geotiff.maptools.org/rpc_prop.html . \u21a9 National Imagery and Mapping Agency. The Compendium of Controlled Extensions \\(CE\\) for the National Imagery Transmission Format \\(NITF\\) Version 2.1 . November 2000. URL: http://geotiff.maptools.org/STDI-0002_v2.1.pdf . \u21a9 QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/ . \u21a9 R.J. Muellerschoen. The rosamond corner reflector array for sar calibration; past, present, future. 7th Nov 2017. Accessed 30 December 2021. URL: https://trs.jpl.nasa.gov/handle/2014/48764 . \u21a9","title":"References"},{"location":"productFormats/grd/","text":"'Ground Range Detected' - \ud83d\ude35\u200d\ud83d\udcab? After complex images are processed into amplitude images and projected to the ground plane they retain the native range-azimuth sensor orientation. The commonly used terms for these range-azimuth amplitude images include some combination of ' detected ', ' ground range ' and ' multi-look '. At ICEYE these have been called Ground Range Detected ( GRD ) images. While our term is consistent with industry practice, over time we have come to realise that ' GRD ' does not adequately describe the product. In fact, few users understand what ' detected ' really means. It is actually an old electronic engineering term from the days when signal processing was performed on oscilloscopes. When applied to SAR images, detection is the process of converting in-phase and quadrature complex pixels (equivalent to amplitude and phase) into amplitude-only values. Due to SAR\u2019s electrical engineering heritage, technical jargon like this has become infused into the language of SAR, and this confuses users. In this case, we form a simple amplitude image, and refer to it with an obscure engineering term. Another limitation is that ' ground range ' and ' detected ' do not describe the essential fact that the image is in the range-azimuth layout. In fact, an alternate form of amplitude images is to interpolate pixels to fit a map projection. While that format is completely different from the native range-azimuth structure, it is also detected and it is in the ground range. So, the SAR community\u2019s commonly used terms for range-azimuth amplitude images are based on dated jargon and they fail to state what the structure actually is. At ICEYE we like to use clear, descriptive English so we prefer to call a GRD image a range-azimuth amplitude image. It might also be called a sensor-orientation amplitude image. It is a struggle, though, to shake off the SAR community\u2019s legacy language. Many of our customers are used to the term GRD and we are keeping the acronym in some of our product filenames for compatibility reasons. This is likely to change in the future. Amplitude Image Description Amplitude images represent focused SAR data that has been detected and (usually) multi-look processed and projected to the ground plane using an Earth ellipsoid model. The image coordinates are oriented along the flight direction and ground range (figure 1). The pixel spacing is equidistant in azimuth and in ground range. Ground range coordinates are the slant range coordinates projected onto the ellipsoid of the Earth. For this projection the WGS84 reference ellipsoid (table 1) is used and an averaged fixed value of terrain height is used. This makes the ellipsoid surface closer to the true ground surface. The mean ellipsoid height used is annotated in the avg_scene_height metadata element. Tip For an explanation of why see Terrain Height in the 'Geospatial Accuracy' section under 'Foundations'. ELLIPSOID REFERENCE SEMI MAJOR AXIS SEMI MINOR AXIS INVERSE FLATTENING WGS84 6378137.0 m 6356752.314245 m 298.257 223 563 Table 1 : WGS84 Reference Ellipsoid used in ICEYE Amplitude images Pixel values represent a scaled amplitude. The resulting product has approximately circular spatial resolution and square pixel spacing. Additionally, an incidence angle dependence in range, calculated using the ellipsoidal Earth model has been applied to enable the conversion of radar brightness to backscatter intensity. This is explained in more detail in the section on Radiometric Considerations . The core advantages of range-azimuth amplitude (GRD) images is that they are laid out in the natural SAR orientation, which is required for rigorous geolocation, and their pixels are free of the interpolation artifacts of map projection images. This product is the form of a SAR amplitude image that retains its SAR heritage. It\u2019s pixels are presented in the natural range-azimuth form best suited for shadows-down interpretation, that is free of map-projection-induced artifacts, that supports manipulation into orthophotos and other forms, and which supports the SAR image geometry model used to calculate ground locations. To assist users that require geocoded imagery with minimal interpolation artefacts, ICEYE amplitude image products are tagged with ground control points (GCP) and rapid positioning capability polynomial coefficients (RPC\u2019s). These allow precise geospatial exploitation using freely available tools such as QGIS 1 or GDAL 2 . Figure 1: The Binary Representation of Amplitude Images Binary Representation The 'digital numbers' in the image data layer \\(DN_{GRD}\\) of amplitude SAR products are stored in a GeoTIFF file format using unsigned 16 bit integer representation along with a combination of commonly used and specifically defined GeoTIFF tags. GeoTiff files are readable with standard image processing and GIS software tools. It is common for different imaging modes and different incidence angles to have a native range-azimuth sample spacing in the slant plane that is not square. Square sample spacing and a circular impulse response function in the ground plane is achieved either by varying the transmitted bandwidth or by applying multi-looking during the slant to ground transformation and detection process. Typically, the conversion from complex samples to amplitude only samples is performed as \\[ |DN_{SLC}|^2 = (I^2 + Q^2) \\] with \\(I^2\\) and \\(Q^2\\) representing the real and imaginary amplitude of the complex backscatter. For amplitude image scenes, a conversion to \\(\\sigma_0\\) has been already applied using an incidence angle \\(\\theta\\) that is calculated from the ellipsoidal Earth model: \\[ |DN_{GRD}|^2 =|DN_{SLC}|^2\\sin(\\theta) \\] Ellipsoid parameters and metadata tags can easily be found using the command : gdalinfo < geotiff_filename . tif > The amplitude image metadata elements can be found in the metadata section . Amplitude Image in Context Figure 2 provides a useful summary of Amplitude images in the context of the processing options available with the red line highlighting the decisions made during product production. Figure 2: The Processing Steps and Implementation Considerations for ICEYE amplitude images References QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/ . \u21a9 OSGeo. GDAL: Geospatial Data Abstraction Layer. May 2020. Accessed June 2020. URL: https://gdal.org/ . \u21a9","title":"Amplitude Image"},{"location":"productFormats/grd/#ground-range-detected-","text":"After complex images are processed into amplitude images and projected to the ground plane they retain the native range-azimuth sensor orientation. The commonly used terms for these range-azimuth amplitude images include some combination of ' detected ', ' ground range ' and ' multi-look '. At ICEYE these have been called Ground Range Detected ( GRD ) images. While our term is consistent with industry practice, over time we have come to realise that ' GRD ' does not adequately describe the product. In fact, few users understand what ' detected ' really means. It is actually an old electronic engineering term from the days when signal processing was performed on oscilloscopes. When applied to SAR images, detection is the process of converting in-phase and quadrature complex pixels (equivalent to amplitude and phase) into amplitude-only values. Due to SAR\u2019s electrical engineering heritage, technical jargon like this has become infused into the language of SAR, and this confuses users. In this case, we form a simple amplitude image, and refer to it with an obscure engineering term. Another limitation is that ' ground range ' and ' detected ' do not describe the essential fact that the image is in the range-azimuth layout. In fact, an alternate form of amplitude images is to interpolate pixels to fit a map projection. While that format is completely different from the native range-azimuth structure, it is also detected and it is in the ground range. So, the SAR community\u2019s commonly used terms for range-azimuth amplitude images are based on dated jargon and they fail to state what the structure actually is. At ICEYE we like to use clear, descriptive English so we prefer to call a GRD image a range-azimuth amplitude image. It might also be called a sensor-orientation amplitude image. It is a struggle, though, to shake off the SAR community\u2019s legacy language. Many of our customers are used to the term GRD and we are keeping the acronym in some of our product filenames for compatibility reasons. This is likely to change in the future.","title":"'Ground Range Detected' - \ud83d\ude35\u200d\ud83d\udcab?"},{"location":"productFormats/grd/#amplitude-image-description","text":"Amplitude images represent focused SAR data that has been detected and (usually) multi-look processed and projected to the ground plane using an Earth ellipsoid model. The image coordinates are oriented along the flight direction and ground range (figure 1). The pixel spacing is equidistant in azimuth and in ground range. Ground range coordinates are the slant range coordinates projected onto the ellipsoid of the Earth. For this projection the WGS84 reference ellipsoid (table 1) is used and an averaged fixed value of terrain height is used. This makes the ellipsoid surface closer to the true ground surface. The mean ellipsoid height used is annotated in the avg_scene_height metadata element. Tip For an explanation of why see Terrain Height in the 'Geospatial Accuracy' section under 'Foundations'. ELLIPSOID REFERENCE SEMI MAJOR AXIS SEMI MINOR AXIS INVERSE FLATTENING WGS84 6378137.0 m 6356752.314245 m 298.257 223 563 Table 1 : WGS84 Reference Ellipsoid used in ICEYE Amplitude images Pixel values represent a scaled amplitude. The resulting product has approximately circular spatial resolution and square pixel spacing. Additionally, an incidence angle dependence in range, calculated using the ellipsoidal Earth model has been applied to enable the conversion of radar brightness to backscatter intensity. This is explained in more detail in the section on Radiometric Considerations . The core advantages of range-azimuth amplitude (GRD) images is that they are laid out in the natural SAR orientation, which is required for rigorous geolocation, and their pixels are free of the interpolation artifacts of map projection images. This product is the form of a SAR amplitude image that retains its SAR heritage. It\u2019s pixels are presented in the natural range-azimuth form best suited for shadows-down interpretation, that is free of map-projection-induced artifacts, that supports manipulation into orthophotos and other forms, and which supports the SAR image geometry model used to calculate ground locations. To assist users that require geocoded imagery with minimal interpolation artefacts, ICEYE amplitude image products are tagged with ground control points (GCP) and rapid positioning capability polynomial coefficients (RPC\u2019s). These allow precise geospatial exploitation using freely available tools such as QGIS 1 or GDAL 2 . Figure 1: The Binary Representation of Amplitude Images","title":"Amplitude Image Description"},{"location":"productFormats/grd/#binary-representation","text":"The 'digital numbers' in the image data layer \\(DN_{GRD}\\) of amplitude SAR products are stored in a GeoTIFF file format using unsigned 16 bit integer representation along with a combination of commonly used and specifically defined GeoTIFF tags. GeoTiff files are readable with standard image processing and GIS software tools. It is common for different imaging modes and different incidence angles to have a native range-azimuth sample spacing in the slant plane that is not square. Square sample spacing and a circular impulse response function in the ground plane is achieved either by varying the transmitted bandwidth or by applying multi-looking during the slant to ground transformation and detection process. Typically, the conversion from complex samples to amplitude only samples is performed as \\[ |DN_{SLC}|^2 = (I^2 + Q^2) \\] with \\(I^2\\) and \\(Q^2\\) representing the real and imaginary amplitude of the complex backscatter. For amplitude image scenes, a conversion to \\(\\sigma_0\\) has been already applied using an incidence angle \\(\\theta\\) that is calculated from the ellipsoidal Earth model: \\[ |DN_{GRD}|^2 =|DN_{SLC}|^2\\sin(\\theta) \\] Ellipsoid parameters and metadata tags can easily be found using the command : gdalinfo < geotiff_filename . tif > The amplitude image metadata elements can be found in the metadata section .","title":"Binary Representation"},{"location":"productFormats/grd/#amplitude-image-in-context","text":"Figure 2 provides a useful summary of Amplitude images in the context of the processing options available with the red line highlighting the decisions made during product production. Figure 2: The Processing Steps and Implementation Considerations for ICEYE amplitude images","title":"Amplitude Image in Context"},{"location":"productFormats/grd/#references","text":"QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/ . \u21a9 OSGeo. GDAL: Geospatial Data Abstraction Layer. May 2020. Accessed June 2020. URL: https://gdal.org/ . \u21a9","title":"References"},{"location":"productFormats/introduction/","text":"Introduction To SAR Data From Satellite to SAR After an imaging operation has taken place, the recorded radar echo data is downloaded to one of the terminals in the ICEYE ground station network where the images are formed. The focussing algorithm varies depending on the acquisition type. The data is then stored and represented as binary data in a container file format ready for exploitation. When producing different forms of exploitable products, several decisions have to be made about the data representation. At ICEYE we realise that not every format is suitable for every customer or use case, so starting in 2022 we will be increasing the range of processing options available. This section includes a discussion of format options so that later we can refer to our current formats in context of the larger landscape. Figure 1: The Port of Rotterdam on three consecutive days. The Tree of Processing Options There are many steps that have to be considered when converting RADAR pulse data into an exploitable image. Here we will talk about each in turn. Figure 2: The SAR Image Tree of Processing Options Sample Arrangement This is the way the image pixels are aligned as a raster in the container file. Most Geospatial Information System (GIS) viewers will convert the projection for you on your screen. Map-oriented images are larger than range-azimuth images as the rotation to make the image 'north-up' in the container file requires the addition of blank pixels to make the image rectangular. Map projection layouts are often projected to a single elevation surface; thus, they lack the geometric fidelity of range-azimuth images. They also can impart flipped terrain-perception effects in which mountains appear to be valleys and valleys appear elevated. Despite this, some users prefer the map-oriented product because its map representation with north up can be directly used with paper-based maps without any rotations. Axis Alignment Another file representation option is the alignment of axes in the binary data. Range-azimuth data can be aligned shadows down or azimuth down . Modern GIS viewers can display the data in either representation and easily convert between the two. Scientists using algorithms to exploit the data need to understand the data representation thought. Historically, imagery intelligence analysts require fine resolution imagery to observe subtle features on small objects of interest. In these situations it is more important to have a consistent alignment of shadows, multipath and layover of an object than to have North \u2018up\u2019. For large-scale mapping, azimuth down easily allows a collection to be extended by concatenating more data to the end of a file. Projection Suface The focussed SAR resolution cells are fit to a projection surface. Most commonly this is the slant plane, the ground plane or an ellipsoid surface, but the projection surface can have any orientation and even be an inclined plane, a curve or the topographic surface. There are many reasons for a user preferring one projection surface over another. This is usually related to how the imagery will be exploited, but it should be recognised that the slant plane is the most efficient and artefact-free focus projection surface. Number of Looks The multi-look process reduces resolution in order to reduce the speckle in the image. A single look has the finest resolution which may be different in range and azimuth. Symmetric IPR is the term used when the resolution (sometimes referred to as IPR or impulse response ) is symmetrical in range and azimuth. Complex Samples Each sample starts life as a complex number. This is usually as an in-phase ( I ) and quadrature ( Q ) pair, but it can also be represented as amplitude and phase, which saves a user some time if they want to look at only the amplitude data. The process of calculating the amplitude from I and Q is called detection , which is the D in Ground Range Detected (GRD). The number of shades of grey that a pixel in a SAR image can have is determined by the binary representation of that pixel. As very few pixels are very bright or very dark it is often convenient to store the SAR image data as an unsigned integer - typically uint8 or uint16 format- designed to span the majority of the grey-scale values. This reduces the data size of the image and is useful for most tasks. Sometimes however, it is important to be able to discriminate between different kinds of very bright or dark pixel values (for example man-made objects in trees or ocean wave structure on a calm ocean). In these situations, a floating-point representation is more useful as it has a larger bit depth.. Container Format The container and file format defines how the data and associated metadata is stored on disk. It also defines which image viewers know how to read the data.","title":"SAR Data Formatting Options"},{"location":"productFormats/introduction/#introduction-to-sar-data","text":"","title":"Introduction To SAR Data"},{"location":"productFormats/introduction/#from-satellite-to-sar","text":"After an imaging operation has taken place, the recorded radar echo data is downloaded to one of the terminals in the ICEYE ground station network where the images are formed. The focussing algorithm varies depending on the acquisition type. The data is then stored and represented as binary data in a container file format ready for exploitation. When producing different forms of exploitable products, several decisions have to be made about the data representation. At ICEYE we realise that not every format is suitable for every customer or use case, so starting in 2022 we will be increasing the range of processing options available. This section includes a discussion of format options so that later we can refer to our current formats in context of the larger landscape. Figure 1: The Port of Rotterdam on three consecutive days.","title":"From Satellite to SAR"},{"location":"productFormats/introduction/#the-tree-of-processing-options","text":"There are many steps that have to be considered when converting RADAR pulse data into an exploitable image. Here we will talk about each in turn. Figure 2: The SAR Image Tree of Processing Options","title":"The Tree of Processing Options"},{"location":"productFormats/introduction/#sample-arrangement","text":"This is the way the image pixels are aligned as a raster in the container file. Most Geospatial Information System (GIS) viewers will convert the projection for you on your screen. Map-oriented images are larger than range-azimuth images as the rotation to make the image 'north-up' in the container file requires the addition of blank pixels to make the image rectangular. Map projection layouts are often projected to a single elevation surface; thus, they lack the geometric fidelity of range-azimuth images. They also can impart flipped terrain-perception effects in which mountains appear to be valleys and valleys appear elevated. Despite this, some users prefer the map-oriented product because its map representation with north up can be directly used with paper-based maps without any rotations.","title":"Sample Arrangement"},{"location":"productFormats/introduction/#axis-alignment","text":"Another file representation option is the alignment of axes in the binary data. Range-azimuth data can be aligned shadows down or azimuth down . Modern GIS viewers can display the data in either representation and easily convert between the two. Scientists using algorithms to exploit the data need to understand the data representation thought. Historically, imagery intelligence analysts require fine resolution imagery to observe subtle features on small objects of interest. In these situations it is more important to have a consistent alignment of shadows, multipath and layover of an object than to have North \u2018up\u2019. For large-scale mapping, azimuth down easily allows a collection to be extended by concatenating more data to the end of a file.","title":"Axis Alignment"},{"location":"productFormats/introduction/#projection-suface","text":"The focussed SAR resolution cells are fit to a projection surface. Most commonly this is the slant plane, the ground plane or an ellipsoid surface, but the projection surface can have any orientation and even be an inclined plane, a curve or the topographic surface. There are many reasons for a user preferring one projection surface over another. This is usually related to how the imagery will be exploited, but it should be recognised that the slant plane is the most efficient and artefact-free focus projection surface.","title":"Projection Suface"},{"location":"productFormats/introduction/#number-of-looks","text":"The multi-look process reduces resolution in order to reduce the speckle in the image. A single look has the finest resolution which may be different in range and azimuth. Symmetric IPR is the term used when the resolution (sometimes referred to as IPR or impulse response ) is symmetrical in range and azimuth.","title":"Number of Looks"},{"location":"productFormats/introduction/#complex-samples","text":"Each sample starts life as a complex number. This is usually as an in-phase ( I ) and quadrature ( Q ) pair, but it can also be represented as amplitude and phase, which saves a user some time if they want to look at only the amplitude data. The process of calculating the amplitude from I and Q is called detection , which is the D in Ground Range Detected (GRD). The number of shades of grey that a pixel in a SAR image can have is determined by the binary representation of that pixel. As very few pixels are very bright or very dark it is often convenient to store the SAR image data as an unsigned integer - typically uint8 or uint16 format- designed to span the majority of the grey-scale values. This reduces the data size of the image and is useful for most tasks. Sometimes however, it is important to be able to discriminate between different kinds of very bright or dark pixel values (for example man-made objects in trees or ocean wave structure on a calm ocean). In these situations, a floating-point representation is more useful as it has a larger bit depth..","title":"Complex Samples"},{"location":"productFormats/introduction/#container-format","text":"The container and file format defines how the data and associated metadata is stored on disk. It also defines which image viewers know how to read the data.","title":"Container Format"},{"location":"productFormats/metadata/","text":"Metadata is the term used to describe all the ancillary information about an image that might be important to the user. This page captures all the metadata items that are present in ICEYE imagery. You can use the search bar at the top from any page and enter the metadata element you are interested in and it will find it on this page. ICEYE Product Metadata (Version 2.6) FORMAT METADATA ELEMENTS DESCRIPTION TYPE UNIT EXAMPLE HDF5 SLC-XML GEOTIF AMP-XML acquisition_end_utc UTC time for when the last pulse of the scene was sent ASCII UTC time 2019-03-10T18:20:00.307546 acquisition_mode Acquisition mode used ASCII text Stripmap, Spotlight acquisition_prf Pulse Repetition Frequency used for the acquisition float64 Hz 4823.00342969132 acquisition_start_utc UTC time for when the first pulse of the scene was sent ASCII UTC time 2019-03-10T18:19:50.316054 angX X-component of the antenna pointing orientation vector of float64 TBP angY Y-component of the antenna pointing orientation vector of float64 TBP angZ Z-component of the antenna pointing orientation vector of float64 TBP ant_elev_corr_flag Flag indicating if antenna elevation pattern compensation was applied int64 flag 1 antenna_pattern_compensation Amplification factor applied for antenna pattern compensation (for each range sample) vector of float numbers [1.8106, 1.8103...1.0956,1.0957] avg_scene_height Average elevation over ellipsoid (calculated using SRTM or other low resolution global DEM) float32 meters 661 azimuth_ground_spacing Azimuth sample spacing in meters with the average ground projected velocity float64 meters 1.44733 azimuth_spacing Azimuth sample spacing in meters with the average ground projected velocity float64 meters 1.44733 azimuth_look_bandwidth Bandwidth of each look in range (only for GRD products) float64 Hz 1157.2 azimuth_look_overlap Overlap of adjacent looks in azimuth (only for GRD products) float64 Hz 289.3 azimuth_looks Looks in azimuth direction (for SLC products it is 1) int64 number 3 azimuth_time_interval Time interval between azimuth samples in the SLC product. (=1/processing_prf) float64 seconds 0.0002073 calibration_factor Factor to be applied to calibrate detected products to absolute brightness intensity float64 number 1.2341123e-05 carrier_frequency Carrier frequency of the radar system, static parameter float64 Hz 9650000000 chirp_bandwidth Bandwidth used for radar pulse (defines achievable radar range resolution) float64 Hz 134000000 chirp_duration Duration of chirp float64 seconds 4.1473e-05 coord_center Centre coordinate [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [8440,22139,34.86704,-117.99988] coord_first_far First azimuth row far range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [16878,1,35.17738,-118,11233] coord_first_near First azimuth row near range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [1,1,35.12016,-117.74549] coord_last_far Last azimuth row far range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [16878,44298,34.61222,-118.24414] coord_last_near Last azimuth row near range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [1,44298,34.55509,-117.88013] data_orientation Can be either \"native\" or \"shadows_down\". This describes the data inside the product storage arrays. 'native' means columns are for increasing range and increasing rows are slow time. ''shadows-down' means increasing rows are increasing range and columns represent slow-time direction ASCII text \"native\" dc_estimate_coeffs Doppler centroid coefficient as a 2D array, size MxN, where M is the number of DC estimates, and N is the (DC polynomial order+1) 2D array of float64, size MxN number [[5.417583e+03, 1.130813e+07, -8.125472e+09,7.947223e+12], ... [5.417583e+03, 1.130813e+07, -8.125472e+09,7.947223e+12]] dc_estimate_poly_order Order of polynomial describing one doppler centroid estimate int64 number 3 dc_estimate_time_utc Timestamp for each doppler centroid estimate ASCII list Time (UTC) ['2019-03-10T18:19:51.775477'],['2019-03-10T18:19:52.775477'],['2019-03-10T18:19:53.775477'],['2019-03-10T18:19:54.775477']] Doppler_Centroid_Coefficients XML Block of data containing sets of coefficiencts in a . Each Coefficient. Has a list index number , a and a . These are then followed by +1 coefficients ( ), each marked with a number ( ) and a value ( ). See Doppler Centroid Coefficient Schema Coefficient Block Hz Doppler_Rate See Doppler Rate Coefficients Schema Coefficient Block doppler_rate_coeffs Coefficients of doppler rate polynomial as a function of range time. Stored as a vector with size corresponding to the order of the doppler rate polynomial vector of float64 number [5.124592968269841e+03; -1.153864338674892e+06; 2.582540352459471e+08; -5.572042961000484e+10] doppler_rate_poly_order Order of polynomial describing doppler rate range dependence int64 number 3 first_pixel_time Two-way slant range time origin, corresponding to the near range (1st range sample) float64 seconds 0.004398670017444 fsl_compensation Amplification factor applied for free space loss compensation (for each range sample) vector of float64 numbers [1.0457, 1.0457...1.0841,1.0841] gcp_terrain_model Options are WGS84 for Ellipsoid, EGM96 for GEOID, DEM for DEM based ASCII text geo_ref_system Geographic reference frame indicator for scene coordinates and orbit state vectors ASCII text WGS84 grd_amplitude Amplitude array (only for GRD products). Sigma-nought conversion factor of sin(inc_angle) applied. as \u2018sample_precision\u2019 number array grsr_coefficients ground range to slant range polynomial coefficients (only for GRD product) vector of float64 number [6.467483312430216e+05; 0.47388031307797884; 6.685331046296479e-07; -4.928145432555108e-13; 5.0525558404285224e-20] GRSR_Coefficients See GRSR_Coefficients schema Coefficient Block grsr_ground_range_origin ground range origin for GRSR conversion number 0 grsr_poly_order Order of polynomial describing ground range to slant range projection dependence (only for GRD product) int64 number 4 grsr_zero_doppler_time ground range origin zero Doppler time ASCII UTC time 2019-04-08T14:50:13.120113 heading Satellite heading at centre of imaging operation float64 degrees incidence_angle_coefficients coefficients of the polynomial for calculating the incidence angle dependence in range vector of float64 number [ 2.67986035e+01; 8.66207416e-05; -5.61940883e-11; -1.73946139e-17; 8.22003978e-23] Incidence_Angle_Coefficients See Incidence_Angle_Coefficients XML Block Schema Coefficient Block number incidence_angle_ground_range_origin incidence angle origin in ground range, for calculating incidence angle dependence in range float64 number 0 incidence_angle_poly_order order of the polynomial for calculating the incidence angle dependence in range int64 number 4 incidence_angle_zero_doppler_time incidence angle origin zero Doppler time ASCII UTC time 2019-04-08T14:50:13.120113 incidence_center incidence angle in ground at middle range float64 degrees 23.5 incidence_far incidence angle in ground at far range float64 degrees incidence_near incidence angle in ground at near range float64 degrees look_side Look side of the acquisition, only 2 options LEFT or RIGHT ASCII text LEFT mean_earth_radius mean WGS84 ellipsoid radius over scene float64 meters 6371346.049 mean_orbit_altitude mean sensor altitude above WGS84 ellipsoid float64 meters 595177.494 number_of_azimuth_samples Number of azimuth samples (number of rows in binary data) int64 number 44298 number_of_dc_estimations Number of doppler centroid estimates int64 number 9 number_of_range_samples Number of range samples (number of columns in binary data) int64 number 16878 number_of_state_vectors Total number of orbit state vectors provided for the scene int64 number 120 orbit_absolute_number Absolute number of orbits since launch int64 number 1447 orbit_direction Specifies whether the orbit is in ascending or descending node at the time of acquisition ASCII text ASCENDING or DESCENDING orbit_processing_level PREDICTED (based on orbit propagation model ) RAPID (uses onboard GPS data ) PRECISE (corrections applied after GPS data received in ground using high precision orbit propagator (eg ODTK) SCIENTIFIC (Uses precise ground-based measurements together with all above to post-fix orbit to best possible) ASCII Text orbit_relative_number Relative number of orbit within the repeat cycle int64 number 1447 orbit_repeat_cycle Ground track repeat cycle (to be included) int64 number 99999 Orbit_State_Vectors See Orbit_State_Vectors XML Schema Coefficient Block pitch Pitch angle of the satellite attitude float degrees 11.5 polarization Transmit and receive polarizations used ASCII text VV posX X-component of state vector position, for each state vector vector of float64 meters [-2401162517\u2026 -2456350660] posY Y-component of state vector position, for each state vector vector of float64 meters [-5201254993\u2026 -5253761907] posZ Z-component of state vector position, for each state vector vector of float64 meters [3963994744\u2026 3859728760] processing_prf Pulse Repetition Frequency used for the processing, defines azimuth sample spacing in time (can be higher than acquisition in cases where the Doppler frequency needs to be unfolded due to high variation of Doppler centroid with range) float64 Hz 9646.00685938265 processing_time Timestamp provided by the SAR processor saying when the image for processed ASCII UTC Time 2020-05-27T05:01:49 processor_version Version number of the processor used to generate the product float64 number (internal version numbering) product_level Processing level ASCII text SLC, GRD product_file File name of this product ASCII text ICEYE_X2_SLC_SM_16519_20200102T155349.h5 product_name ICEYE_datasetID_eventID_(YYYYMMDD)T(HHMMSS) ASCII Text ICEYE_2457_123123_20191201T056721 product_type Product type (if we have product names for different imaging modes) ASCII text Stripmap, StripmapHigh, Spotlight, SpotlightHigh range_look_bandwidth Bandwidth of each look in range (only for GRD products) float64 Hz 53600000 range_look_overlap Overlap of adjacent looks in range (only for GRD products) float64 Hz 13400000 range_looks Looks in range direction (for SLC products it is 1) int64 number 3 range_sampling_rate Sampling rate used for digital sampling, defines range sample spacing in time float64 Hz 157500000 range_spread_comp_flag Flag indicating if free space loss compensation was applied int64 flag 1 RPC RPC according to http://geotiff.maptools.org/rpc_prop.html Coefficient Block s_i Real part of the SLC complex array (only for SLC products) as \u2018sample_precision\u2019 number array s_q Imaginary part of the SLC complex array (only for SLC products) as \u2018sample_precision\u2019 number array sample_precision Precision used for binary data samples ASCII text float32, int16 satellite_look_angle Satellite look angle float64 degrees 23.5 satellite_name Name of the satellite ASCII text ICEYE-X2, ICEYE-X4... scan_beams Provides information Scan beams used in Scan mode (SCAN MODE ONLY) Struct slant_range_spacing Spacing between two consecutive slant range samples in meters (SLC ONLY) float64 meters 0.95172208888 slant_range_to_first_pixel Two-way slant range distance corresponding to near range (1st sample) float64 metres spec_version Version of the Level 1 Product Format Specification document float64 number 2.3 state_vector_time_utc Timestamp for each orbit state vector list of ASCII UTC time [2019-03-10T18:19:48.000000, ...] total_processed_bandwidth_azimuth Doppler bandwidth used for azimuth compression (defines achievable azimuth resolution) float64 Hz 2893 tropo_range_delay Mean signal path length correction (one way) that has been applied to correct for tropospheric propagation float64 meters 2.4 velX X-component of state vector velocity, for each state vector vector of float64 meters/sec [-3285.698...-3245.220] velY Y-component of state vector velocity, for each state vector vector of float64 meters/sec [-3162.667...-3051.016] velZ Z-component of state vector velocity, for each state vector vector of float64 meters/sec [-6130.372...-6208.463] window_function_azimuth Windowing function used over azimuth frequencies ASCII text taylor_20_4 window_function_range Windowing function used over range frequencies ASCII text taylor_20_4 yaw Yaw angle of the satellite attitude float degrees zerodoppler_end_utc Time corresponding to when the satellite was at the zero Doppler position for the last scene pulse ASCII UTC time 2019-03-10T18:20:00.960210 zerodoppler_start_utc Time corresponding to when the satellite was at the zero Doppler position for the first scene pulse ASCII UTC time 2019-03-10T18:19:51.775477","title":"Metadata"},{"location":"productFormats/metadata/#iceye-product-metadata-version-26","text":"FORMAT METADATA ELEMENTS DESCRIPTION TYPE UNIT EXAMPLE HDF5 SLC-XML GEOTIF AMP-XML acquisition_end_utc UTC time for when the last pulse of the scene was sent ASCII UTC time 2019-03-10T18:20:00.307546 acquisition_mode Acquisition mode used ASCII text Stripmap, Spotlight acquisition_prf Pulse Repetition Frequency used for the acquisition float64 Hz 4823.00342969132 acquisition_start_utc UTC time for when the first pulse of the scene was sent ASCII UTC time 2019-03-10T18:19:50.316054 angX X-component of the antenna pointing orientation vector of float64 TBP angY Y-component of the antenna pointing orientation vector of float64 TBP angZ Z-component of the antenna pointing orientation vector of float64 TBP ant_elev_corr_flag Flag indicating if antenna elevation pattern compensation was applied int64 flag 1 antenna_pattern_compensation Amplification factor applied for antenna pattern compensation (for each range sample) vector of float numbers [1.8106, 1.8103...1.0956,1.0957] avg_scene_height Average elevation over ellipsoid (calculated using SRTM or other low resolution global DEM) float32 meters 661 azimuth_ground_spacing Azimuth sample spacing in meters with the average ground projected velocity float64 meters 1.44733 azimuth_spacing Azimuth sample spacing in meters with the average ground projected velocity float64 meters 1.44733 azimuth_look_bandwidth Bandwidth of each look in range (only for GRD products) float64 Hz 1157.2 azimuth_look_overlap Overlap of adjacent looks in azimuth (only for GRD products) float64 Hz 289.3 azimuth_looks Looks in azimuth direction (for SLC products it is 1) int64 number 3 azimuth_time_interval Time interval between azimuth samples in the SLC product. (=1/processing_prf) float64 seconds 0.0002073 calibration_factor Factor to be applied to calibrate detected products to absolute brightness intensity float64 number 1.2341123e-05 carrier_frequency Carrier frequency of the radar system, static parameter float64 Hz 9650000000 chirp_bandwidth Bandwidth used for radar pulse (defines achievable radar range resolution) float64 Hz 134000000 chirp_duration Duration of chirp float64 seconds 4.1473e-05 coord_center Centre coordinate [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [8440,22139,34.86704,-117.99988] coord_first_far First azimuth row far range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [16878,1,35.17738,-118,11233] coord_first_near First azimuth row near range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [1,1,35.12016,-117.74549] coord_last_far Last azimuth row far range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [16878,44298,34.61222,-118.24414] coord_last_near Last azimuth row near range coordinate. [x(col), y(row),lat,lon] [int32,int32, float64, float64] coordinates [1,44298,34.55509,-117.88013] data_orientation Can be either \"native\" or \"shadows_down\". This describes the data inside the product storage arrays. 'native' means columns are for increasing range and increasing rows are slow time. ''shadows-down' means increasing rows are increasing range and columns represent slow-time direction ASCII text \"native\" dc_estimate_coeffs Doppler centroid coefficient as a 2D array, size MxN, where M is the number of DC estimates, and N is the (DC polynomial order+1) 2D array of float64, size MxN number [[5.417583e+03, 1.130813e+07, -8.125472e+09,7.947223e+12], ... [5.417583e+03, 1.130813e+07, -8.125472e+09,7.947223e+12]] dc_estimate_poly_order Order of polynomial describing one doppler centroid estimate int64 number 3 dc_estimate_time_utc Timestamp for each doppler centroid estimate ASCII list Time (UTC) ['2019-03-10T18:19:51.775477'],['2019-03-10T18:19:52.775477'],['2019-03-10T18:19:53.775477'],['2019-03-10T18:19:54.775477']] Doppler_Centroid_Coefficients XML Block of data containing sets of coefficiencts in a . Each Coefficient. Has a list index number , a and a . These are then followed by +1 coefficients ( ), each marked with a number ( ) and a value ( ). See Doppler Centroid Coefficient Schema Coefficient Block Hz Doppler_Rate See Doppler Rate Coefficients Schema Coefficient Block doppler_rate_coeffs Coefficients of doppler rate polynomial as a function of range time. Stored as a vector with size corresponding to the order of the doppler rate polynomial vector of float64 number [5.124592968269841e+03; -1.153864338674892e+06; 2.582540352459471e+08; -5.572042961000484e+10] doppler_rate_poly_order Order of polynomial describing doppler rate range dependence int64 number 3 first_pixel_time Two-way slant range time origin, corresponding to the near range (1st range sample) float64 seconds 0.004398670017444 fsl_compensation Amplification factor applied for free space loss compensation (for each range sample) vector of float64 numbers [1.0457, 1.0457...1.0841,1.0841] gcp_terrain_model Options are WGS84 for Ellipsoid, EGM96 for GEOID, DEM for DEM based ASCII text geo_ref_system Geographic reference frame indicator for scene coordinates and orbit state vectors ASCII text WGS84 grd_amplitude Amplitude array (only for GRD products). Sigma-nought conversion factor of sin(inc_angle) applied. as \u2018sample_precision\u2019 number array grsr_coefficients ground range to slant range polynomial coefficients (only for GRD product) vector of float64 number [6.467483312430216e+05; 0.47388031307797884; 6.685331046296479e-07; -4.928145432555108e-13; 5.0525558404285224e-20] GRSR_Coefficients See GRSR_Coefficients schema Coefficient Block grsr_ground_range_origin ground range origin for GRSR conversion number 0 grsr_poly_order Order of polynomial describing ground range to slant range projection dependence (only for GRD product) int64 number 4 grsr_zero_doppler_time ground range origin zero Doppler time ASCII UTC time 2019-04-08T14:50:13.120113 heading Satellite heading at centre of imaging operation float64 degrees incidence_angle_coefficients coefficients of the polynomial for calculating the incidence angle dependence in range vector of float64 number [ 2.67986035e+01; 8.66207416e-05; -5.61940883e-11; -1.73946139e-17; 8.22003978e-23] Incidence_Angle_Coefficients See Incidence_Angle_Coefficients XML Block Schema Coefficient Block number incidence_angle_ground_range_origin incidence angle origin in ground range, for calculating incidence angle dependence in range float64 number 0 incidence_angle_poly_order order of the polynomial for calculating the incidence angle dependence in range int64 number 4 incidence_angle_zero_doppler_time incidence angle origin zero Doppler time ASCII UTC time 2019-04-08T14:50:13.120113 incidence_center incidence angle in ground at middle range float64 degrees 23.5 incidence_far incidence angle in ground at far range float64 degrees incidence_near incidence angle in ground at near range float64 degrees look_side Look side of the acquisition, only 2 options LEFT or RIGHT ASCII text LEFT mean_earth_radius mean WGS84 ellipsoid radius over scene float64 meters 6371346.049 mean_orbit_altitude mean sensor altitude above WGS84 ellipsoid float64 meters 595177.494 number_of_azimuth_samples Number of azimuth samples (number of rows in binary data) int64 number 44298 number_of_dc_estimations Number of doppler centroid estimates int64 number 9 number_of_range_samples Number of range samples (number of columns in binary data) int64 number 16878 number_of_state_vectors Total number of orbit state vectors provided for the scene int64 number 120 orbit_absolute_number Absolute number of orbits since launch int64 number 1447 orbit_direction Specifies whether the orbit is in ascending or descending node at the time of acquisition ASCII text ASCENDING or DESCENDING orbit_processing_level PREDICTED (based on orbit propagation model ) RAPID (uses onboard GPS data ) PRECISE (corrections applied after GPS data received in ground using high precision orbit propagator (eg ODTK) SCIENTIFIC (Uses precise ground-based measurements together with all above to post-fix orbit to best possible) ASCII Text orbit_relative_number Relative number of orbit within the repeat cycle int64 number 1447 orbit_repeat_cycle Ground track repeat cycle (to be included) int64 number 99999 Orbit_State_Vectors See Orbit_State_Vectors XML Schema Coefficient Block pitch Pitch angle of the satellite attitude float degrees 11.5 polarization Transmit and receive polarizations used ASCII text VV posX X-component of state vector position, for each state vector vector of float64 meters [-2401162517\u2026 -2456350660] posY Y-component of state vector position, for each state vector vector of float64 meters [-5201254993\u2026 -5253761907] posZ Z-component of state vector position, for each state vector vector of float64 meters [3963994744\u2026 3859728760] processing_prf Pulse Repetition Frequency used for the processing, defines azimuth sample spacing in time (can be higher than acquisition in cases where the Doppler frequency needs to be unfolded due to high variation of Doppler centroid with range) float64 Hz 9646.00685938265 processing_time Timestamp provided by the SAR processor saying when the image for processed ASCII UTC Time 2020-05-27T05:01:49 processor_version Version number of the processor used to generate the product float64 number (internal version numbering) product_level Processing level ASCII text SLC, GRD product_file File name of this product ASCII text ICEYE_X2_SLC_SM_16519_20200102T155349.h5 product_name ICEYE_datasetID_eventID_(YYYYMMDD)T(HHMMSS) ASCII Text ICEYE_2457_123123_20191201T056721 product_type Product type (if we have product names for different imaging modes) ASCII text Stripmap, StripmapHigh, Spotlight, SpotlightHigh range_look_bandwidth Bandwidth of each look in range (only for GRD products) float64 Hz 53600000 range_look_overlap Overlap of adjacent looks in range (only for GRD products) float64 Hz 13400000 range_looks Looks in range direction (for SLC products it is 1) int64 number 3 range_sampling_rate Sampling rate used for digital sampling, defines range sample spacing in time float64 Hz 157500000 range_spread_comp_flag Flag indicating if free space loss compensation was applied int64 flag 1 RPC RPC according to http://geotiff.maptools.org/rpc_prop.html Coefficient Block s_i Real part of the SLC complex array (only for SLC products) as \u2018sample_precision\u2019 number array s_q Imaginary part of the SLC complex array (only for SLC products) as \u2018sample_precision\u2019 number array sample_precision Precision used for binary data samples ASCII text float32, int16 satellite_look_angle Satellite look angle float64 degrees 23.5 satellite_name Name of the satellite ASCII text ICEYE-X2, ICEYE-X4... scan_beams Provides information Scan beams used in Scan mode (SCAN MODE ONLY) Struct slant_range_spacing Spacing between two consecutive slant range samples in meters (SLC ONLY) float64 meters 0.95172208888 slant_range_to_first_pixel Two-way slant range distance corresponding to near range (1st sample) float64 metres spec_version Version of the Level 1 Product Format Specification document float64 number 2.3 state_vector_time_utc Timestamp for each orbit state vector list of ASCII UTC time [2019-03-10T18:19:48.000000, ...] total_processed_bandwidth_azimuth Doppler bandwidth used for azimuth compression (defines achievable azimuth resolution) float64 Hz 2893 tropo_range_delay Mean signal path length correction (one way) that has been applied to correct for tropospheric propagation float64 meters 2.4 velX X-component of state vector velocity, for each state vector vector of float64 meters/sec [-3285.698...-3245.220] velY Y-component of state vector velocity, for each state vector vector of float64 meters/sec [-3162.667...-3051.016] velZ Z-component of state vector velocity, for each state vector vector of float64 meters/sec [-6130.372...-6208.463] window_function_azimuth Windowing function used over azimuth frequencies ASCII text taylor_20_4 window_function_range Windowing function used over range frequencies ASCII text taylor_20_4 yaw Yaw angle of the satellite attitude float degrees zerodoppler_end_utc Time corresponding to when the satellite was at the zero Doppler position for the last scene pulse ASCII UTC time 2019-03-10T18:20:00.960210 zerodoppler_start_utc Time corresponding to when the satellite was at the zero Doppler position for the first scene pulse ASCII UTC time 2019-03-10T18:19:51.775477","title":"ICEYE Product Metadata (Version 2.6)"},{"location":"productFormats/packaging/","text":"SAR Data Package File Naming Product file naming convention describes the product processing level so that a user does not have to analyze product metadata to understand key properties. The product filename components are shown in Figure 1. The Product ID is a unique identifier of the acquired scene and is assigned during scene ordering and acquisition. Figure 1: Data product filename components The constituent elements are explained in more detail in Table 1 CONSTITUENT NAME VALUE NOTES ICEYE_ constellation ICEYE_ fixed XN_ sensor X2/X4/X5 specific sensor that has acquired the scene PPL_ product processing level SLC/GRD variant of processing level IM_ imaging mode SM/SMH/SL/SLH stripmap, stripmap-high, spotlight, spotlight-high PRID_ product id eg. 6403 data take ID YYYYMMDD UTC start date eg. 20190211 YYYYMMDD format Thhmmss UTC start time eg. T131415 Thhmmss format Table 1: Product filename components. Example : ICEYE_X6_GRD_SM_153426_20211026T060946 Package Overview SAR images can be ordered either from archive (previously collected imagery) or as a planned future acquisition. Products are geo-coded and radiometrically corrected. ICEYE\u2019s focus is currently on the integrity of complex and amplitude images. This will expand over the next year as we introduce a phase history data product and other products derived from complex and amplitude images. A basic ICEYE product is represented by a set of SAR image binary data, corresponding image metadata and it is delivered as a singular product package. Products are characterized by the payload configuration (such as imaging mode and look direction) used by the respective satellite, as well as the level of processing that has been applied to the SAR scene. With respect to the data geometric projection and representation, products are differentiated into two primary types: geo-referenced Single Look Complex (SLC) and Amplitude Images (Also known as Ground Range Detected (GRD) scenes). SAR image binary data, delivered as digital numbers or quadrature components, can be converted to radar brightness \\(\\beta_0\\) and mean radar cross section \\(\\sigma_0\\) using the annotated calibration factor in the image metadata.","title":"Packaging"},{"location":"productFormats/packaging/#sar-data-package","text":"","title":"SAR Data Package"},{"location":"productFormats/packaging/#file-naming","text":"Product file naming convention describes the product processing level so that a user does not have to analyze product metadata to understand key properties. The product filename components are shown in Figure 1. The Product ID is a unique identifier of the acquired scene and is assigned during scene ordering and acquisition. Figure 1: Data product filename components The constituent elements are explained in more detail in Table 1 CONSTITUENT NAME VALUE NOTES ICEYE_ constellation ICEYE_ fixed XN_ sensor X2/X4/X5 specific sensor that has acquired the scene PPL_ product processing level SLC/GRD variant of processing level IM_ imaging mode SM/SMH/SL/SLH stripmap, stripmap-high, spotlight, spotlight-high PRID_ product id eg. 6403 data take ID YYYYMMDD UTC start date eg. 20190211 YYYYMMDD format Thhmmss UTC start time eg. T131415 Thhmmss format Table 1: Product filename components. Example : ICEYE_X6_GRD_SM_153426_20211026T060946","title":"File Naming"},{"location":"productFormats/packaging/#package-overview","text":"SAR images can be ordered either from archive (previously collected imagery) or as a planned future acquisition. Products are geo-coded and radiometrically corrected. ICEYE\u2019s focus is currently on the integrity of complex and amplitude images. This will expand over the next year as we introduce a phase history data product and other products derived from complex and amplitude images. A basic ICEYE product is represented by a set of SAR image binary data, corresponding image metadata and it is delivered as a singular product package. Products are characterized by the payload configuration (such as imaging mode and look direction) used by the respective satellite, as well as the level of processing that has been applied to the SAR scene. With respect to the data geometric projection and representation, products are differentiated into two primary types: geo-referenced Single Look Complex (SLC) and Amplitude Images (Also known as Ground Range Detected (GRD) scenes). SAR image binary data, delivered as digital numbers or quadrature components, can be converted to radar brightness \\(\\beta_0\\) and mean radar cross section \\(\\sigma_0\\) using the annotated calibration factor in the image metadata.","title":"Package Overview"},{"location":"productFormats/radiometric/","text":"Calibration and Projection Conversion The grey-scale values of SAR pixels do not directly correspond to a scientific measurement of the radar cross section of the associated ground area. In most cases this does not matter as users just want to view the spatial distribution of scattering objects and perhaps their relative radar reflectivity. However, SAR is a scientific instrument and some applications benefit from additional information about the ground's reflecting properties. These applications require the pixel\u2019s mean radar cross section, which is a true measure of the radar reflectivity. To access this information, a calibration factor needs to be applied to the pixel data. This next section provides information on how this is done. First, however, we need to have a short discussion about mean radar cross section. Different Types of Mean Radar Cross Section An object's ability to scatter energy back towards the radar is called its radar cross section (RCS). It is not a fixed property and its value can change under different situations: The orientation of the object with respect to the RADAR The shape of the object The wavelength of the RADAR compared to the size of the object The ability of the object to reflect an electromagnetic field This is called the dielectric constant . Metal and water have high dielectric constants and reflect strongly, bare ground cover has much lower dielectric constant. Polarization of the radar energy The RCS describes the relative reflecting cross-section of an object and its units are \\(m^2\\) . RCS values are compared to the reference RCS of a hypothetical, perfectly-reflecting sphere with an area of 1 \\(m^2\\) (radius of 0.565 m) . RCS does not indicate the physical size of an object. For example, a metal plate with an area of 1 \\(m^2\\) oriented orthogonal to the incoming energy would have an RCS of 14,000 \\(m^2\\) , while that of a small boat could be much less than 1 \\(m^2\\) . The symbol for RCS is by convention \\(\\sigma\\) . In the real world, though, there are usually multiple scattering objects within a resolution cell (and we almost never encounter a 1 m metal sphere). Since a pixel in a SAR image contains many hundreds of scattering objects, it has a mean RADAR cross section. To distinguish this from a single-object RCS we use the symbol \\(\\sigma_0\\) . Figure 1: The relationship between \u03b20, \u03b30 and \u03c30 When illuminating the ground with a SAR sensor, the orientation of the surface compared to the resolution cell in the slant plane has a large impact on the mean RCS. The slant plane area of a pixel is constant, but when projected onto the ground, the pixel\u2019s area is elongated in range, and the mean RCS changes with incidence angle. This leads to a 'brightening effect' at lower incidence angles in the slant plane image as each pixel's ground area increases. This means that the observed mean RCS values in the SLC image represent the RADAR brightness rather than the terrain mean RCS \\(\\sigma_0\\) . The RADAR brightness is denoted by \\(\\beta_0\\) . Another noticeable and sometimes undesirable effect is that of local terrain topography. Terrain slopes that are oriented towards the satellite have a larger radar backscatter towards the RADAR than leeward slopes, which are inclined away from the radar and tend to reflect radar energy away. If the actual reflective properties of the terrain are needed, then this relief effect can be flattened to create a \\(\\gamma_0\\) image. The relationship between these three properties can be seen in Figure 1. Calibration Correction The radiometric and beam calibration of ICEYE's sensors is performed using wide-area and consistent reflections from Amazon and Congo forests, while point target sites are used for impulse response and geolocation calibration. The conversion to radar brightness ( \\(\\beta_0\\) ) values is provided through the application of a calibration factor (CF) annotated as calibration_factor in the product metadata: \\[ \\beta_0 = CF|DN_{SLC}|^2 \\] \\[ \\beta_0 = CF\\frac{|DN_{GRD}|^2}{\\sin(\\theta)} \\] For amplitude scenes, a conversion to \\(\\sigma_0\\) has already been applied using the incidence angle calculated from the ellipsoid model. This simplifies the calculation of the radar backscatter to : \\[ \\sigma_0 = CF |DN_{GRD}|^2 \\] \\[ \\sigma_{0dB} = 10\\log_{10}(\\sigma_0) \\] \\[ |DN_{GRD}|^2 = |DN_{SLC}|^2 \\sin(\\theta) \\] If the processing of \\(\\beta_0\\) is required from the amplitude image for further orthorectification to \\(\\sigma_0\\) or \\(\\gamma_0\\) values using a local DEM, then the conversion to radar brightness can be performed using the incidence angle information annotated in the metadata (see Ground Range To Incidence Angle Conversion ). ( \\(\\gamma_0\\) ) values can be obtained using the \\(\\beta_0\\) values and a local digital elevation model. To assist in viewing analysis and projection, all amplitude products are projected onto the WGS84 Reference Ellipsoid. Doppler Centroid Determination ICEYE SAR images are zero-Doppler based. This means that image pixels are focussed to the zero-Doppler (or broadside ) position. The radar beam covers a range of Doppler frequencies. Objects entering the beam have a high Doppler frequency and objects leaving the beam have a low Doppler frequency. This means that the centre point, called the Doppler Centroid (DC), can be used to find where the radar beam is pointing at any moment. The Doppler Centroid and the orbit state vector information are used to determine the precise azimuth location that the radar beam is pointing to. A set of DC coefficients are provided in the image metadata. For each azimuth location, the DC dependence in range is described using a polynomial function. The polynomial is valid from the near to the far range of the scene. The DC coefficients can be obtained by fitting the DC dependence in range from time as: \\[ DC(t)=C_0\\left(t-t_{ref}\\right)^0+C_1 \\left(t-t_{ref}\\right)^1+C_2 \\left(t-t_{ref}\\right)^2+C_3 \\left(t-t_{ref}\\right)^3\\] where the reference point in time \\(t_{ref}\\) corresponds to the mid-range time, and time varies between \\(t_{min}\\) and \\(t_{max}\\) corresponding to near range (first pixel time) and far range, respectively. The mid-range time is calculated as: \\[ t_{ref}= (t_{min} +t_{max})/2=t_{min}+n_{rs}/(2f_{sr} )\\] where \\(n_{rs}\\) is the number of range samples, and \\(f_{sr}\\) is the range sampling rate.","title":"Radiometric Considerations"},{"location":"productFormats/radiometric/#calibration-and-projection-conversion","text":"The grey-scale values of SAR pixels do not directly correspond to a scientific measurement of the radar cross section of the associated ground area. In most cases this does not matter as users just want to view the spatial distribution of scattering objects and perhaps their relative radar reflectivity. However, SAR is a scientific instrument and some applications benefit from additional information about the ground's reflecting properties. These applications require the pixel\u2019s mean radar cross section, which is a true measure of the radar reflectivity. To access this information, a calibration factor needs to be applied to the pixel data. This next section provides information on how this is done. First, however, we need to have a short discussion about mean radar cross section.","title":"Calibration and Projection Conversion"},{"location":"productFormats/radiometric/#different-types-of-mean-radar-cross-section","text":"An object's ability to scatter energy back towards the radar is called its radar cross section (RCS). It is not a fixed property and its value can change under different situations: The orientation of the object with respect to the RADAR The shape of the object The wavelength of the RADAR compared to the size of the object The ability of the object to reflect an electromagnetic field This is called the dielectric constant . Metal and water have high dielectric constants and reflect strongly, bare ground cover has much lower dielectric constant. Polarization of the radar energy The RCS describes the relative reflecting cross-section of an object and its units are \\(m^2\\) . RCS values are compared to the reference RCS of a hypothetical, perfectly-reflecting sphere with an area of 1 \\(m^2\\) (radius of 0.565 m) . RCS does not indicate the physical size of an object. For example, a metal plate with an area of 1 \\(m^2\\) oriented orthogonal to the incoming energy would have an RCS of 14,000 \\(m^2\\) , while that of a small boat could be much less than 1 \\(m^2\\) . The symbol for RCS is by convention \\(\\sigma\\) . In the real world, though, there are usually multiple scattering objects within a resolution cell (and we almost never encounter a 1 m metal sphere). Since a pixel in a SAR image contains many hundreds of scattering objects, it has a mean RADAR cross section. To distinguish this from a single-object RCS we use the symbol \\(\\sigma_0\\) . Figure 1: The relationship between \u03b20, \u03b30 and \u03c30 When illuminating the ground with a SAR sensor, the orientation of the surface compared to the resolution cell in the slant plane has a large impact on the mean RCS. The slant plane area of a pixel is constant, but when projected onto the ground, the pixel\u2019s area is elongated in range, and the mean RCS changes with incidence angle. This leads to a 'brightening effect' at lower incidence angles in the slant plane image as each pixel's ground area increases. This means that the observed mean RCS values in the SLC image represent the RADAR brightness rather than the terrain mean RCS \\(\\sigma_0\\) . The RADAR brightness is denoted by \\(\\beta_0\\) . Another noticeable and sometimes undesirable effect is that of local terrain topography. Terrain slopes that are oriented towards the satellite have a larger radar backscatter towards the RADAR than leeward slopes, which are inclined away from the radar and tend to reflect radar energy away. If the actual reflective properties of the terrain are needed, then this relief effect can be flattened to create a \\(\\gamma_0\\) image. The relationship between these three properties can be seen in Figure 1.","title":"Different Types of Mean Radar Cross Section"},{"location":"productFormats/radiometric/#calibration-correction","text":"The radiometric and beam calibration of ICEYE's sensors is performed using wide-area and consistent reflections from Amazon and Congo forests, while point target sites are used for impulse response and geolocation calibration. The conversion to radar brightness ( \\(\\beta_0\\) ) values is provided through the application of a calibration factor (CF) annotated as calibration_factor in the product metadata: \\[ \\beta_0 = CF|DN_{SLC}|^2 \\] \\[ \\beta_0 = CF\\frac{|DN_{GRD}|^2}{\\sin(\\theta)} \\] For amplitude scenes, a conversion to \\(\\sigma_0\\) has already been applied using the incidence angle calculated from the ellipsoid model. This simplifies the calculation of the radar backscatter to : \\[ \\sigma_0 = CF |DN_{GRD}|^2 \\] \\[ \\sigma_{0dB} = 10\\log_{10}(\\sigma_0) \\] \\[ |DN_{GRD}|^2 = |DN_{SLC}|^2 \\sin(\\theta) \\] If the processing of \\(\\beta_0\\) is required from the amplitude image for further orthorectification to \\(\\sigma_0\\) or \\(\\gamma_0\\) values using a local DEM, then the conversion to radar brightness can be performed using the incidence angle information annotated in the metadata (see Ground Range To Incidence Angle Conversion ). ( \\(\\gamma_0\\) ) values can be obtained using the \\(\\beta_0\\) values and a local digital elevation model. To assist in viewing analysis and projection, all amplitude products are projected onto the WGS84 Reference Ellipsoid.","title":"Calibration Correction"},{"location":"productFormats/radiometric/#doppler-centroid-determination","text":"ICEYE SAR images are zero-Doppler based. This means that image pixels are focussed to the zero-Doppler (or broadside ) position. The radar beam covers a range of Doppler frequencies. Objects entering the beam have a high Doppler frequency and objects leaving the beam have a low Doppler frequency. This means that the centre point, called the Doppler Centroid (DC), can be used to find where the radar beam is pointing at any moment. The Doppler Centroid and the orbit state vector information are used to determine the precise azimuth location that the radar beam is pointing to. A set of DC coefficients are provided in the image metadata. For each azimuth location, the DC dependence in range is described using a polynomial function. The polynomial is valid from the near to the far range of the scene. The DC coefficients can be obtained by fitting the DC dependence in range from time as: \\[ DC(t)=C_0\\left(t-t_{ref}\\right)^0+C_1 \\left(t-t_{ref}\\right)^1+C_2 \\left(t-t_{ref}\\right)^2+C_3 \\left(t-t_{ref}\\right)^3\\] where the reference point in time \\(t_{ref}\\) corresponds to the mid-range time, and time varies between \\(t_{min}\\) and \\(t_{max}\\) corresponding to near range (first pixel time) and far range, respectively. The mid-range time is calculated as: \\[ t_{ref}= (t_{min} +t_{max})/2=t_{min}+n_{rs}/(2f_{sr} )\\] where \\(n_{rs}\\) is the number of range samples, and \\(f_{sr}\\) is the range sampling rate.","title":"Doppler Centroid Determination"},{"location":"productFormats/slantToGround/","text":"Ground Range To Slant Range Conversion For ground projected products, the ground range to slant range (GRSR) conversion can be performed using the GRSR polynomial coefficients ( GRSR_Coefficients ) stored in the metadata. Once applied, the slant range location of a specific pixel in the ground range can be calculated from: \\[ R_{slant}(j)=\\sum_{k=0}^{p+1} C_k ((j-1)\\delta_r)^k,\\qquad j=[1...n] \\] Where: \\(R_{slant}(j)\\) is the slant range for the \\(j\\) -th ground range pixel \\(p\\) is the order of the ground range to slant range polynomial ( grsr_poly_order in the metadata) \\(C_k\\) is the \\(k\\) -th polynomial coefficient \\(\\delta_r\\) is the ground range spacing ( range_spacing in the metadata) Ground Range To Incidence Angle Conversion The nominal incidence angle is the angle between a given slant range and the WGS84 ellipsoid. This should not be confused with the local incidence angle , which is references to the local terrain. It can be calculated from the ground range using the Incidence_Angle_Coefficients in the metadata and: \\[ \\theta(j)=\\sum_{k=0}^{p+1} C_k ((j-1)\\delta_r)^k,\\qquad j=[1...n] \\] Where: \\(\\theta(j)\\) is the incidence angle for the \\(j\\) -th ground range pixel \\(p\\) is the order of the ground range to incidence angle polynomial ( incidence_angle_poly_order in the metadata) \\(C_k\\) is the \\(k\\) -th polynomial coefficient \\(\\delta_r\\) is the ground range spacing ( range_spacing in the metadata)","title":"Slant to Ground Conversion"},{"location":"productFormats/slantToGround/#ground-range-to-slant-range-conversion","text":"For ground projected products, the ground range to slant range (GRSR) conversion can be performed using the GRSR polynomial coefficients ( GRSR_Coefficients ) stored in the metadata. Once applied, the slant range location of a specific pixel in the ground range can be calculated from: \\[ R_{slant}(j)=\\sum_{k=0}^{p+1} C_k ((j-1)\\delta_r)^k,\\qquad j=[1...n] \\] Where: \\(R_{slant}(j)\\) is the slant range for the \\(j\\) -th ground range pixel \\(p\\) is the order of the ground range to slant range polynomial ( grsr_poly_order in the metadata) \\(C_k\\) is the \\(k\\) -th polynomial coefficient \\(\\delta_r\\) is the ground range spacing ( range_spacing in the metadata)","title":"Ground Range To Slant Range Conversion"},{"location":"productFormats/slantToGround/#ground-range-to-incidence-angle-conversion","text":"The nominal incidence angle is the angle between a given slant range and the WGS84 ellipsoid. This should not be confused with the local incidence angle , which is references to the local terrain. It can be calculated from the ground range using the Incidence_Angle_Coefficients in the metadata and: \\[ \\theta(j)=\\sum_{k=0}^{p+1} C_k ((j-1)\\delta_r)^k,\\qquad j=[1...n] \\] Where: \\(\\theta(j)\\) is the incidence angle for the \\(j\\) -th ground range pixel \\(p\\) is the order of the ground range to incidence angle polynomial ( incidence_angle_poly_order in the metadata) \\(C_k\\) is the \\(k\\) -th polynomial coefficient \\(\\delta_r\\) is the ground range spacing ( range_spacing in the metadata)","title":"Ground Range To Incidence Angle Conversion"},{"location":"productFormats/slc/","text":"Overview Single Look Complex (SLC) images have the highest fidelity of all SAR image products because they are only one step removed from the original RADAR collected data. They retain all the original sensor measurements and are free from interpolation artefacts or projection issues. A small concession is made with the default SLC product in that the dynamic range of the complex numbers is reduced to make image sizes more manageable. SLC products are the best source for SAR image analysis, but complex-image exploitation software is currently difficult to use without skill and experience. For this reason, SLC images are usually used for automated processing and advanced exploitation such as interferometric applications, or by users who prefer lower-level processing in order to implement their own processing chains. The SLC product can be orthorectified using both commercial and free specialized SAR software tools such as the European Space Agency (ESA) Sentinel Application Platform (SNAP) 1 . Geometry Scenes are stored in the satellite image acquisition geometry (AKA the slant plane ). The image coordinate system is centred on the zero-Doppler (time of closest approach) SAR coordinates and are arranged in the slant-range-by-azimuth imaging plane. The pixels are spaced equidistant in azimuth (according to the inverse of the pulse repetition frequency) and in slant range (according to the range sampling frequency). Each image pixel is stored with in-phase I and quadrature Q components and therefore, contains both amplitude and phase information. Looks As the name suggests, SLC images have only a single look. This means they retain full resolution in azimuth and range. In most cases the impulse response function (the shape of a single, isolated radar-bright object in the radar image) is asymmetrical with azimuth resolution being smaller (finer) than range resolution. Binary Representation SLC images are stored as binary matrices in an HDF5 file container 2 . Real and imaginary components are stored separately, using either signed 16 bit integers or IEEE-754 single precision 32-bit floating point format (the version used is annotated in the sample_precision metadata element). It is assumed that all pixels are valid, unless marked with a NaN (Not a Number) value. The structure of the binary data is shown in Figure 1. Each row of the matrix is a single range line (often called a range profile by RADAR engineers) of the image with increasing range preceding from lower indices to higher indices (left to right in Figure 1). Early row indices in the matrix correspond to early pulses and later rows correspond to later pulses (top to bottom in Figure 1). It is important to recognise that image viewing software needs to take into account the matrix configuration as viewing the matrix as it is stored may result in the image being reflected in either dimension depending on right/left looking and ascending/descending. Figure 1: The Binary Representation of SLC images Shadows Down Some software algorithms prefer to process SLC imagery with increasing range aligned to increasing row index - often called shadows down orientation. This approach is usually used for fine resolution SAR imaging systems where it is important for target recognition to have a consistent shadow and layover alignment. It is often better for analysts to view SAR amplitude imagery shadows down as opposed to North-up because the human visual system prefers that orientation to properly interpret topography and elevated features. ICEYE provides SLC imagery shadows down by request. However, any image storage scheme can be manipulated on an image workstation to present images shadows down . HDF5 Container The SLC HDF5 container contains metadata associated with the collection in its header structure. The metadata is described in the Metadata section of this site . HDF and metadata tags can easily be found using a Python interpreter and the commands : import h5py f = h5py . File ( \"<filename.h5>\" ) for key in f . keys (): print ( f [ key ]) Sensor Independent Complex Data (SICD) This is a form of complex data that is carefully designed to remove any sensor-specific parameters. SICD image data is in the same format regardless of processing algorithm or collection strategy. In theory, any algorithm that uses SICD will work on SAR imagery from any SAR vendor. The SICD specification was developed by the US National Geospatial Intelligence Agency (NGA) and it is stored in the NITF (National Imagery Transmission Format[@nitf) container. For this reason, SICD files can only be used with GIS viewers and algorithms that know how to handle this type of dataset. Since NITF is not as well known as hdf5, the SICD product is currently only available from ICEYE by request. SLC in Context Figure 2 provides a useful summary of SLC images in the context of the processing options available with the red line highlighting the decisions made during product production. Figure 2: The Processing Steps and Implementation Considerations for ICEYE SLC images References European Space Agency. The sentinel application platform - snap. Accessed 2020 Dec 17. URL: http://step.esa.int/main/toolboxes/snap/ . \u21a9 The HDF Group. The hdf5 library & file format. Accessed 2020 Dec 17. URL: https://www.hdfgroup.org/solutions/hdf5/ . \u21a9","title":"Single Look Complex Image"},{"location":"productFormats/slc/#overview","text":"Single Look Complex (SLC) images have the highest fidelity of all SAR image products because they are only one step removed from the original RADAR collected data. They retain all the original sensor measurements and are free from interpolation artefacts or projection issues. A small concession is made with the default SLC product in that the dynamic range of the complex numbers is reduced to make image sizes more manageable. SLC products are the best source for SAR image analysis, but complex-image exploitation software is currently difficult to use without skill and experience. For this reason, SLC images are usually used for automated processing and advanced exploitation such as interferometric applications, or by users who prefer lower-level processing in order to implement their own processing chains. The SLC product can be orthorectified using both commercial and free specialized SAR software tools such as the European Space Agency (ESA) Sentinel Application Platform (SNAP) 1 .","title":"Overview"},{"location":"productFormats/slc/#geometry","text":"Scenes are stored in the satellite image acquisition geometry (AKA the slant plane ). The image coordinate system is centred on the zero-Doppler (time of closest approach) SAR coordinates and are arranged in the slant-range-by-azimuth imaging plane. The pixels are spaced equidistant in azimuth (according to the inverse of the pulse repetition frequency) and in slant range (according to the range sampling frequency). Each image pixel is stored with in-phase I and quadrature Q components and therefore, contains both amplitude and phase information.","title":"Geometry"},{"location":"productFormats/slc/#looks","text":"As the name suggests, SLC images have only a single look. This means they retain full resolution in azimuth and range. In most cases the impulse response function (the shape of a single, isolated radar-bright object in the radar image) is asymmetrical with azimuth resolution being smaller (finer) than range resolution.","title":"Looks"},{"location":"productFormats/slc/#binary-representation","text":"SLC images are stored as binary matrices in an HDF5 file container 2 . Real and imaginary components are stored separately, using either signed 16 bit integers or IEEE-754 single precision 32-bit floating point format (the version used is annotated in the sample_precision metadata element). It is assumed that all pixels are valid, unless marked with a NaN (Not a Number) value. The structure of the binary data is shown in Figure 1. Each row of the matrix is a single range line (often called a range profile by RADAR engineers) of the image with increasing range preceding from lower indices to higher indices (left to right in Figure 1). Early row indices in the matrix correspond to early pulses and later rows correspond to later pulses (top to bottom in Figure 1). It is important to recognise that image viewing software needs to take into account the matrix configuration as viewing the matrix as it is stored may result in the image being reflected in either dimension depending on right/left looking and ascending/descending. Figure 1: The Binary Representation of SLC images","title":"Binary Representation"},{"location":"productFormats/slc/#shadows-down","text":"Some software algorithms prefer to process SLC imagery with increasing range aligned to increasing row index - often called shadows down orientation. This approach is usually used for fine resolution SAR imaging systems where it is important for target recognition to have a consistent shadow and layover alignment. It is often better for analysts to view SAR amplitude imagery shadows down as opposed to North-up because the human visual system prefers that orientation to properly interpret topography and elevated features. ICEYE provides SLC imagery shadows down by request. However, any image storage scheme can be manipulated on an image workstation to present images shadows down .","title":"Shadows Down"},{"location":"productFormats/slc/#hdf5-container","text":"The SLC HDF5 container contains metadata associated with the collection in its header structure. The metadata is described in the Metadata section of this site . HDF and metadata tags can easily be found using a Python interpreter and the commands : import h5py f = h5py . File ( \"<filename.h5>\" ) for key in f . keys (): print ( f [ key ])","title":"HDF5 Container"},{"location":"productFormats/slc/#sensor-independent-complex-data-sicd","text":"This is a form of complex data that is carefully designed to remove any sensor-specific parameters. SICD image data is in the same format regardless of processing algorithm or collection strategy. In theory, any algorithm that uses SICD will work on SAR imagery from any SAR vendor. The SICD specification was developed by the US National Geospatial Intelligence Agency (NGA) and it is stored in the NITF (National Imagery Transmission Format[@nitf) container. For this reason, SICD files can only be used with GIS viewers and algorithms that know how to handle this type of dataset. Since NITF is not as well known as hdf5, the SICD product is currently only available from ICEYE by request.","title":"Sensor Independent Complex Data (SICD)"},{"location":"productFormats/slc/#slc-in-context","text":"Figure 2 provides a useful summary of SLC images in the context of the processing options available with the red line highlighting the decisions made during product production. Figure 2: The Processing Steps and Implementation Considerations for ICEYE SLC images","title":"SLC in Context"},{"location":"productFormats/slc/#references","text":"European Space Agency. The sentinel application platform - snap. Accessed 2020 Dec 17. URL: http://step.esa.int/main/toolboxes/snap/ . \u21a9 The HDF Group. The hdf5 library & file format. Accessed 2020 Dec 17. URL: https://www.hdfgroup.org/solutions/hdf5/ . \u21a9","title":"References"},{"location":"productguide/collectioncharacteristics/","text":"IMAGING COLLECTION CHARACTERISTICS The following provides additional technical information on the performance of the current ICEYE imaging modes. Our satellites are constantly being improved, but in order to manage expectations, in the tables below we provide the worst-case values across the fleet. Some parameters warrant a more detailed explanation which you can read in the Notes section. Table 2 provides parameters associated with ICEYE complex images and Table 3 provides the technical parameters associated with ICEYE Amplitude Images. Technical Overview PARAMETER STRIP SPOT SPOT EXTENDED AREA SCAN COMMENTS Product Short Name 'SM' 'SLH' 'SLEA' 'SC' Note 1 Radar Beams Used 1 1 1 4 Note 2 Nominal swath width [km] 30 5 15 100 Note 3 Nominal product length (Azimuth Direction) [km] 50 5 15 100 Note 4 Nominal collection duration [sec] 10 10 10 15 Maximum collection duration [sec] 35-75 N/A N/A 75 Note 5 Maximum Scene Length [km] 500 5 15 500 Note 5 Noise Equivalent Sigma-Zero [ dBm 2 /m 2 ] -21.5 to -20 -18 to -15 -18 to -15 -22.2 to -21.5 Note 6 Azimuth Ambiguity Ratio [dB] -17 -17 -17 -17 Range Ambiguity Ratio [dB] <-20 <-20 <-20 <-20 Geospatial Accuracy [m RMSE] 6 6 6 15 Note 14 ESA Copernicus Contributing Mission (CCM) Class 1 VHR2 VHR1 VHR1 HR1 Polarization VV VV VV VV RNIIRS 3.6 5.5 5.5 2.1 Note 8 RGIQE [bits/ \\(m^2\\) ] 0.8 22 8.4 0.1 Note 9 Performant Incidence Range [deg] 15-30 20-35 20-35 21-29 Note 12 Time Dominant Incidence Range [deg] 11-43 11-56 11-56 N/A Note 13 Table 1 : ICEYE Collections Technical Summary Complex Image Parameters PARAMETER STRIP SPOT COMMENTS Focusing plane Slant Plane Slant Plane Slant range resolution [m] 0.5 to 2.5 0.5 Note 7 Slant azimuth resolution [m] 3 0.25 Impulse response weighing function (peak side level) Uniform (-13.3dB) Uniform (-13.3dB) Slant Range Sample Spacing [m] 0.4 to 2.4 0.4 Note 7 Slant Azimuth Sample Spacing [m] 1.6 0.2 Slant range product format HDF5 + XML HDF5 + XML SLC Product Size [GB] 3.4 to 2.9 0.6 to 7.2 Dynamic Range (bits per pixel) 16(uint) 32(Float) 16(uint) 32(Float) Note 10 Table 2 : Parameters for ICEYE Complex Images Amplitude Image Parameters PARAMETER STRIP SPOT SCAN COMMENTS Ground Range Resolution [m] 3 1.5 to 0.9 < 15 Note 7 Ground Azimuth Resolution [m] 3 1 < 15 Impulse response weighing function (peak side level) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Ground Range Sample Spacing [m] 2.5 0.5 6 Ground Azimuth Sample Spacing [m] 2.5 0.5 6 Range Looks 1 1 to 2 1 Azimuth Looks 1 to 2 1 to 4 1 Product format Geotiff + XML Geotiff + XML Geotiff + XML GRD Product Size [MB] 700 250, 2250 800 Dynamic Range (bits per pixel) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) Note 12 Table 3 : Parameters for ICEYE Amplitude Images Notes and Explanations Short Name: For example, Strip mode has 'SM' : ICEYE_X7_GRD_ SM _36535_20201020T175609 Radar Beams: The current generation of ICEYE satellites use electronically steered elements to control multiple radar beams. Usually this is only one beam but Scan products use multiple beams to image different ranges (at the cost of reduced resolution) Nominal Swath Width: The actual image size will be slightly larger than this to guarantee that the tasked area is covered. Nominal Swath Length: The actual image length may be slightly larger to guarantee that the tasked area is covered. The maximum value can vary from satellite to satellite due to power/data/thermal limitations. Maximum Collection Duration/Length: Spot images do not have a maximum collection duration as they image for the required amount of time to obtain a tasked azimuth resolution. For Strip and Scan modes the maximum collection duration (and therefore the maximum image length) is limited by the amount of on-board memory storage or satellite thermal limitations. As different incidence angles have different slant range resolutions in order to provide the same ground range resolution, then the maximum collection duration is also a function of incidence angle. NESZ: The noise equivalent sigma zero values are taken at scene center for near and far range extents. Slant Range Resolution: For Strip mode the transmitted bandwidth is varied to make sure that the resolution on the ground remains the same. For Spot mode the maximum bandwidth is transmitted at all times. This means that the slant resolution for Spot images is constant and the ground resolution changes with indidence angle. RNIIRS: Radar National Imagery Interpretability Rating Scale is a subjective assessment of Radar Image Quality used primarily by military analysts. The scale is from 0 (\" interpretability of the imagery is precluded by obscuration, degradation, or very poor resolution \") to the highest quality figure of merit, 10 2 . RGIQE: This is the Radar General Image Quality Equation. It is an adaptation of the concept of a General Image Quality Equation 3 Developed by NGA . Unlike the RNIIRS scale which is a largely subjective assessment of image quality, the RGIQE uses maximum channel capacity (measured in bits of information) as a figure of merit. From the Shannon-Hartley Theorem 4 the maximum information that can be carried in a signal (conventionally called a channel due to the origins in communications) is given by : \\[ C = B \\log_2\\left(1+\\frac{S}{N}\\right) \\] Where \\(C\\) is measured in bits per second, \\(B\\) is the bandwidth of the system and \\(\\frac{S}{N}\\) is the signal to noise ratio. Recognising that a resolution cell in a SAR image is ultimately defined in range by the transmitted bandwidth and in azimuth by the Doppler bandwidth, a measure of the maximum information content of a resolution cell in bits/ \\(m^2\\) can be formulated : \\[ I = B_{az} B_{R_{ground}} \\log_2\\left(1 + \\frac{S}{N}\\right) \\] Where \\(I\\) is the information content measured in bits/ \\(m^2\\) , \\(B_{az}\\) is the Doppler bandwidth used to form the azimuth extent of a pixel and \\(B_{R_{ground}}\\) is the range bandwidth in the ground plane used to form the range extent of a pixel. The noise in this case is made up from all the noise elements that contribute to reduced image quality in the final image (Thermal noise, quantization noise, sidelobes, ambiguities). In this scale the higher the figure then the more 'information' is available for exploitation within the pixel. Complex Dynamic Range: A complex number with 16bit I and 16bit Q values. 32 bit float values can be provided by request. Amplitude Dynamic Range: Stored as an unsigned 16 bit integer. 32 bit float values can be provided by request. Performant Incidence Range: This is the nominal or standard range of incidence angles that the ICEYE Fleet operates over. The parameters in these tables are correct within this range of angles. Time Dominant Incidence Range: Being quite small and agile, and having an electronically steered antenna, ICEYE satellites can collect radar imagery from a wide range of angles. Outside of the Performant Incidence Range , SAR image quality may be degraded. However in some situations it may be more important to obtain a SAR image quickly rather than wait for an opportunity to image the location with the performant range of angles. For this reason ICEYE offers time dominant tasking as either a Tactical or a Custom order. Geospatial Accuracy: Each satellite in the ICEYE fleet is periodically evaluated against ground based calibration targets to obtain the geospatial accuracy of the system. This process involves measuring the location of each target in the SAR imagery after the image has been terrain corrected (see here for why this step is essential) and comparing the location to the known ground truth . Each calibration target will have its own slightly different error. The RMSE is the root mean square error of all the measured calibration points from all the satellites. References V. Amans B. Hoersch. Copernicus Space Component Data Access Portfolio: Data Warehouse 2014 - 2020. resolution classes for EO SAR Image products . ESRIN, ESA, Via Galileo Galilei Casella Postale 64 00044 Frascati Italy, March 2015. URL: https://spacedata.copernicus.eu/documents/20126/0/DAP_Release_Phase_2_1.0_final.pdf . \u21a9 National Geospatial-Intelligence Agency \\(NGA\\) . National imagery interoperability rating scale standards 2017-03-10 version 1.1.1. December 4 2019. URL: https://nsgreg.nga.mil/doc/view?i=5104 . \u21a9 Jon C Leachtenauer, William Malila, John Irvine, Linda Colburn, and Nanette Salvaggio. General image-quality equation: giqe. Applied optics , 36 \\(32\\) :8322\u20138328, 1997. \u21a9 Claude E Shannon. Communication in the presence of noise. Proceedings of the IEEE , 72 \\(9\\) :1192\u20131201, 1984. \u21a9","title":"Collection Characteristics"},{"location":"productguide/collectioncharacteristics/#imaging-collection-characteristics","text":"The following provides additional technical information on the performance of the current ICEYE imaging modes. Our satellites are constantly being improved, but in order to manage expectations, in the tables below we provide the worst-case values across the fleet. Some parameters warrant a more detailed explanation which you can read in the Notes section. Table 2 provides parameters associated with ICEYE complex images and Table 3 provides the technical parameters associated with ICEYE Amplitude Images.","title":"IMAGING COLLECTION CHARACTERISTICS"},{"location":"productguide/collectioncharacteristics/#technical-overview","text":"PARAMETER STRIP SPOT SPOT EXTENDED AREA SCAN COMMENTS Product Short Name 'SM' 'SLH' 'SLEA' 'SC' Note 1 Radar Beams Used 1 1 1 4 Note 2 Nominal swath width [km] 30 5 15 100 Note 3 Nominal product length (Azimuth Direction) [km] 50 5 15 100 Note 4 Nominal collection duration [sec] 10 10 10 15 Maximum collection duration [sec] 35-75 N/A N/A 75 Note 5 Maximum Scene Length [km] 500 5 15 500 Note 5 Noise Equivalent Sigma-Zero [ dBm 2 /m 2 ] -21.5 to -20 -18 to -15 -18 to -15 -22.2 to -21.5 Note 6 Azimuth Ambiguity Ratio [dB] -17 -17 -17 -17 Range Ambiguity Ratio [dB] <-20 <-20 <-20 <-20 Geospatial Accuracy [m RMSE] 6 6 6 15 Note 14 ESA Copernicus Contributing Mission (CCM) Class 1 VHR2 VHR1 VHR1 HR1 Polarization VV VV VV VV RNIIRS 3.6 5.5 5.5 2.1 Note 8 RGIQE [bits/ \\(m^2\\) ] 0.8 22 8.4 0.1 Note 9 Performant Incidence Range [deg] 15-30 20-35 20-35 21-29 Note 12 Time Dominant Incidence Range [deg] 11-43 11-56 11-56 N/A Note 13 Table 1 : ICEYE Collections Technical Summary","title":"Technical Overview"},{"location":"productguide/collectioncharacteristics/#complex-image-parameters","text":"PARAMETER STRIP SPOT COMMENTS Focusing plane Slant Plane Slant Plane Slant range resolution [m] 0.5 to 2.5 0.5 Note 7 Slant azimuth resolution [m] 3 0.25 Impulse response weighing function (peak side level) Uniform (-13.3dB) Uniform (-13.3dB) Slant Range Sample Spacing [m] 0.4 to 2.4 0.4 Note 7 Slant Azimuth Sample Spacing [m] 1.6 0.2 Slant range product format HDF5 + XML HDF5 + XML SLC Product Size [GB] 3.4 to 2.9 0.6 to 7.2 Dynamic Range (bits per pixel) 16(uint) 32(Float) 16(uint) 32(Float) Note 10 Table 2 : Parameters for ICEYE Complex Images","title":"Complex Image Parameters"},{"location":"productguide/collectioncharacteristics/#amplitude-image-parameters","text":"PARAMETER STRIP SPOT SCAN COMMENTS Ground Range Resolution [m] 3 1.5 to 0.9 < 15 Note 7 Ground Azimuth Resolution [m] 3 1 < 15 Impulse response weighing function (peak side level) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Taylor Weighting (-20dB) Ground Range Sample Spacing [m] 2.5 0.5 6 Ground Azimuth Sample Spacing [m] 2.5 0.5 6 Range Looks 1 1 to 2 1 Azimuth Looks 1 to 2 1 to 4 1 Product format Geotiff + XML Geotiff + XML Geotiff + XML GRD Product Size [MB] 700 250, 2250 800 Dynamic Range (bits per pixel) 16(uint) 32(Float) 16(uint) 32(Float) 16(uint) 32(Float) Note 12 Table 3 : Parameters for ICEYE Amplitude Images","title":"Amplitude Image Parameters"},{"location":"productguide/collectioncharacteristics/#notes-and-explanations","text":"Short Name: For example, Strip mode has 'SM' : ICEYE_X7_GRD_ SM _36535_20201020T175609 Radar Beams: The current generation of ICEYE satellites use electronically steered elements to control multiple radar beams. Usually this is only one beam but Scan products use multiple beams to image different ranges (at the cost of reduced resolution) Nominal Swath Width: The actual image size will be slightly larger than this to guarantee that the tasked area is covered. Nominal Swath Length: The actual image length may be slightly larger to guarantee that the tasked area is covered. The maximum value can vary from satellite to satellite due to power/data/thermal limitations. Maximum Collection Duration/Length: Spot images do not have a maximum collection duration as they image for the required amount of time to obtain a tasked azimuth resolution. For Strip and Scan modes the maximum collection duration (and therefore the maximum image length) is limited by the amount of on-board memory storage or satellite thermal limitations. As different incidence angles have different slant range resolutions in order to provide the same ground range resolution, then the maximum collection duration is also a function of incidence angle. NESZ: The noise equivalent sigma zero values are taken at scene center for near and far range extents. Slant Range Resolution: For Strip mode the transmitted bandwidth is varied to make sure that the resolution on the ground remains the same. For Spot mode the maximum bandwidth is transmitted at all times. This means that the slant resolution for Spot images is constant and the ground resolution changes with indidence angle. RNIIRS: Radar National Imagery Interpretability Rating Scale is a subjective assessment of Radar Image Quality used primarily by military analysts. The scale is from 0 (\" interpretability of the imagery is precluded by obscuration, degradation, or very poor resolution \") to the highest quality figure of merit, 10 2 . RGIQE: This is the Radar General Image Quality Equation. It is an adaptation of the concept of a General Image Quality Equation 3 Developed by NGA . Unlike the RNIIRS scale which is a largely subjective assessment of image quality, the RGIQE uses maximum channel capacity (measured in bits of information) as a figure of merit. From the Shannon-Hartley Theorem 4 the maximum information that can be carried in a signal (conventionally called a channel due to the origins in communications) is given by : \\[ C = B \\log_2\\left(1+\\frac{S}{N}\\right) \\] Where \\(C\\) is measured in bits per second, \\(B\\) is the bandwidth of the system and \\(\\frac{S}{N}\\) is the signal to noise ratio. Recognising that a resolution cell in a SAR image is ultimately defined in range by the transmitted bandwidth and in azimuth by the Doppler bandwidth, a measure of the maximum information content of a resolution cell in bits/ \\(m^2\\) can be formulated : \\[ I = B_{az} B_{R_{ground}} \\log_2\\left(1 + \\frac{S}{N}\\right) \\] Where \\(I\\) is the information content measured in bits/ \\(m^2\\) , \\(B_{az}\\) is the Doppler bandwidth used to form the azimuth extent of a pixel and \\(B_{R_{ground}}\\) is the range bandwidth in the ground plane used to form the range extent of a pixel. The noise in this case is made up from all the noise elements that contribute to reduced image quality in the final image (Thermal noise, quantization noise, sidelobes, ambiguities). In this scale the higher the figure then the more 'information' is available for exploitation within the pixel. Complex Dynamic Range: A complex number with 16bit I and 16bit Q values. 32 bit float values can be provided by request. Amplitude Dynamic Range: Stored as an unsigned 16 bit integer. 32 bit float values can be provided by request. Performant Incidence Range: This is the nominal or standard range of incidence angles that the ICEYE Fleet operates over. The parameters in these tables are correct within this range of angles. Time Dominant Incidence Range: Being quite small and agile, and having an electronically steered antenna, ICEYE satellites can collect radar imagery from a wide range of angles. Outside of the Performant Incidence Range , SAR image quality may be degraded. However in some situations it may be more important to obtain a SAR image quickly rather than wait for an opportunity to image the location with the performant range of angles. For this reason ICEYE offers time dominant tasking as either a Tactical or a Custom order. Geospatial Accuracy: Each satellite in the ICEYE fleet is periodically evaluated against ground based calibration targets to obtain the geospatial accuracy of the system. This process involves measuring the location of each target in the SAR imagery after the image has been terrain corrected (see here for why this step is essential) and comparing the location to the known ground truth . Each calibration target will have its own slightly different error. The RMSE is the root mean square error of all the measured calibration points from all the satellites.","title":"Notes and Explanations"},{"location":"productguide/collectioncharacteristics/#references","text":"V. Amans B. Hoersch. Copernicus Space Component Data Access Portfolio: Data Warehouse 2014 - 2020. resolution classes for EO SAR Image products . ESRIN, ESA, Via Galileo Galilei Casella Postale 64 00044 Frascati Italy, March 2015. URL: https://spacedata.copernicus.eu/documents/20126/0/DAP_Release_Phase_2_1.0_final.pdf . \u21a9 National Geospatial-Intelligence Agency \\(NGA\\) . National imagery interoperability rating scale standards 2017-03-10 version 1.1.1. December 4 2019. URL: https://nsgreg.nga.mil/doc/view?i=5104 . \u21a9 Jon C Leachtenauer, William Malila, John Irvine, Linda Colburn, and Nanette Salvaggio. General image-quality equation: giqe. Applied optics , 36 \\(32\\) :8322\u20138328, 1997. \u21a9 Claude E Shannon. Communication in the presence of noise. Proceedings of the IEEE , 72 \\(9\\) :1192\u20131201, 1984. \u21a9","title":"References"},{"location":"productguide/dataformats/","text":"PRODUCT FORMATS Geocoding Information in ICEYE Images To enable easy and fast geolocation, a processed form of the geometry model called rational polynomial coefficients (RPCs) is provided for each image. RPCs link image locations to ground locations via simple equations that enable rapid calculations. In addition to ease and speed, RPC coefficients have the further advantage of being sensor independent. The structure of the RPC equations is always the same. For this reason, RPC exploitation code does not have to change to accommodate different sensors. In fact, both optical and SAR sensors are modeled by the same RPC structure. Exploitation code that performs geolocation for images from optical sensors can actually be used to derive ground locations from the RPC data included with ICEYE complex and amplitude images. This process is now commonplace in most geospatial viewers (we recommend using QGIS 1 and it is freely available for analysts and software developers.) Info Image geolocation of any mono image, optical or SAR, requires that an elevation model be used during exploitation. This is true for the physics-based equations and RPCs. Single Look Complex (SLC) Product These are full-resolution, single-look images of the focused SAR signals. Scenes are stored in the satellite\u2019s native image acquisition geometry, which is the slant-range-by-azimuth imaging plane. As shown in the green surface in Figure 2, the pixels are aligned perpendicular to the sensor flight track (The pixels have zero-Doppler SAR coordinates}). They are spaced equidistant in azimuth and in slant range. Each pixel contains both amplitude and phase information as represented by a complex magnitude value with in-phase and quadrature components (I & Q). Figure 2: Slant range and ground range image geometry SLC products are suitable for applications that rely on phase information or require the full image resolution. Because SLC images are in the native sensor orientation, there are no radiometric artefacts induced by the spatial resampling applied to map projection images. The range-azimuth orientation also enables further geometric manipulation, like orthorectification. Ortho versions can be produced using both commercial and free software tools, such as the European\u2019s Space Agency\u2019s Sentinel Application Platform (ESA SNAP S1TBX 2 ). The SLC product is particularly useful for those analysts who require multiple collections with matching phase data for applications like Coherent Change Detection (CCD). SLC images are typically used by scientists and organisations with advanced SAR expertise, but complex images will become core products for numerous users once SAR applications become more user-friendly. Amplitude Image Note When mapping an image from the slant plane to the ground, the average elevation of the scene is applied to the ellipsoid used in the projection. These are viewable forms of SAR data used for analyst exploitation; the pixels have brightness values but no phase data. Amplitude images are multi-looked to reduce the salt-and-pepper effect of speckle. The images are also projected from the slant plane onto an ellipsoid model of the ground surface (See Figure 2). The resulting product has approximately square spatial resolution and equal pixel spacing. It also has reduced speckle, due to the multi-look processing. Figure 3 illustrates slant range and ground range projections of amplitude pixels. The pixel's dimensions are equal in range and azimuth in the ground projection on the right. As with SLC images, sensor-oriented amplitude images maintain the native sensor geometry of range and azimuth and no image rotation to a map coordinate system has been performed. This avoids interpolation artefacts and it supports image stacking for change detection applications and physics-based, rigorous geolocation. ICEYE images can be viewed using open standard GIS readers such as QGIS 1 . We do not orthorectify our amplitude images or project them to an ellipsoid-based map projection, but we provide information, which can be quickly applied by users to their ICEYE imagery using freeware software, available on the market. This lowers the cost to our customers and ensures that they are always aware of the provenance of the elevation data used to project the image pixels to the topographic surface. This software is described in our Imagery Product Format Specification Document 3 . Figure 3: Slant range and ground range images ICEYE Image Formats ICEYE SLC products are stored and delivered in the HDF5 format, which is particularly suitable for storing binary complex SAR data channels and annotated metadata. Amplitude images are produced as GeoTiff files. These are readable by common GIS software tools. Additionally, both SLC and Amplitude products are accompanied by XML metadata files. This enables quick screening of products without the use of specialized software. A detailed description of the format of SLC data and amplitude images is given in the ICEYE Product Format Specification Document, which is available on the ICEYE website 3 . Complex Amplitude Quicklook Strip HDF5,XML GeoTiff,XML PNG,KML Spot HDF5,XML GeoTiff,XML PNG,KML Scan - GeoTiff,XML PNG,KML References QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/ . \u21a9 \u21a9 European Space Agency. The sentinel application platform - snap. Accessed 2020 Dec 17. URL: http://step.esa.int/main/toolboxes/snap/ . \u21a9 ICEYE Level 1 Product Format Specification Document. URL: https://www.iceye.com/sar-data/documents/ . \u21a9 \u21a9","title":"PRODUCT FORMATS"},{"location":"productguide/dataformats/#product-formats","text":"","title":"PRODUCT FORMATS"},{"location":"productguide/dataformats/#geocoding-information-in-iceye-images","text":"To enable easy and fast geolocation, a processed form of the geometry model called rational polynomial coefficients (RPCs) is provided for each image. RPCs link image locations to ground locations via simple equations that enable rapid calculations. In addition to ease and speed, RPC coefficients have the further advantage of being sensor independent. The structure of the RPC equations is always the same. For this reason, RPC exploitation code does not have to change to accommodate different sensors. In fact, both optical and SAR sensors are modeled by the same RPC structure. Exploitation code that performs geolocation for images from optical sensors can actually be used to derive ground locations from the RPC data included with ICEYE complex and amplitude images. This process is now commonplace in most geospatial viewers (we recommend using QGIS 1 and it is freely available for analysts and software developers.) Info Image geolocation of any mono image, optical or SAR, requires that an elevation model be used during exploitation. This is true for the physics-based equations and RPCs.","title":"Geocoding Information in ICEYE Images"},{"location":"productguide/dataformats/#single-look-complex-slc-product","text":"These are full-resolution, single-look images of the focused SAR signals. Scenes are stored in the satellite\u2019s native image acquisition geometry, which is the slant-range-by-azimuth imaging plane. As shown in the green surface in Figure 2, the pixels are aligned perpendicular to the sensor flight track (The pixels have zero-Doppler SAR coordinates}). They are spaced equidistant in azimuth and in slant range. Each pixel contains both amplitude and phase information as represented by a complex magnitude value with in-phase and quadrature components (I & Q). Figure 2: Slant range and ground range image geometry SLC products are suitable for applications that rely on phase information or require the full image resolution. Because SLC images are in the native sensor orientation, there are no radiometric artefacts induced by the spatial resampling applied to map projection images. The range-azimuth orientation also enables further geometric manipulation, like orthorectification. Ortho versions can be produced using both commercial and free software tools, such as the European\u2019s Space Agency\u2019s Sentinel Application Platform (ESA SNAP S1TBX 2 ). The SLC product is particularly useful for those analysts who require multiple collections with matching phase data for applications like Coherent Change Detection (CCD). SLC images are typically used by scientists and organisations with advanced SAR expertise, but complex images will become core products for numerous users once SAR applications become more user-friendly.","title":"Single Look Complex (SLC) Product"},{"location":"productguide/dataformats/#amplitude-image","text":"Note When mapping an image from the slant plane to the ground, the average elevation of the scene is applied to the ellipsoid used in the projection. These are viewable forms of SAR data used for analyst exploitation; the pixels have brightness values but no phase data. Amplitude images are multi-looked to reduce the salt-and-pepper effect of speckle. The images are also projected from the slant plane onto an ellipsoid model of the ground surface (See Figure 2). The resulting product has approximately square spatial resolution and equal pixel spacing. It also has reduced speckle, due to the multi-look processing. Figure 3 illustrates slant range and ground range projections of amplitude pixels. The pixel's dimensions are equal in range and azimuth in the ground projection on the right. As with SLC images, sensor-oriented amplitude images maintain the native sensor geometry of range and azimuth and no image rotation to a map coordinate system has been performed. This avoids interpolation artefacts and it supports image stacking for change detection applications and physics-based, rigorous geolocation. ICEYE images can be viewed using open standard GIS readers such as QGIS 1 . We do not orthorectify our amplitude images or project them to an ellipsoid-based map projection, but we provide information, which can be quickly applied by users to their ICEYE imagery using freeware software, available on the market. This lowers the cost to our customers and ensures that they are always aware of the provenance of the elevation data used to project the image pixels to the topographic surface. This software is described in our Imagery Product Format Specification Document 3 . Figure 3: Slant range and ground range images","title":"Amplitude Image"},{"location":"productguide/dataformats/#iceye-image-formats","text":"ICEYE SLC products are stored and delivered in the HDF5 format, which is particularly suitable for storing binary complex SAR data channels and annotated metadata. Amplitude images are produced as GeoTiff files. These are readable by common GIS software tools. Additionally, both SLC and Amplitude products are accompanied by XML metadata files. This enables quick screening of products without the use of specialized software. A detailed description of the format of SLC data and amplitude images is given in the ICEYE Product Format Specification Document, which is available on the ICEYE website 3 . Complex Amplitude Quicklook Strip HDF5,XML GeoTiff,XML PNG,KML Spot HDF5,XML GeoTiff,XML PNG,KML Scan - GeoTiff,XML PNG,KML","title":"ICEYE Image Formats"},{"location":"productguide/dataformats/#references","text":"QGIS - A Free and Open Geographic Information System. Accessed 2020 Dec 17. URL: https://qgis.org/en/site/ . \u21a9 \u21a9 European Space Agency. The sentinel application platform - snap. Accessed 2020 Dec 17. URL: http://step.esa.int/main/toolboxes/snap/ . \u21a9 ICEYE Level 1 Product Format Specification Document. URL: https://www.iceye.com/sar-data/documents/ . \u21a9 \u21a9","title":"References"},{"location":"productguide/fleet/","text":"THE ICEYE FLEET The ICEYE global imaging service uses an innovative satellite and sensor design based on advancements in small satellite technologies and an adaptable New Space approach. The ICEYE constellation is constantly evolving and it is optimized for persistent monitoring with fast and repeatable access to any location on Earth. Our flexible collection supports high resolution imaging over small areas as well as reduced resolution scans of wide areas. Our goal is to provide global access from a fleet of satellites, each in a coherent daily ground track repeat orbit ( CD-GTR ). This means that any location can be imaged multiple times from nearly the same orbital location using the same imaging geometry. The repeat cycle for these coherent collections is 24 hours or less. During the coming year our global coherent imaging plan will be implemented as we move more satellites into their allocated repeating ground tracks. Figure 1: ICEYE Generation 2 Satellite SAR Sensor Parameters The ICEYE sensors are X-band radars, each with an active phased array antenna and electronic beam steering. The innate mechanical agility of these low-mass satellites and their electronic steering enable fast and precise pointing of radar pulses to the ground. The satellites can also image to the right or left side of the satellite track. Technical parameters of the current sensors are listed in Table 1. SENSOR PARAMETER SPECIFICATION Carrier frequency 9.65 GHz (X-band) Antenna size 3.2 meters (along-track) x 0.4 meters PRF 2-7 kHz Look direction both LEFT and RIGHT Range Bandwidth 37.6-299 MHz Peak Radiated Power 3.2 kW Polarization VV Incidence angle range 15-35 (mode dependent) Mass 92 kg Communication [radar payload data downlink] X-band 140 Mbits/s Table 1: ICEYE Generation 2 satellite system parameters Orbits At present, ICEYE satellites are all in sun-synchronous orbits with 15 orbits per day, but the orbits are not uniformly spaced. This means that the time to revisit a location on the equator varies over a period of days. The mean revisit rate at the equator is 20 hours and the mean time to access a location on the equator is 12 hours. At higher and lower latitudes, the rates are more frequent. Table 2 lists the orbital parameters of the current SAR instruments. Their ground track repeat cycles vary between 1 and 22 days. Each orbital plane is phased around the Earth with a different local time of the ascending node (LTAN) so that the overall constellation can observe a location at different times of the day. This has an advantage over dawn-dusk sun-synchronous orbits, in which the local time of collection is always close to sunrise or sunset. Orbit Parameters Nominal Altitude 560 to 580 km Orbit Parameters Value Inclination 97.7\u00b0 (sun-synchronous) Orbits / Day 15 Ground track repeat 1 - 22 days Constellation mean revisit at equator 20 hours Constellation mean time to access at equator 12 hours Orbit maintenance Ion Propulsion Table 2: Constellation Parameters Each satellite has the ability to slowly adjust its orbits throughout its operating life. The adjustment is usually performed in the orbital plane by raising or lowering the satellite's altitude. This changes the orbital period, which in turn changes the ground track repeat period. As the fleet grows it will gradually be adjusted into one-day repeating coherent ground tracks. This provides novel opportunities to combine identical data collections of the same area whilst maintaining rapid access times. Figure 2: Daily Coherent Ground Track Repeat (GTR) imagery reveals unprecedented levels of intelligence such as the flow rate of The Muldrow Glacier USA between 16th and 30th April 2021. The satellite orbital agility is provided via a set of ion thrusters positioned around the satellite. These provide a near limitless supply of manoeuvring thrust, and also ensure that the constellation can be rapidly configured to increase the coverage rate of certain geographic regions in response to world events. The location of each ICEYE satellite is publicly available. The current configuration of the constellation can be found using one of the excellent online orbital elements tools such as celestrak 2 or n2yo 1 , which provide a live view of the current ICEYE constellation. References N2YO. Accessed 2020 Dec 17. URL: https://www.n2yo.com/ . \u21a9 T.S. Kelso. Celstrak. 1985. Accessed 2020 Dec 17. URL: http://www.celestrak.com . \u21a9","title":"The ICEYE Fleet"},{"location":"productguide/fleet/#the-iceye-fleet","text":"The ICEYE global imaging service uses an innovative satellite and sensor design based on advancements in small satellite technologies and an adaptable New Space approach. The ICEYE constellation is constantly evolving and it is optimized for persistent monitoring with fast and repeatable access to any location on Earth. Our flexible collection supports high resolution imaging over small areas as well as reduced resolution scans of wide areas. Our goal is to provide global access from a fleet of satellites, each in a coherent daily ground track repeat orbit ( CD-GTR ). This means that any location can be imaged multiple times from nearly the same orbital location using the same imaging geometry. The repeat cycle for these coherent collections is 24 hours or less. During the coming year our global coherent imaging plan will be implemented as we move more satellites into their allocated repeating ground tracks. Figure 1: ICEYE Generation 2 Satellite","title":"THE ICEYE FLEET"},{"location":"productguide/fleet/#sar-sensor-parameters","text":"The ICEYE sensors are X-band radars, each with an active phased array antenna and electronic beam steering. The innate mechanical agility of these low-mass satellites and their electronic steering enable fast and precise pointing of radar pulses to the ground. The satellites can also image to the right or left side of the satellite track. Technical parameters of the current sensors are listed in Table 1. SENSOR PARAMETER SPECIFICATION Carrier frequency 9.65 GHz (X-band) Antenna size 3.2 meters (along-track) x 0.4 meters PRF 2-7 kHz Look direction both LEFT and RIGHT Range Bandwidth 37.6-299 MHz Peak Radiated Power 3.2 kW Polarization VV Incidence angle range 15-35 (mode dependent) Mass 92 kg Communication [radar payload data downlink] X-band 140 Mbits/s Table 1: ICEYE Generation 2 satellite system parameters","title":"SAR Sensor Parameters"},{"location":"productguide/fleet/#orbits","text":"At present, ICEYE satellites are all in sun-synchronous orbits with 15 orbits per day, but the orbits are not uniformly spaced. This means that the time to revisit a location on the equator varies over a period of days. The mean revisit rate at the equator is 20 hours and the mean time to access a location on the equator is 12 hours. At higher and lower latitudes, the rates are more frequent. Table 2 lists the orbital parameters of the current SAR instruments. Their ground track repeat cycles vary between 1 and 22 days. Each orbital plane is phased around the Earth with a different local time of the ascending node (LTAN) so that the overall constellation can observe a location at different times of the day. This has an advantage over dawn-dusk sun-synchronous orbits, in which the local time of collection is always close to sunrise or sunset. Orbit Parameters Nominal Altitude 560 to 580 km Orbit Parameters Value Inclination 97.7\u00b0 (sun-synchronous) Orbits / Day 15 Ground track repeat 1 - 22 days Constellation mean revisit at equator 20 hours Constellation mean time to access at equator 12 hours Orbit maintenance Ion Propulsion Table 2: Constellation Parameters Each satellite has the ability to slowly adjust its orbits throughout its operating life. The adjustment is usually performed in the orbital plane by raising or lowering the satellite's altitude. This changes the orbital period, which in turn changes the ground track repeat period. As the fleet grows it will gradually be adjusted into one-day repeating coherent ground tracks. This provides novel opportunities to combine identical data collections of the same area whilst maintaining rapid access times. Figure 2: Daily Coherent Ground Track Repeat (GTR) imagery reveals unprecedented levels of intelligence such as the flow rate of The Muldrow Glacier USA between 16th and 30th April 2021. The satellite orbital agility is provided via a set of ion thrusters positioned around the satellite. These provide a near limitless supply of manoeuvring thrust, and also ensure that the constellation can be rapidly configured to increase the coverage rate of certain geographic regions in response to world events. The location of each ICEYE satellite is publicly available. The current configuration of the constellation can be found using one of the excellent online orbital elements tools such as celestrak 2 or n2yo 1 , which provide a live view of the current ICEYE constellation.","title":"Orbits"},{"location":"productguide/fleet/#references","text":"N2YO. Accessed 2020 Dec 17. URL: https://www.n2yo.com/ . \u21a9 T.S. Kelso. Celstrak. 1985. Accessed 2020 Dec 17. URL: http://www.celestrak.com . \u21a9","title":"References"},{"location":"productguide/ordering/","text":"Ordering ICEYE Products ICEYE offers timely and reliable global SAR imaging. This section describes the tasking process for new ICEYE collections and how to order archived imagery from ICEYE\u2019s catalog. The type of SAR collections available to order are described in ICEYE Products . ICEYE Tasking To make things easier for our customers we have a simple tasking process for new images based on standard imaging configurations and simple time windows ( Standard Orders ). This provides you with the quickest and simplest way to order SAR imagery. More sophisticated requests can be placed using a Custom Order . Standard Orders ICEYE Tasking Standard Orders are based on the concept of acquisition time windows . When placing an order, you can specify a list of timing requirements that define one or more time windows in which the desired images should be acquired. This allows ICEYE to confirm that the images will be acquired during the specified time windows, without the need for you to review a preliminary feasibility study with exact acquisition times. Figure 1: Example of a single image order with an acquisition time window of 2 days. This order specifies that the image should be collected anytime between 4-October-2021 00:00 and 6-October-2021 00:00 Figure 2: Example of an order for a stack of images with a repeat cycle of 20 days and an acquisition time window for each image of 14 days. For existing customer, standard orders are submitted via email. To order, please fill out the Standard Order Form with your contact information, and be sure to specify all the required tasking options described in the paragraphs below. Once completed, please send your Standard Order Form and the optional AOI file to the COSP email address you were provided with during your account set up. New customers should complete this form on the ICEYE website . There may be a slight delay while your account is set up but after that you will be able to order data using the instructions on this page. Info The order form will be provided by COSP. If you need a new one please contact the COSP team using the information that you were provided with when your account was set up or contact the sales team Figure 3: Standard ICEYE Tasking order flow The named recipients for that order will be notified via email once the order is received by the ICEYE Customer Operations and Satellite Planning (COSP) team. Once received, your order will be ingested into the ICEYE's planning system which will determine if the order can be confirmed within the area of interest (AOI), and time windows that you have requested for the AOI. If the order can be fulfilled , you will be notified via email that your order has been accepted and the images will be scheduled for acquisition. Alternatives are provided if available. If the order cannot be fulfilled within the time constraints that you specified, you will be notified via email that your order cannot be completed. Please note that standard orders require no final confirmation from you. If your order is accepted, the images will be acquired and delivered to you. After an order is confirmed, ICEYE will make sure that your images are acquired, downlinked, processed, quality controlled and delivered to you. The exact acquisition times are determined by the acquisition time window that you chose when placing your order. How to fill in a standard order form When placing a Standard Order you will need to specify and/or select from the following options available in the Imagery Order Form : AOI : The Area of Interest in the form of a latitude/longitude pair in the WGS 84 coordinate system. Alternatively, you can include a KML/KMZ, or geojson file as an attachment to your order. Acquisition type : Select whether you want a Single acquisition of the specified AOI Stack of images of the same AOI over a time period Timing information : Start and End time for the order : This is the time range in which the order is valid. Acquisition time windows : Choose a time window according to the precision that you require for each of the images that should be acquired. Basic: Each image is acquired within a 14-day time window from your specified order start time and repeat cycle. This time window is ideal for non-time-critical monitoring applications that do not require precise acquisition times. Pro: Each image is acquired within a 2-day time window from your specified order start time and repeat cycle. This is our base level service, commonly used in applications that do not depend on exact acquisition times or geometries. Exact: Each image is acquired within a 2-hour time window from your specified order start time and repeat cycle. This is our premium service, tailored for time-critical collections that do not require a precise imaging geometry. Note that for Exact time windows, you can optionally include an attachment with your desired exact acquisition times. This attachment can be the result of a feasibility study that you had previously requested or it can be generated directly by you using our published satellite ephemerides. Please see the section Optional Feasibility Studies below. Repeat cycle : This is the time between the start of consecutive acquisition time windows. This information is only required for orders of image stacks (repeat acquisitions). Imaging Mode : Refer to Section Types of SAR Collection for more information on these imaging modes Strip Spot Spot Extended Area Scan Feasibility Study as Part of a Standard Order ICEYE customers can request a feasibility study at any time when considering placing a standard order request. Simply email the COSP team at the address your were given when your account was set up. You will need to provide an AOI, an imaging mode (or resolution), a time period and any possible additional instructions that you may require. The ICEYE Customer Operations and Satellite Planning Team will respond with a list of acquisition opportunities. Please note that Feasibility Studies are for informational purposes and do not reserve constellation capacity for the opportunities reported. The required constellation capacity to fulfill an order under the agreed time window is only reserved after ICEYE confirms an order . Please also note that feasibility studies are not required to place a standard order. You can eliminate the need for a feasibility study by accurately describing the time windows and other acquisition constraints that match your actual needs as part of your standard order. Figure 4: Feasibility studies can be requested before placing a standard order. Sometimes you might like to perform your own feasibility studies and we encourage this. We have made sure our satellite ephemeris information is publicly available at celestrak [^1] and n2yo.com [^2], and have provided step by step instructions on how to use the Swath Acquisition Viewer Software, SaVoir on the ICEYE website . Let us know how well this works for you. Custom Orders Custom Tasking orders offer a higher level of flexibility when specifying tasking requirements you desire. In general, any options that are not available as part of standard order can be requested as part of a custom order. Custom orders are initiated by submitting a Custom Order Form to the email address you received when your account was set up. Our tasking experts will study the feasibility of your request and will quote an acquisition plan for you to approve. New customers should contact the ICEYE sales team . The following are examples of options that are currently available as part of a custom order: Mosaics : Coverage of large areas by acquiring multiple images Custom AOI coverage requirements : Each acquired image must cover at least a minimum percentage of the area of interest. Local time deviation limits : Images belonging to a stack or mosaic collection should be acquired within a certain local time range. Long image size requirements : Images that exceed the standard frame size of the requested imaging mode to cover the desired AOI. For example, long Strip acquisitions. Azimuth angle deviation limits for stacks or mosaics : Images belonging to a stack or mosaic collection should be acquired within a certain azimuth angle range. Custom acquisition time windows not available as standard tasking options : For example 72-hour, or 96-hour time windows for each acquisition. Our tasking experts will be happy to try to accommodate any special tasking request that is required to meet your business needs. Figure 5: Custom ICEYE Tasking order flow. Quality Control and Image Delivery Automatic delivery All acquisition SAR data initially goes though an automated quick Quality Control process in which we ensure that it covers the intended target location. The data is then automatically and immediately delivered to your folder in the ICEYE SFTP server. This gives you access to the SAR data without delay. Quality Control In addition to the automated quick Quality Control mentioned above, a detailed manual Quality Control is performed on all acquisition data. An ICEYE analyst will verify the acquired SAR Data conforms to the product specifications and that it does not contain any disqualifying ambiguities. Redelivery (if required) If defects are found during the detailed manual Quality Control steps, ICEYE will attempt to correct and redeliver the data to your SFTP folder as soon as possible. The most common type of defects that are detected and corrected in during Quality Control are geolocation inaccuracies. When performing Quality Control, sometimes ICEYE will have access to more refined satellite telemetry and orbit information that allows us to improve the geolocation accuracy. In such cases, the SAR data will be reprocessed to improve its geolocation accuracy and will be redelivered to you. Delivery service level Automatic delivery, quality control and redelivery (if required) will be completed within 8 hours of the data being acquired. ICEYE will soon offer faster delivery times for customers that require near-real-time data. New customers receive instructions from the Customer Operations and Satellite Planning team on how to access your SFTP account. Through the SFTP server, you will have access to download all of your SAR data. You will receive a notification (via email) every time a new acquisition has passed our detailed Quality Control process and the final version of the data is ready for you to download using your SFTP account. Info Images are stored in your SFTP account for a period of 30 days. Unforeseen Circumstances In very rare situations, it might not be possible to acquire an image within the agreed time window. In this case, the Customer Operations and Satellite Planning team will immediately inform you and will propose an extended acquisition time window or allow you to cancel the collection. ICEYE Archive Imagery As an ICEYE customer, you have access to a complete catalog of archive imagery that is available for ordering. This catalog is updated on a regular basis on your SFTP account. The catalog is available in kmz and geojson formats and it includes low resolution image thumbnails so you can get a feel for the content of the image. The archive catalog can be viewed in Google Earth, QGIS or your favorite GIS where you can browse image locations, filter by time or different image metadata and perform advanced searches. Please note that imagery is included in the ICEYE Archive Catalog at least seven days after its acquisition time. Figure 6: Browsing the ICEYE Archive catalog in Google Earth (kmz format). Figure 7: Browsing the ICEYE Archive catalog in QGIS (geojson format). Archive imagery orders can be submitted via email. To place an order, please fill out either the Standard Order Form or the Custom Order Form with your contact information, and include a list of the product names for the scenes that you wish to purchase. An example of a product name that identifies an image scene is : ICEYE_ARCHIVE_SM_10306_20190918T125047 Once an order is received, the ICEYE Customer Success team will deliver the requested images to you within 12 hours (assuming a realistic number of archive images. eg. less than 50). Please note that all orders for archive imagery require no final confirmation from you. The images that you request in your order will be delivered to you. Figure 8: Archive imagery order flow. Please note that orders for archive imagery do not go through additional quality control. However, if you are not satisfied with the quality of an archive image that you have received, you can make use of our return policy described below. Order Cancellation In order to support your evolving business requirements, ICEYE supports a user-friendly order cancellation policy. Cancellation of Tasking Orders Standard Tasking orders confirmed by ICEYE can be cancelled free of charge up to 72 hours prior to the start of the acquisition time window. Custom Tasking orders may be cancelled or rescheduled within twenty four (24) hours after order confirmation at no cost, as long as the order is submitted at least 72 hours before the proposed data collection time. Cancellation policy conditions are presented in the table below. CANCELLATION REQUEST TIME (HOURS) ADDITIONAL CONDITION CANCELLATION CHARGE Within 24 of order confirmation of a Custom Order Order submitted >72h before the acquisition acquisition time window Free of charge More than 72h prior to the start of the acquisition time window N/A Free of charge 72 - 48h prior to the start of the acquisition time window N/A 10% of the image value 48 - 24h prior to the start of the acquisition time window N/A 20% of the image value Less than 24h prior to the start of the acquisition time window Order submitted >24h before the start of the acquisition time window 100% of the image value Table 1: Cancellation Requests. Return Policy If you are not satisfied with your purchase, please contact our Customer Operations and Satellite Planning team at customer@iceye.com within 30 days of receiving your order. Your satisfaction is our priority, so we will work quickly to resolve your concerns. Invoicing ICEYE users can pay for imaging in a range of different ways in order to be as flexible as possible: Prepayment : In this option a number of images can be paid for up-front. When the prepayment has been paid, you can place orders and receive the amount of data up to your prepaid quota. This is designed for customers that know that they would like to purchase a number of images and offers imagery at a reduced rate. Net 30 : This is designed for larger or industrial customers wishing to purchase imagery in volume. In this case we will discuss your needs and enter into a contract with you. Images can then be tasked as and when you see fit and we will invoice you monthly. Payment then has to be made within 30 days of sending you the invoice. ICEYE Finance will send invoices during the first week of the month for all the products delivered to you within the previous month. The monthly invoice will not include the products that have been ordered but have not yet been delivered to you. If no products have been shipped to you during the previous month, invoice will not be extended.","title":"Ordering data"},{"location":"productguide/ordering/#ordering-iceye-products","text":"ICEYE offers timely and reliable global SAR imaging. This section describes the tasking process for new ICEYE collections and how to order archived imagery from ICEYE\u2019s catalog. The type of SAR collections available to order are described in ICEYE Products .","title":"Ordering ICEYE Products"},{"location":"productguide/ordering/#iceye-tasking","text":"To make things easier for our customers we have a simple tasking process for new images based on standard imaging configurations and simple time windows ( Standard Orders ). This provides you with the quickest and simplest way to order SAR imagery. More sophisticated requests can be placed using a Custom Order .","title":"ICEYE Tasking"},{"location":"productguide/ordering/#standard-orders","text":"ICEYE Tasking Standard Orders are based on the concept of acquisition time windows . When placing an order, you can specify a list of timing requirements that define one or more time windows in which the desired images should be acquired. This allows ICEYE to confirm that the images will be acquired during the specified time windows, without the need for you to review a preliminary feasibility study with exact acquisition times. Figure 1: Example of a single image order with an acquisition time window of 2 days. This order specifies that the image should be collected anytime between 4-October-2021 00:00 and 6-October-2021 00:00 Figure 2: Example of an order for a stack of images with a repeat cycle of 20 days and an acquisition time window for each image of 14 days. For existing customer, standard orders are submitted via email. To order, please fill out the Standard Order Form with your contact information, and be sure to specify all the required tasking options described in the paragraphs below. Once completed, please send your Standard Order Form and the optional AOI file to the COSP email address you were provided with during your account set up. New customers should complete this form on the ICEYE website . There may be a slight delay while your account is set up but after that you will be able to order data using the instructions on this page. Info The order form will be provided by COSP. If you need a new one please contact the COSP team using the information that you were provided with when your account was set up or contact the sales team Figure 3: Standard ICEYE Tasking order flow The named recipients for that order will be notified via email once the order is received by the ICEYE Customer Operations and Satellite Planning (COSP) team. Once received, your order will be ingested into the ICEYE's planning system which will determine if the order can be confirmed within the area of interest (AOI), and time windows that you have requested for the AOI. If the order can be fulfilled , you will be notified via email that your order has been accepted and the images will be scheduled for acquisition. Alternatives are provided if available. If the order cannot be fulfilled within the time constraints that you specified, you will be notified via email that your order cannot be completed. Please note that standard orders require no final confirmation from you. If your order is accepted, the images will be acquired and delivered to you. After an order is confirmed, ICEYE will make sure that your images are acquired, downlinked, processed, quality controlled and delivered to you. The exact acquisition times are determined by the acquisition time window that you chose when placing your order.","title":"Standard Orders"},{"location":"productguide/ordering/#how-to-fill-in-a-standard-order-form","text":"When placing a Standard Order you will need to specify and/or select from the following options available in the Imagery Order Form : AOI : The Area of Interest in the form of a latitude/longitude pair in the WGS 84 coordinate system. Alternatively, you can include a KML/KMZ, or geojson file as an attachment to your order. Acquisition type : Select whether you want a Single acquisition of the specified AOI Stack of images of the same AOI over a time period Timing information : Start and End time for the order : This is the time range in which the order is valid. Acquisition time windows : Choose a time window according to the precision that you require for each of the images that should be acquired. Basic: Each image is acquired within a 14-day time window from your specified order start time and repeat cycle. This time window is ideal for non-time-critical monitoring applications that do not require precise acquisition times. Pro: Each image is acquired within a 2-day time window from your specified order start time and repeat cycle. This is our base level service, commonly used in applications that do not depend on exact acquisition times or geometries. Exact: Each image is acquired within a 2-hour time window from your specified order start time and repeat cycle. This is our premium service, tailored for time-critical collections that do not require a precise imaging geometry. Note that for Exact time windows, you can optionally include an attachment with your desired exact acquisition times. This attachment can be the result of a feasibility study that you had previously requested or it can be generated directly by you using our published satellite ephemerides. Please see the section Optional Feasibility Studies below. Repeat cycle : This is the time between the start of consecutive acquisition time windows. This information is only required for orders of image stacks (repeat acquisitions). Imaging Mode : Refer to Section Types of SAR Collection for more information on these imaging modes Strip Spot Spot Extended Area Scan","title":"How to fill in a standard order form"},{"location":"productguide/ordering/#feasibility-study-as-part-of-a-standard-order","text":"ICEYE customers can request a feasibility study at any time when considering placing a standard order request. Simply email the COSP team at the address your were given when your account was set up. You will need to provide an AOI, an imaging mode (or resolution), a time period and any possible additional instructions that you may require. The ICEYE Customer Operations and Satellite Planning Team will respond with a list of acquisition opportunities. Please note that Feasibility Studies are for informational purposes and do not reserve constellation capacity for the opportunities reported. The required constellation capacity to fulfill an order under the agreed time window is only reserved after ICEYE confirms an order . Please also note that feasibility studies are not required to place a standard order. You can eliminate the need for a feasibility study by accurately describing the time windows and other acquisition constraints that match your actual needs as part of your standard order. Figure 4: Feasibility studies can be requested before placing a standard order. Sometimes you might like to perform your own feasibility studies and we encourage this. We have made sure our satellite ephemeris information is publicly available at celestrak [^1] and n2yo.com [^2], and have provided step by step instructions on how to use the Swath Acquisition Viewer Software, SaVoir on the ICEYE website . Let us know how well this works for you.","title":"Feasibility Study as Part of a Standard Order"},{"location":"productguide/ordering/#custom-orders","text":"Custom Tasking orders offer a higher level of flexibility when specifying tasking requirements you desire. In general, any options that are not available as part of standard order can be requested as part of a custom order. Custom orders are initiated by submitting a Custom Order Form to the email address you received when your account was set up. Our tasking experts will study the feasibility of your request and will quote an acquisition plan for you to approve. New customers should contact the ICEYE sales team . The following are examples of options that are currently available as part of a custom order: Mosaics : Coverage of large areas by acquiring multiple images Custom AOI coverage requirements : Each acquired image must cover at least a minimum percentage of the area of interest. Local time deviation limits : Images belonging to a stack or mosaic collection should be acquired within a certain local time range. Long image size requirements : Images that exceed the standard frame size of the requested imaging mode to cover the desired AOI. For example, long Strip acquisitions. Azimuth angle deviation limits for stacks or mosaics : Images belonging to a stack or mosaic collection should be acquired within a certain azimuth angle range. Custom acquisition time windows not available as standard tasking options : For example 72-hour, or 96-hour time windows for each acquisition. Our tasking experts will be happy to try to accommodate any special tasking request that is required to meet your business needs. Figure 5: Custom ICEYE Tasking order flow.","title":"Custom Orders"},{"location":"productguide/ordering/#quality-control-and-image-delivery","text":"","title":"Quality Control and Image Delivery"},{"location":"productguide/ordering/#automatic-delivery","text":"All acquisition SAR data initially goes though an automated quick Quality Control process in which we ensure that it covers the intended target location. The data is then automatically and immediately delivered to your folder in the ICEYE SFTP server. This gives you access to the SAR data without delay.","title":"Automatic delivery"},{"location":"productguide/ordering/#quality-control","text":"In addition to the automated quick Quality Control mentioned above, a detailed manual Quality Control is performed on all acquisition data. An ICEYE analyst will verify the acquired SAR Data conforms to the product specifications and that it does not contain any disqualifying ambiguities.","title":"Quality Control"},{"location":"productguide/ordering/#redelivery-if-required","text":"If defects are found during the detailed manual Quality Control steps, ICEYE will attempt to correct and redeliver the data to your SFTP folder as soon as possible. The most common type of defects that are detected and corrected in during Quality Control are geolocation inaccuracies. When performing Quality Control, sometimes ICEYE will have access to more refined satellite telemetry and orbit information that allows us to improve the geolocation accuracy. In such cases, the SAR data will be reprocessed to improve its geolocation accuracy and will be redelivered to you.","title":"Redelivery (if required)"},{"location":"productguide/ordering/#delivery-service-level","text":"Automatic delivery, quality control and redelivery (if required) will be completed within 8 hours of the data being acquired. ICEYE will soon offer faster delivery times for customers that require near-real-time data. New customers receive instructions from the Customer Operations and Satellite Planning team on how to access your SFTP account. Through the SFTP server, you will have access to download all of your SAR data. You will receive a notification (via email) every time a new acquisition has passed our detailed Quality Control process and the final version of the data is ready for you to download using your SFTP account. Info Images are stored in your SFTP account for a period of 30 days.","title":"Delivery service level"},{"location":"productguide/ordering/#unforeseen-circumstances","text":"In very rare situations, it might not be possible to acquire an image within the agreed time window. In this case, the Customer Operations and Satellite Planning team will immediately inform you and will propose an extended acquisition time window or allow you to cancel the collection.","title":"Unforeseen Circumstances"},{"location":"productguide/ordering/#iceye-archive-imagery","text":"As an ICEYE customer, you have access to a complete catalog of archive imagery that is available for ordering. This catalog is updated on a regular basis on your SFTP account. The catalog is available in kmz and geojson formats and it includes low resolution image thumbnails so you can get a feel for the content of the image. The archive catalog can be viewed in Google Earth, QGIS or your favorite GIS where you can browse image locations, filter by time or different image metadata and perform advanced searches. Please note that imagery is included in the ICEYE Archive Catalog at least seven days after its acquisition time. Figure 6: Browsing the ICEYE Archive catalog in Google Earth (kmz format). Figure 7: Browsing the ICEYE Archive catalog in QGIS (geojson format). Archive imagery orders can be submitted via email. To place an order, please fill out either the Standard Order Form or the Custom Order Form with your contact information, and include a list of the product names for the scenes that you wish to purchase. An example of a product name that identifies an image scene is : ICEYE_ARCHIVE_SM_10306_20190918T125047 Once an order is received, the ICEYE Customer Success team will deliver the requested images to you within 12 hours (assuming a realistic number of archive images. eg. less than 50). Please note that all orders for archive imagery require no final confirmation from you. The images that you request in your order will be delivered to you. Figure 8: Archive imagery order flow. Please note that orders for archive imagery do not go through additional quality control. However, if you are not satisfied with the quality of an archive image that you have received, you can make use of our return policy described below.","title":"ICEYE Archive Imagery"},{"location":"productguide/ordering/#order-cancellation","text":"In order to support your evolving business requirements, ICEYE supports a user-friendly order cancellation policy.","title":"Order Cancellation"},{"location":"productguide/ordering/#cancellation-of-tasking-orders","text":"Standard Tasking orders confirmed by ICEYE can be cancelled free of charge up to 72 hours prior to the start of the acquisition time window. Custom Tasking orders may be cancelled or rescheduled within twenty four (24) hours after order confirmation at no cost, as long as the order is submitted at least 72 hours before the proposed data collection time. Cancellation policy conditions are presented in the table below. CANCELLATION REQUEST TIME (HOURS) ADDITIONAL CONDITION CANCELLATION CHARGE Within 24 of order confirmation of a Custom Order Order submitted >72h before the acquisition acquisition time window Free of charge More than 72h prior to the start of the acquisition time window N/A Free of charge 72 - 48h prior to the start of the acquisition time window N/A 10% of the image value 48 - 24h prior to the start of the acquisition time window N/A 20% of the image value Less than 24h prior to the start of the acquisition time window Order submitted >24h before the start of the acquisition time window 100% of the image value Table 1: Cancellation Requests.","title":"Cancellation of Tasking Orders"},{"location":"productguide/ordering/#return-policy","text":"If you are not satisfied with your purchase, please contact our Customer Operations and Satellite Planning team at customer@iceye.com within 30 days of receiving your order. Your satisfaction is our priority, so we will work quickly to resolve your concerns.","title":"Return Policy"},{"location":"productguide/ordering/#invoicing","text":"ICEYE users can pay for imaging in a range of different ways in order to be as flexible as possible: Prepayment : In this option a number of images can be paid for up-front. When the prepayment has been paid, you can place orders and receive the amount of data up to your prepaid quota. This is designed for customers that know that they would like to purchase a number of images and offers imagery at a reduced rate. Net 30 : This is designed for larger or industrial customers wishing to purchase imagery in volume. In this case we will discuss your needs and enter into a contract with you. Images can then be tasked as and when you see fit and we will invoice you monthly. Payment then has to be made within 30 days of sending you the invoice. ICEYE Finance will send invoices during the first week of the month for all the products delivered to you within the previous month. The monthly invoice will not include the products that have been ordered but have not yet been delivered to you. If no products have been shipped to you during the previous month, invoice will not be extended.","title":"Invoicing"},{"location":"productguide/productguide/","text":"ICEYE SAR PRODUCTS WELCOME TO ICEYE Your Choice for Persistent Monitoring ICEYE empowers commercial and government partners with unmatched persistent monitoring capabilities for any location on Earth. We do this with our continually growing SAR satellite constellation, currently in orbit and delivering SAR data. This product guide reviews our constellation, products, imaging modes and ordering process. This is a living document because our innovative small SARs are flexible and they welcome our routine upgrades to their resolution, coverage and quality. We\u2019ll release new versions of this guide as we improve our sensors, expand our constellation, and streamline our order and delivery systems. SAR sensors see through clouds and darkness. They measure pulse echoes with a precision much smaller than a single wavelength. Their resolution is independent of distance. They are capable of pristine geolocation, and they are change detection machines. We Look Forward to Serving You The Small SAR Revolution in Earth Imaging During the Middle Ages, if you wanted to understand the way the world worked you would consult your local religious leader. A Priest or Prophet would interpret the Word of God from beautifully written tomes that were transcribed by hand over many years. These books were ornate and so precious that they could not be widely distributed, and most people did not know how to read. In these years, the thoughts of nations were controlled by various religious and political leaders. Then everything changed. The Renaissance and Reformation spurred new ways of thinking, and their ideas were recorded in printed books that were produced at low cost and in great volumes. People learned to read for themselves and think for themselves. Information spread across the globe. Sometimes disruption can be good. Hundreds of years later, in 2012, a small team of students working in the Nanosatellite Group of Aalto University considered the sequestered world of earth observation. The team was bothered by the limitations of government satellite programs in the same way that Renaissance and Reformation advocates challenged the knowledge control of the Middle Ages. Satellite imagery has been mostly provided by massive, government-owned or government-sponsored, exquisite systems. Like the tomes of old, these are beautifully implemented and precious. But normal people rarely have access to their images, and even when they are available, they do not have the timeliness to support the quick decisions needed in this rapidly changing world. The Nanosatellite students thought that timely, always available fine-resolution imagery should become a part of everyday life in the 21st century in the same way that GPS became integrated to nearly all businesses in the last decade of the 20th century. The humanitarian applications of easily-accessible imagery would include earthquakes, floods, volcanoes, glacial flow, and numerous environmental indicators. But if earth-observation imagery were to become as available, reliable and timely as the pace of our modern lives requires, things needed to change. Fueled by curiosity, passion, and long, dark Helsinki nights, the students decided that Synthetic Aperture Radar (SAR) would be the most useful way to obtain guaranteed, all-weather, day-night, observations of this cloud-covered planet. They reconsidered the conventional thinking regarding the mass and size needed to build SAR satellites, and then developed experimental sensors to prove and revise their thinking. In 2015 ICEYE Oy was born. And thanks to several backers who shared our vision, on January 12th, 2018 the world\u2019s first micro-SAR satellite was launched. In contrast to the existing SAR systems that each weigh several tons, our ICEYE-X1 weighed only 75kg. It provided beautiful 3-meter resolution imagery, and it allowed our company to evaluate many natural disasters. The ICEYE fleet is now growing rapidly. We began 2021 with 7 satellites, and we\u2019ll expand this to a constellation of 18 by mid-2022. Change is natural to our flexible systems. We upgrade our satellites the way programmers update code. Our resolution and coverage improves with each new version. And our low-cost, low-mass satellites are so highly maneuverable that we can reposition them to optimize revisit rates and support global change detection. We will bring our users access to highly accurate, highly reliable monitoring, whenever and wherever they need it, at a pace that has never before existed. Welcome to the Earth Observation Renaissance ! \u2013 Medium \u2013 Twitter \u2013 Facebook References","title":"ICEYE SAR PRODUCTS"},{"location":"productguide/productguide/#iceye-sar-products","text":"","title":"ICEYE SAR PRODUCTS"},{"location":"productguide/productguide/#welcome-to-iceye","text":"","title":"WELCOME TO ICEYE"},{"location":"productguide/productguide/#your-choice-for-persistent-monitoring","text":"ICEYE empowers commercial and government partners with unmatched persistent monitoring capabilities for any location on Earth. We do this with our continually growing SAR satellite constellation, currently in orbit and delivering SAR data. This product guide reviews our constellation, products, imaging modes and ordering process. This is a living document because our innovative small SARs are flexible and they welcome our routine upgrades to their resolution, coverage and quality. We\u2019ll release new versions of this guide as we improve our sensors, expand our constellation, and streamline our order and delivery systems. SAR sensors see through clouds and darkness. They measure pulse echoes with a precision much smaller than a single wavelength. Their resolution is independent of distance. They are capable of pristine geolocation, and they are change detection machines. We Look Forward to Serving You","title":"Your Choice for Persistent Monitoring"},{"location":"productguide/productguide/#the-small-sar-revolution-in-earth-imaging","text":"During the Middle Ages, if you wanted to understand the way the world worked you would consult your local religious leader. A Priest or Prophet would interpret the Word of God from beautifully written tomes that were transcribed by hand over many years. These books were ornate and so precious that they could not be widely distributed, and most people did not know how to read. In these years, the thoughts of nations were controlled by various religious and political leaders. Then everything changed. The Renaissance and Reformation spurred new ways of thinking, and their ideas were recorded in printed books that were produced at low cost and in great volumes. People learned to read for themselves and think for themselves. Information spread across the globe. Sometimes disruption can be good. Hundreds of years later, in 2012, a small team of students working in the Nanosatellite Group of Aalto University considered the sequestered world of earth observation. The team was bothered by the limitations of government satellite programs in the same way that Renaissance and Reformation advocates challenged the knowledge control of the Middle Ages. Satellite imagery has been mostly provided by massive, government-owned or government-sponsored, exquisite systems. Like the tomes of old, these are beautifully implemented and precious. But normal people rarely have access to their images, and even when they are available, they do not have the timeliness to support the quick decisions needed in this rapidly changing world. The Nanosatellite students thought that timely, always available fine-resolution imagery should become a part of everyday life in the 21st century in the same way that GPS became integrated to nearly all businesses in the last decade of the 20th century. The humanitarian applications of easily-accessible imagery would include earthquakes, floods, volcanoes, glacial flow, and numerous environmental indicators. But if earth-observation imagery were to become as available, reliable and timely as the pace of our modern lives requires, things needed to change. Fueled by curiosity, passion, and long, dark Helsinki nights, the students decided that Synthetic Aperture Radar (SAR) would be the most useful way to obtain guaranteed, all-weather, day-night, observations of this cloud-covered planet. They reconsidered the conventional thinking regarding the mass and size needed to build SAR satellites, and then developed experimental sensors to prove and revise their thinking. In 2015 ICEYE Oy was born. And thanks to several backers who shared our vision, on January 12th, 2018 the world\u2019s first micro-SAR satellite was launched. In contrast to the existing SAR systems that each weigh several tons, our ICEYE-X1 weighed only 75kg. It provided beautiful 3-meter resolution imagery, and it allowed our company to evaluate many natural disasters. The ICEYE fleet is now growing rapidly. We began 2021 with 7 satellites, and we\u2019ll expand this to a constellation of 18 by mid-2022. Change is natural to our flexible systems. We upgrade our satellites the way programmers update code. Our resolution and coverage improves with each new version. And our low-cost, low-mass satellites are so highly maneuverable that we can reposition them to optimize revisit rates and support global change detection. We will bring our users access to highly accurate, highly reliable monitoring, whenever and wherever they need it, at a pace that has never before existed. Welcome to the Earth Observation Renaissance ! \u2013 Medium \u2013 Twitter \u2013 Facebook","title":"The Small SAR Revolution in Earth Imaging"},{"location":"productguide/productguide/#references","text":"","title":"References"},{"location":"productguide/products/","text":"ICEYE PRODUCTS Product Types There are two basic forms of ICEYE images: complex images in the slant plane and amplitude images projected to the ground surface. Details about the formats of these products are provided in 'SAR Data Formatting Options' . Info The section \"What is SAR?\" provides a review of the technologies mentioned here. Complex Images SAR complex images contain pixels that have both amplitude and phase values. They are produced at full resolution and are projected in the inclined direction of illumination, called the slant plane. Since complex images retain phase information, they can be used to produce numerous SAR products like coherent change images and precise surface motion measurements. Info Complex Images are used for 'interferometric SAR' such as the formation of digital elevation models (DEM), land subsidence monitoring or coherent change analysis. Amplitude Images These are the familiar SAR gray-scale images with amplitude-only pixels. They are \u201cmulti-looked\u201d to reduce the grainy effect of speckle, at the cost of slightly lower resolution. Amplitude images are projected to the ground surface and can be oriented with respect to the sensor or produced on an ellipsoid-based map projection. ICEYE produces amplitude images in the natural range-azimuth sensor orientation because they offer the most flexibility in exploitation. To be consistent with conventional terminology, these sensor-oriented images are called Ground Range Detected (GRD). This term may change in the future to be something more meaningful. Info Amplitude images are most useful for rapid observation of a location regardless of lighting or weather conditions. Types of SAR Collection Our first set of satellites operate in one of two primary imaging modes called Strip Mode and Spot Mode. These are available in both right and left-looking configurations. The design flexibility of our satellites allows their imaging modes to be continually evolved. We will be adding more modes, and more flexible illumination patterns, in future versions. A recent addition is Scan Mode, which is a wide-area imaging capability that uses electronic beam steering. A summary of the imaging modes is listed in An Overview of SAR Imaging . Strip Mode In this mode the ground swath is illuminated with a continuous sequence of pulses while the antenna beam is fixed in its orientation. The beam is pointed off to the side of the satellite at an angle broadside to the satellite flight path. This results in a long image strip parallel to the flight direction. ICEYE standard Strip products have a ground resolution of 3m in range and azimuth and cover an area of 30km (range) by 50km (azimuth). The strip length can be tailored up to a length of 500 km, in increments of 50 km. Info Having a wide area and a moderate resolution, Strip images are useful for 'situational awareness'. They allow a user to quickly asses what is occurring in the region. They are particularly useful for tasks such as deforestation monitoring, or iceberg / glacier monitoring. They are also our 'first responder' product in times of natural disaster to assess the impact of a flood, earthquake or volcano. Spot Mode In Spot mode the radar beam is steered to illuminate a fixed point. This increases the illumination time and therefore increases the length of the synthetic aperture and improves azimuth resolution. ICEYE Generation2 satellites have a maximum 300 MHz pulse bandwidth in Spot Mode to achieve a 0.5m slant range resolution ( here is an explanation of where this comes from.). This will improve to 600 MHz for our Generation3 version. ICEYE's standard Spot collection covers an area of 5km x 5km with a 1 m ground resolution for multi-looked amplitude images. These are formed from 4 independent looks to suppress speckle and increase image quality. Alternatively, customers can request an extended area spot image. This uses a slightly modified spot collection (sometimes called sliding spot ) in which the beam is allowed to slide just a bit. This increases collection area and trades the number of looks to preserve resolution for amplitude images. The Spot extended area collection has a scene size of 15km x 15km at 1m ground resolution with no multi-looking applied. Note Having the finest resolution, Spot images are useful to more detailed investigation of an area. They are used primarily to discriminate between different types of object such as boats or ships, different aircraft, or different types of building or infrastructure. The additional resolution also helps with coherence analysis techniques such as INSAR. Scan Mode This mode uses the phased array antenna to create multiple beams in the elevation direction. This beam steering illuminates a wide area via multiple adjacent strips, but it means that points on the ground are not illuminated for as long as conventional Strip Mode. This reduces the resolution of a Scan product. In conventional scan mode, ground points are illuminated by different parts of the radar beam resulting in brighter and darker regions in the image. We compensate for this in our scan by also steering the radar beam sideways during each burst of radar pulses. This improves image quality. This technique is called Terrain Observation by Progressive Scans (TOPS or TOPSAR 1 ). Our Scan product produces imagery that covers an area of 100km x 100km with a resolution better than 15m. The length of a Scan product can be increased to 300km. Note Having the largest area coverage and a modest resolution, Scan images are highly suited to wide area surveillance and mapping projects. Being able to operate in all weather and lighting conditions, they provide an excellent opportunity to image the oceans and to detect ships and monitor shipping lanes. References F. De Zan and A. Monti Guarnieri. Topsar: terrain observation by progressive scans. IEEE Transactions on Geoscience and Remote Sensing , 44 \\(9\\) :2352\u20132360, 2006. doi:10.1109/TGRS.2006.873853 . \u21a9","title":"Product Types"},{"location":"productguide/products/#iceye-products","text":"","title":"ICEYE PRODUCTS"},{"location":"productguide/products/#product-types","text":"There are two basic forms of ICEYE images: complex images in the slant plane and amplitude images projected to the ground surface. Details about the formats of these products are provided in 'SAR Data Formatting Options' . Info The section \"What is SAR?\" provides a review of the technologies mentioned here.","title":"Product Types"},{"location":"productguide/products/#complex-images","text":"SAR complex images contain pixels that have both amplitude and phase values. They are produced at full resolution and are projected in the inclined direction of illumination, called the slant plane. Since complex images retain phase information, they can be used to produce numerous SAR products like coherent change images and precise surface motion measurements. Info Complex Images are used for 'interferometric SAR' such as the formation of digital elevation models (DEM), land subsidence monitoring or coherent change analysis.","title":"Complex Images"},{"location":"productguide/products/#amplitude-images","text":"These are the familiar SAR gray-scale images with amplitude-only pixels. They are \u201cmulti-looked\u201d to reduce the grainy effect of speckle, at the cost of slightly lower resolution. Amplitude images are projected to the ground surface and can be oriented with respect to the sensor or produced on an ellipsoid-based map projection. ICEYE produces amplitude images in the natural range-azimuth sensor orientation because they offer the most flexibility in exploitation. To be consistent with conventional terminology, these sensor-oriented images are called Ground Range Detected (GRD). This term may change in the future to be something more meaningful. Info Amplitude images are most useful for rapid observation of a location regardless of lighting or weather conditions.","title":"Amplitude Images"},{"location":"productguide/products/#types-of-sar-collection","text":"Our first set of satellites operate in one of two primary imaging modes called Strip Mode and Spot Mode. These are available in both right and left-looking configurations. The design flexibility of our satellites allows their imaging modes to be continually evolved. We will be adding more modes, and more flexible illumination patterns, in future versions. A recent addition is Scan Mode, which is a wide-area imaging capability that uses electronic beam steering. A summary of the imaging modes is listed in An Overview of SAR Imaging .","title":"Types of SAR Collection"},{"location":"productguide/products/#strip-mode","text":"In this mode the ground swath is illuminated with a continuous sequence of pulses while the antenna beam is fixed in its orientation. The beam is pointed off to the side of the satellite at an angle broadside to the satellite flight path. This results in a long image strip parallel to the flight direction. ICEYE standard Strip products have a ground resolution of 3m in range and azimuth and cover an area of 30km (range) by 50km (azimuth). The strip length can be tailored up to a length of 500 km, in increments of 50 km. Info Having a wide area and a moderate resolution, Strip images are useful for 'situational awareness'. They allow a user to quickly asses what is occurring in the region. They are particularly useful for tasks such as deforestation monitoring, or iceberg / glacier monitoring. They are also our 'first responder' product in times of natural disaster to assess the impact of a flood, earthquake or volcano.","title":"Strip Mode"},{"location":"productguide/products/#spot-mode","text":"In Spot mode the radar beam is steered to illuminate a fixed point. This increases the illumination time and therefore increases the length of the synthetic aperture and improves azimuth resolution. ICEYE Generation2 satellites have a maximum 300 MHz pulse bandwidth in Spot Mode to achieve a 0.5m slant range resolution ( here is an explanation of where this comes from.). This will improve to 600 MHz for our Generation3 version. ICEYE's standard Spot collection covers an area of 5km x 5km with a 1 m ground resolution for multi-looked amplitude images. These are formed from 4 independent looks to suppress speckle and increase image quality. Alternatively, customers can request an extended area spot image. This uses a slightly modified spot collection (sometimes called sliding spot ) in which the beam is allowed to slide just a bit. This increases collection area and trades the number of looks to preserve resolution for amplitude images. The Spot extended area collection has a scene size of 15km x 15km at 1m ground resolution with no multi-looking applied. Note Having the finest resolution, Spot images are useful to more detailed investigation of an area. They are used primarily to discriminate between different types of object such as boats or ships, different aircraft, or different types of building or infrastructure. The additional resolution also helps with coherence analysis techniques such as INSAR.","title":"Spot Mode"},{"location":"productguide/products/#scan-mode","text":"This mode uses the phased array antenna to create multiple beams in the elevation direction. This beam steering illuminates a wide area via multiple adjacent strips, but it means that points on the ground are not illuminated for as long as conventional Strip Mode. This reduces the resolution of a Scan product. In conventional scan mode, ground points are illuminated by different parts of the radar beam resulting in brighter and darker regions in the image. We compensate for this in our scan by also steering the radar beam sideways during each burst of radar pulses. This improves image quality. This technique is called Terrain Observation by Progressive Scans (TOPS or TOPSAR 1 ). Our Scan product produces imagery that covers an area of 100km x 100km with a resolution better than 15m. The length of a Scan product can be increased to 300km. Note Having the largest area coverage and a modest resolution, Scan images are highly suited to wide area surveillance and mapping projects. Being able to operate in all weather and lighting conditions, they provide an excellent opportunity to image the oceans and to detect ships and monitor shipping lanes.","title":"Scan Mode"},{"location":"productguide/products/#references","text":"F. De Zan and A. Monti Guarnieri. Topsar: terrain observation by progressive scans. IEEE Transactions on Geoscience and Remote Sensing , 44 \\(9\\) :2352\u20132360, 2006. doi:10.1109/TGRS.2006.873853 . \u21a9","title":"References"},{"location":"productguide/support/","text":"SUPPORT Customer Operations and Satellite Planning Team The Customer Operations and Satellite Planning (COSP) team is the department of ICEYE in charge of order processing and customer support. Customer Operations and Satellite Planning staff who interact directly with the customer are called Customer Operations and Satellite Planning Specialists. The responsibilities of the COSP Specialist are: Customer on-boarding and training Customer order management: Receiving orders Confirming orders Processing orders Conducting Quality Control of the products Delivering orders Customer Communications regarding any issues within the framework of the current contract Customer Satisfaction Surveys Improvement of the overall customer experience Working Hours The Customer Operations and Satellite Planning team is available 24 hours per day to answer any collection planning queries or to help you find solutions to technical problems. Contact Information The customer can reach out to the Customer Operations and Satellite Planning team via email to customer@iceye.com .","title":"Support"},{"location":"productguide/support/#support","text":"","title":"SUPPORT"},{"location":"productguide/support/#customer-operations-and-satellite-planning-team","text":"The Customer Operations and Satellite Planning (COSP) team is the department of ICEYE in charge of order processing and customer support. Customer Operations and Satellite Planning staff who interact directly with the customer are called Customer Operations and Satellite Planning Specialists. The responsibilities of the COSP Specialist are: Customer on-boarding and training Customer order management: Receiving orders Confirming orders Processing orders Conducting Quality Control of the products Delivering orders Customer Communications regarding any issues within the framework of the current contract Customer Satisfaction Surveys Improvement of the overall customer experience","title":"Customer Operations and Satellite Planning Team"},{"location":"productguide/support/#working-hours","text":"The Customer Operations and Satellite Planning team is available 24 hours per day to answer any collection planning queries or to help you find solutions to technical problems.","title":"Working Hours"},{"location":"productguide/support/#contact-information","text":"The customer can reach out to the Customer Operations and Satellite Planning team via email to customer@iceye.com .","title":"Contact Information"}]}